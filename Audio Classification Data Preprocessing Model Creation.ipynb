{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Classification Model Creation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading a sample audio using librosa\n",
    "import librosa\n",
    "audio_file_path='UrbanSound8K/191431-9-0-73.wav'\n",
    "librosa_audio_data, librosa_sample_rate = librosa.load(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00389228  0.00845505  0.01697432 ... -0.00208947 -0.00125767\n",
      " -0.0056572 ]\n"
     ]
    }
   ],
   "source": [
    "print(librosa_audio_data) #audio data by default converts the audio data into mono channel with 1 signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1557f4e10>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+oAAAFfCAYAAADZBjY9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACLC0lEQVR4nO3dd3wT5R8H8E+6aemgUFoKLRvKLFCkFFBWpSg/ZYmAiAgIouBCUXCAigouxIEgLhwgKE4Q2RvKKnuVTctoy2oLlO77/VEaMi7JZVzukn7er1dfSnK5PEluPN9nfB+NIAgCiIiIiIiIiEgVPJQuABERERERERHdwUCdiIiIiIiISEUYqBMRERERERGpCAN1IiIiIiIiIhVhoE5ERERERESkIgzUiYiIiIiIiFSEgToRERERERGRingpXQAllJaW4sKFCwgMDIRGo1G6OEREREREROTmBEHA9evXERkZCQ8P833mFTJQv3DhAqKiopQuBhEREREREVUw6enpqFWrltltKmSgHhgYCKDsCwoKClK4NEREREREROTucnNzERUVpY1HzamQgXr5cPegoCAG6kREREREROQ0UqZfM5kcERERERERkYowUCciIiIiIiJSEQbqRERERERERCrCQJ2IiIiIiIhIRRioExEREREREakIA3UiIiIiIiIiFWGgTkRERERERKQiDNSJiIiIiIiIVISBOhEREREREZGKMFAnIiIiIiIiUhEG6kRUYdwqLMHzC/dg+cEMpYtCRERERGQSA3UiqjDmbjyFv/ZewJifU5QuChERERGRSQzUiajCyLqer3QRiIiIiIgsYqBOREREREREpCIM1ImowhCULgARERERkQQM1ImIiIhIcTl5RUoXgYhINRioExEREZGiFu1MQ+zbKzFr3Qmli0JEpAoM1ImowhA49p2ISJVe+f0AAODDFakKl4SISB0YqBMRERGR6uXkFeHUpRtKF4OIyCkYqBMRERGR6rWeuhLdPt7AYJ2IKgSnBOqzZs1CnTp14Ofnh/j4eOzYscPs9r/99htiYmLg5+eHFi1aYNmyZSa3HTNmDDQaDWbOnOngUhMRERGRWpTenr60/fRVZQtCROQEsgfqixYtwvjx4zFlyhTs3r0bsbGxSEpKQlZWluj2W7duxeDBgzFy5Ejs2bMHffr0QZ8+fXDw4EGjbf/8809s27YNkZGRcn8MIiIiInKCC9m38PXGU8i5xSzwRFRxyR6oz5gxA6NGjcLw4cPRtGlTzJkzB/7+/vjuu+9Et//000/Rs2dPTJgwAU2aNMHUqVPRpk0bfPHFF3rbnT9/Hs888wzmz58Pb29vuT8GERERETlB/9lb8e6yI3j1zwNKF4WISDGyBuqFhYVISUlBYmLinTf08EBiYiKSk5NFX5OcnKy3PQAkJSXpbV9aWoqhQ4diwoQJaNasmcVyFBQUIDc3V++PiCoipn0nIlK7izn5AIBNxy4pXBIiIuXIGqhfvnwZJSUlCA8P13s8PDwcGRkZoq/JyMiwuP37778PLy8vPPvss5LKMW3aNAQHB2v/oqKirPwkRERERERERM7hclnfU1JS8Omnn2LevHnQaDSSXjNp0iTk5ORo/9LT02UuJRERERHJQVrtj4jItckaqFerVg2enp7IzMzUezwzMxMRERGir4mIiDC7/aZNm5CVlYXo6Gh4eXnBy8sLZ8+exYsvvog6deqI7tPX1xdBQUF6f0RU8Qgc+U5ERERELkDWQN3HxwdxcXFYs2aN9rHS0lKsWbMGCQkJoq9JSEjQ2x4AVq1apd1+6NCh2L9/P/bu3av9i4yMxIQJE7BixQr5PgwRERERERGRE3jJ/Qbjx4/HsGHD0LZtW7Rr1w4zZ87EzZs3MXz4cADAY489hpo1a2LatGkAgOeeew6dO3fGxx9/jF69emHhwoXYtWsX5s6dCwCoWrUqqlatqvce3t7eiIiIQOPGjeX+OERERERERESykj1QHzhwIC5duoTJkycjIyMDrVq1wvLly7UJ49LS0uDhcadjv0OHDliwYAFef/11vPrqq2jYsCH++usvNG/eXO6iEpGb49B3IiLXJzFFEbmgU5duICzQF4F+XHqZSPZAHQDGjRuHcePGiT63fv16o8cGDBiAAQMGSN7/mTNnbCwZERERyaWopBSjf9yFtnVCMbZrA6WLQy7GVNJgNrq6p0MXctDrs80I8vPC/jeTlC4OkeJcLus7EZGt2AvjHq7eLMSVGwVKF4MkWH4wA+tSL+HDFalKF4WIVG7d0SwAQG5+scIlIVIHp/SoExGpAXthXF9RSSnaTF0FADj2zn3w8WJ7s5rdKipRugjkwgRetImoAmMNh4iIXMbNgjs9Ldm3Ci1uvyftGtq9uxr/7LsgZ7GcoqC4BOuOZiGvkL1NVLFxdBQRVQQM1ImIyG09+VMKsq4X4Nlf9ihdFLu9veQwhs/biWcWuP5nIffw07azWHs00+rXbT15GVOXHkY+R1yQDg6gINLHoe9EVGEIYC3ArUj4OYtL3ec3n789DQCw5vY8TiIlHbqQgzf+OggAODO9l1WvfeTr7QCA0AAfJhkkIjKBPepEROQyNLgz5tV9QnAi15OVa39Cx7NXbjqgJERE7omBOhERuQ6duakcJkmkHI5QIiKSFwN1IqowGNi5PmuTSDFrtLKY84vsYWoddQ2PLCKqABioExGRS2KPHpFyHNEGZmvAzXOfiCoCBupEVGFwSR/Xp/sTsrOcSDmOOP+kBNxL91/A0G+348qNO3PiX/n9AM5dy7O/AEREKsZAnYgqjNSM60oXgexkaigsETmXM9rJBEHAuAV7sOn4ZXywPFXvufcN/k2uj22vRPoYqBNRhbHvXI7SRSA76fWoK1YKIjqWaX/Dp6Wh77rn+LW8Qr3nSjmkhojcHAN1IiJyGRq9rO+sqBMppaC4VPb3uJ5fLGm7vMJi5BeVyFwaIiLnYqBOREQuiXE6UcWx8nCm6OP5RSVoOnkFWr+9ysklIiKSFwN1IiJyGVyWqczGY5dws0BabyORLBzQUrbjzFXMWHUMxSXW987nFRRj0c407EnLBgDcYo86EbkZL6ULQEREJBVzyZV57LsdSKhXFb+Mbq90URxKEAQmDHQRjhjQcvryTXy25jjCAn2tfu261EtYl3oJPp7scyIyJAgCtp++ikbhgQgN8FG6OGQjXt2IiMglVfSh78mnrihdBIeavf4kWk9dhRNZXJ3BFTjy/Dt7+abNry20oTeeyN2tOJSJQXO3oetH65UuCtmBgToREbkkKWswV/BY3qW8v/wosvOKMOmPA0oXhSS4rLOuObm+7LxCvLBoL7acuKxYGSp646sjrbqd0yHnVpHCJSF7MFAnIiKXoZ/1XblykDS2DGMvKeUP6woW7kx32L4c9YsLgoDNxy/j8zXHUVoq4MjFXBSxx12S95en4s895zHkm+1KF4UcQEpDNqkf56gTERGRLI7bsNY2q5euR025BR79tizQXH/sElLOXkPPZhGYMzRO4VKp38WcW0oXgTlIHIgN2e6BPepEROQymPVdmtnrT2LB9jSli4EbzExPEshxVqecvQYAWH4oA2uPii/tRnd4eSh/bWVw6TgCv0y3wECdiIhcht7Qd+WKoWrpV/Pw/vKjePVP5ed6s4esYrA3JpD7XB4xbxdOXboh87u4Nk8VBOrkOJxB5B4YqBOR22ALsmsrLRXw5j+HsDjlnMltdKuS/L3FXc9XTy82R0CQM5m7JKRfU35ot5p5eUgLCQRBwLebT2Obm606UZExj4N6MVAnIrfw5foTuOvdNTh7xfZlfkhZ61KzMG/rGbz02z5J2zNMV6/c/CL8uecc8gpLlC4KOYG95yKbc1zHutQsTF16GIPmblO6KE51+EIurue7Tgb1UokN2dP+O4LGr/+HYzbkEyH5MVAnIrfwwfJUXL5RgGnLjipdFLLRr7ssZ5HWTVhVkTrUXS0T+rgFe/DCon34fbfp0RFE5Vzr6HZTEltLzlzOk7ccKrT1xGXc/9kmdPt4g9JFkey/gxmStvtqwymUCsCMlcdkLhHZgoE6kQUXc25h+cEMlLpYRZnI1exOy7a4TUXteXO1pGwbj11SugjkRJyG4voq6rVVihWHyoLeS9cLFC6JdNY27nI5N3VioO4C3vjrIJ74YSdvhArpOH0txvycgj/2nFe6KERuzfprXAW6Jlakj1qBPiuRWkhdXq8iJojkJYmUwkDdBfy07SxWH8nCgfM5ShelQipvlFx24KKyBSEinNbJQSAloHOXoI+9HaRmajk61VIOsg2vc0T6GKi7EFebo+hu1h7NUroIJIFua//fe89j1WHb188tKRWQ60LJY1ydlKD6lk5yMle8Ii7YnoYen2zA+WzrMlAXFlvOyst7BKnNzYJijgZ0EVI7ynW3u3qz0Oy2+UUlWH4ww+x99Mzlm/h282nkFzHxpJJ4mqoTA3UicoiUs9fw0YpUxW+25Tebizm38NzCvRj14y4UFNtWpoFfJaPlmyuZSd5JKkI94dU/D+BY5g28++9hya/ZcOwSfkg+Y3abvenZaPLGcny98VSFHJpKyhKr5J+8dAPNpqzAkz+l2PR6Ur+PV6aaff69ZUcw5ucUPPHDLpPbdPloPaYuPYyZq487unhOl19Ugv8OXETOLddr4OcKHerEQN2F8D5GatZ/9lZ8se4Evt54StFylAcpmbl3kr5cyM63aV+7zl4DAPyz94Ld5SLr7DpzFbPXnzRK4qgbhJpbfqb8dWoNWguKpK9bO+y7HZi17qTZbSb+vh+FJaV4d9kRe4smG/asViw/JZ8FAKyUMKpJ6lJSlkhpFCBxlq6VpaUCjlzMRYnOT5Wbbz7J5W+7ylZ92HH6qsX333nG8jZKkXp4vr/8KJ6avxvDvtshb4FksPnEZVy+4TrJ8ioKBupE5FAnLt1QuggAHJvBVq3BnrvRraw/NCcZ7y8/itE/paDrR+tx+EIuAECj88uWmoh1v9l0Ci3fWomD53P0KlgVJSmn7kfMzC1rpFp7NBNT/j4oaQi9XKR+9e7/C90hCAJ+3ZmOA+fcLwfNvnPZkredt/WMQ95z9RHbpzpVdJZucx+sSMV9n27C1KXSRwNVNH/eTjq8Nz1b2YLYiKt1qA8DdRfCWIFIGVKz4TqCIAiKBlNqs/pIJk5fvomxC3ZLfs07/x7BjYJivPbXQYN9ZSFLJcvrOOqQuphjfq77tlNXAAAj5u3CD8lnsWD7Wce8sQ0qUgAu1fpjl/Dy7/vxwBeblS6KXQyTgKVfzcMeCcstknpYus/N2WA8queKhR7YitbI7ertwK5efnfEQN2F8PwhUoYzKxtDv92B5m+uQE6e681xs5e5SoJY4wUzBAMJ09bin33Sp2ZczLVtGogc0q7kIb+oBH/sPuf0PBDFJaWK59MAgGMZ15UugiyOZ7nn5yJ9W09eMfu82uP01YfLGoKJ1MpL6QIQuZP8ohLsTruGdnVC4eXJdjAlOTK41jixurH5xGUAwJqjmejXppbT3lcNzA1LLywpC9R1f1dbkt8445d899/D2HryChaP6YBKPp6yv9/na47D00PtVeLy37esnFtOXMaQb7YrVpbOH67HpRsF2D+lB/y85f+NTPFwky5H9sS5PsMjsbC4FD5elusxxSWluFlQgmB/b3kKJpMtJy7jiR/Lktydmd5L4dKoA09j9WEkQeRAY+fvxiNfb8fHq44pXRTSYe285BNZN/R6cN2kLo1fd6Yj5XaCPDUy9ytdEhmyPmBOslFP+xlLvSMGv+X87WfR/r01OOHAHsCvN53GoQu5+HvvebMFOXIxF5+uPq635JwjZF5XT6+5Lt3f99dd6YqVAwDOZ99CYXEpTmQpm1PD2mvL9lNXkOqCvfD5RSUVIj+EuzhyMReNXv8P70iYj/7AF1sQ+/ZKpF/NM3rO2mljzjxE9qQ5/l7IY5wcjYE6kQOtub3W+o8OSoxDjmHNrXPZgYtInLEBj357p7fPHZZnSz55BS//vh/9Z2+VZf/ZeebX05XEhjrOuWv6lcNBc7dp/18D44qT4eiI1/48iIzcfEz8/YDJ9ygtFVBcYn3egIl/HMDNAtNZke/7dBM+WX0Mn6117LJEw7/f6dD9OYruTyFXfTY7rxC/7EhzyeWRLDmffQsD525D0syNShfFajFvLMfjKj0uydjHK8s6G77ZfNritkculiX6XHEoQ/vYmcs3kTBtDW6Yuf4pjTE1uQIG6i6kpJRXFUfZfuoKnvxpFy5km0/ERK5LNyATuyH/ZGJd6p+3lSXb0l1O5m8XXp5NEAQ8+dMuDP56m+WNbZBXWIwWb65Aq7dX2d1LWj3I1+rXFJXo/7gZFuZgm+rgKTa4vgqCoA3ye8/agrs/WIciG4J1KUH4wfPul/FbjC05BUpLBSw/mIGfks/g152Wj68xP6dg0h8H8Owve2wpotNZ0+Po6g2GG5hRWt0cOHJs6tLDuJhj3cgeQRCQV+i8wJ41anIFnKPuQhZsT8NddUKVLoZbGHi71+1GQTHmP9Fe4dKQHCzVf9/4+xBuFpZgTOf6FvflyvNIT166gRWH5Fuy6IPlqbh+ey3d1/48gIfbRlm9j5JSAakZ19G3dU18tNK6aSPWBn+mfkndvZSUCnjg880IDfDBz0/E48DtQPp45g00jQyy6v3OXZO/MdBVKpyCAKxPzYK/j4Wqh07L2uLd5/Dy4v3af7erG4o61QJMvnTbqbIGNluCwsLiUqRmXEezyCB4OGnOv1XvouIf2hV6J133Ku4cjszFYtjwKcXutGzsduJKAdYcs1dvShsx5gKngVkcuq8+DNRdiNJz6dyRMyrRFY1arvP65RAv1PT/jkoK1F25gmdLhckayTpZf4tKBOw8c9XqBsWpSw/bvI6ypePNsMfSZA+mIODL9ScQVtkXzWsG4/Dt4ZzkOJdvFGiHPz8YGynpNYbr+l65WSgaqO84fRXrU7P0HrueX4RAP+kJrh6asxX7z+WgV4samDWkjeTX2cMV2wCPZuTi8zUn9B4rVcuF3wz1l9A6NwqK8f5/R9GrZQ20r1fV7v054lhcezQTf++9gOv56p96YumYLRtVBXh4aPDvgYtOKpVzZF3PR1hlX6P7obmpWlKlnL2GqUsPY8oDTdE6uord+6voOPSdKjS56hY3HZwciqT772AGnvhhF27pLL1k9+/sgpXpcjfynTtHcMCcZKtfY02QbliZtDZAMPVTHs+6gQ+Wp2LC4v0mjxdbhm7rvp/uPP5rjpjTL4GUr8fRyexM6Tlzk/b/HX3pffirZHy5Xn+d5++3nLFqH/vPlY2c+PfARdGcBNduFuLtJYdx+IL0RhxLSdRccbRO/y+3GgUuzaaswLwtluczKymvoBgpZ6+5Ta/hzFXH8NO2s3p5OZQ2Yt4u/L33glN7xuUgCAL6z96KHjM3ut200x+Tz6Ddu2swQyTpseFUMlv0n70Ve9OzbaoLkDEG6i7kwPkc9P1yC3aduWp5Y5LFrjNXUVCs/iB8T9o1bYIXZ1NDvXP1kUx8JyEJjhixOpypyvSuM1ex/1y2Te/jLG5WxzCyYHua2ecNK+UFIuuxA7Yt9WYt3QqfWnogZ607gSaTl2PNEfmmR5TTTSzljGDJnmv1dyJB5+t/H8R3W07j/s82ibzC2JUbBYh5YzkGf70NM1am4qHZW43WblfD9dJaphqi31xiOUO4kp6avxv9Z2/FIgm5DtTg521nRYOpcmccnLPA1KH46p8HjFbXsFVOXhF2nrmqisYScyUoLhWwOy0bJ7JuOPx7Vtrkvw8BAD5fe8LoOUdej+QezVdRMFB3MXvSsvGQA1qpsnLzjSoMFZG1PWQPzUnG8wv3ylMYB8nOK0TfL7fivk+lVSYdTQX3XwDQy/psrkgPfrEZP1jo0RWbrpqdV4iH5iTjwS+2qLrFXe5AQOlAY76FQN1Q+2lr8MZfB81uo3td0P1tbTm2rV2eyFa2nncfrkgFUJah3pnMFdfCgFTJ75GRU4BJfxxAytmreonYpAQJ61ON57gfsjLp3/LbWbC3nbqKz9aewK6z1/DPPv3ElK4Up6ddycPe9Gy79rFop3Xnqxx+331O6SJI8vpfB/HZmuM4lqnscnwLtqdpk6zaIyevCLFvr8SAOclYsr9sRIYcS6RJZWtjwbT/jpjZqY2FUYju1DVSJwbqFVD61Ty0e28N7v5gndJFUZwt1+n/DmZY3khBWSLrTVvjQvYt0fVQ3dX+czmY8s8hs9sYBlvnruWh1durtP9Wqnf0RNYNjP91L05dMp2/wlGBwK4zV0Wzk4utby4nsYRHgiCILgNkKqj4yUKlU/fnlGu9b8NPcT2/CPO3n8XlG879Pl3NzjPX0PfLLZJGsvy++xx+2ZGG/rOT0fnD9Th+O+DR/X1NtaOIjaJxxFlutHKAFQ05SscA93y4Dn1mbbFrH6+YWQaRxF03MX3J0bcdc4di5nXrMriLGfHDneX5lh+8iBNZN9D3S3mWC5VC6vd3PFP//vrVhlMylEYZhqvBiI04y80vQqmKOyPcnVMC9VmzZqFOnTrw8/NDfHw8duzYYXb73377DTExMfDz80OLFi2wbNky7XNFRUV45ZVX0KJFCwQEBCAyMhKPPfYYLlxw3eWTnG397eQ8zq5gq5Faen/VorikFB2mr8XdH6yzecSF0j2s5XJ1ktnY+zsbfqSPbvdCSnXgXA4e/GIztp68bF9BDAyauw1/7D6PR7/ZbnljO1y7WTZ64H+fbzZ67orEbLhyGjFvJ5pPWaG3jq8lgiBI6h0sn7dsytqjmej75RYs2pmGmauPGc1tlpJlftPxy+gzawte+/Mghn1n/v5or/KGDsOKl9NPWzPnpLmyTP/vKPakZWPw3G24drPQqiSrm45LP/8Mr2PfbDqFs1esa8AUu+4YJseT8r2funQDXT5chyE65/nao46fqnAs87rivbfOsPPMNXwhYdlEtXNU9aWguATP/rIHf+45r31Mjvt4ytk7veeCABy6oNyylPlFJfhinfHQ73K6H3/MzynyF0glvt6k3wiRfjUPLd9ciYFznTPfPK+wGNtOXVH1KEVnkz1QX7RoEcaPH48pU6Zg9+7diI2NRVJSErKyskS337p1KwYPHoyRI0diz5496NOnD/r06YODB8uGKubl5WH37t144403sHv3bvzxxx9ITU3Fgw8+KPdHIXI51g7t0k3AZmuyK7U0fhzSSfh05UaBXeuzGvaoW/sRh363HfvP5eCRrx0bUJf3vl7IyTc5h9ARFS57R2nIbd3tYcpP/mRcoco10Ru1cGe6yd5BcysGTFt2BN/oVGZGzNuFPWnZeOX3A5i5+jgWmemBNzcM/uSlsqHZh6xIVFaupFQw+TsbTu8RICD55BW0nroK0/87avV7OYq5UShSzq+bhSVoPXUVEmdsMDuixNb96/ao5+QV4Z1/zQx3tcKKQ5lIOXsnz4yU83PiHwdwxqCRYMS8XQ4pT7n8ohL0+GQjenyy0SF5WNRyHzDlo5XHcD7b8au+FBaX4vmFe2QbiSOHX3em4599F/QSiRn9fhJ+T2t+c6WPjy/NBOn2UPlhb1F23p0Ojis3CrQjb3eecc4UhZHzdmHQ3G2Yvd663+d6fhEGfpWMH5PPyFMwBckeqM+YMQOjRo3C8OHD0bRpU8yZMwf+/v747rvvRLf/9NNP0bNnT0yYMAFNmjTB1KlT0aZNG3zxxRcAgODgYKxatQoPP/wwGjdujPbt2+OLL75ASkoK0tKUn/vkEpS+QpKs7InL3PXIeOSb7Wjx5kqbX+9p55VS9+Znyrwtp+1K6DX6J1MVd/EjIudWEdKu5GH14Uzc/cFavd4OQ9bmchgwZytmrDQ/6iC/qAQvL96HVYflT2Im5q0lpqc7mPq8xzKv46uNp8wGbacvOT/x0OnL0t/z642nMPjrbci5VYQ5G05afoHCpBx5u8wcu7bSzUtRUGJb4Gqq7PvS7/QkSsn6XuCEfDK6w6vzCmx/v+W3p4aZG7E3S6YgyVq37Gi8NeWP3efw194LeHnxfofts/wQKSwuRU6e7kgxx9yxr0m4PzmaLSto6L1eEPDK4v2Yvd62a9heCyOlnJVbRM2+3uT8VRyST5XNmf9lh3UNXd9sOo3tp69qE+W5E1kD9cLCQqSkpCAxMfHOG3p4IDExEcnJ4sMokpOT9bYHgKSkJJPbA0BOTg40Gg1CQkJEny8oKEBubq7eX0XGISXmFZWUOm25IrXRve/bumyQWu9v9hz3uvOir90sxN97HTvVZl96Nt5cchgjf7C9l0ws+RVg+vdoM3UV7vlwHZ74cRfSr97CY986rrd/55lr+GztCbM9nd9uPo1fd53DqB+t+8yOOr7yi0xnMTZV/9XNdr3jtHNW38iRWIk2VebVR/RHr6nl8q9Ee3H5W0oJcPRWKZKxrCq9XNqsfJiwueSEH1o5dUhNsvMK8daSQ6L5OgAg+5Z8QW/Xj9Yj9u2VyLo9X1zqYWnL/GLD66yUPdgbfBv6MfkMRv+4S3S0WMrZa1i0Kx3vL7dtVJAcWefVkMnekRz9e8rl521n8eka15/KYoqsgfrly5dRUlKC8PBwvcfDw8ORkSE+lzAjI8Oq7fPz8/HKK69g8ODBCAoKEt1m2rRpCA4O1v5FRUXZ8Gncxx47s7a6E7Hhl3e/vw5NJi+3a6i0oZy8Ioz5KcXpvYdW3zd0kyw56z1dgG7v2hMmAsszl28iNcO2+Z2ZufYn6jHF1O9o2HBhatkyQ9ZURsztMyNHvs9sL91PWGriIzz8VTL2WXEtNbyeSD2/Xvndvp65f/dftLwRxBtAtp+6gh6fbMC2U9ZlBjZKmCbCkZVAe4Ld/32+GTvPXDUqs+5ccptLKuFckdLw5IxLquHvseZIJh75epssw8Nd2VtLDuP7LWdE83XIpfwQKf8ttp4oOx8ND69py45g8NxtesfygXM5aPHmCnxv5xr3Uq771qzAUVwiWDw9Jv99CCsPZ+IPkSz9ci+naW3QnV9UgqSZG0WTmho6kXUDH61IldwIS+a9bmEVF1fn0lnfi4qK8PDDD0MQBMyePdvkdpMmTUJOTo72Lz3ddeYOWSPnVhEW7UyzePKrpUdFDS6KBAsZt4OmIxcdl1Tn41WpWH4ow+reQ2cTHBGpuyHdYXCmhoh3+Wg9kmZu1FsWTio5T0lHDOGztfHFU2xdOwDrjmZZzLyuJN1K2j6d7OKGn2a3yNJChl+VRlMW9DWdvAJtpq4y2t6STcfFR0oYklJBtNbAudtwLPMGBs3dZnljHc8t3GNxG3PHVPlzNwuKse6oeD4bW1y7nfhQr7NcAAbMScZ8kePxqZ9T8P2W07I2PoqtYmDIEe+fcvYa+s/eKilbvkYDjPxhF7aevIJJTl62z7msvzbqJlwDyhpon/hhp7bRTo7bptSf/6uNp5B86ore6KoJi/fhZmEJ3rJzjXspc5StSba4xorzWuzaprZq7JojWThmkB3+i7XH8ece40aGxBkb8MW6E5j8j3sHmOVuFZZg3pbTOHfN/PExbdmdKWVqHZmpBFkD9WrVqsHT0xOZmfq9iJmZmYiIiBB9TUREhKTty4P0s2fPYtWqVSZ70wHA19cXQUFBen+u7vCFXL11YQHg2V/24JXfD2DcL7vNvpbHv2lpVmb1lSorV93JuMrpLVvkQkeKI6Yq/L33PFY7YMRDlkHvuKWW+dJSweaeeGdxdKA+fN5O0cctmfDbPtsKYiXdj2sqSZ8pS/YZT4t4TOZM7gBU1fO57IDl7PvmDqkDt4cVPz1/t6SeM6mNUeayPP9hEIABZUtxvrXksMOHgDrqfLem16//7K1IOXsNA7+y3Oiiu9urN13j3mUb+3/XHp9sxOojWeht57J1jlRiahiQHQzva44gNRgTO7/tXRLV3savzwyGWouV56OVx/DCItP3LCmrjijJEfXWuRtPYvRPu/DmksPoOXOT2W2/2ngnSSsD9TtkDdR9fHwQFxeHNWvWaB8rLS3FmjVrkJCQIPqahIQEve0BYNWqVXrblwfpx48fx+rVq1G1alV5PoDCsq7nm+x1uv+zTej84Xq9xzbcHqpnzRI0pO+eD++sLe9uF4rTl2/izOWbWHkoA9duFmLd0Sy90Rc5eUX4eJV1cwePZV7H5L8PynITt0bijA127+O5hXvxxI+7RCvlHhaulIb36CMXc7WNPkstDD1+f8VRzFh1zOjxKf8cwhUr19Qe81MK9hj08ko9jItLBYxdsNtoeTHA9mHKjj6Ffksx7p2Qg+7vmaFzbBsuWShW2TPMkO9mlxGn2nBM2mgCa3y8MhXnrxk3aphbhm/LCeuG/ltyNEMnT44dB8iinfqjA1cdzsTkvw+anXpwy8rEdO44lclRrucXodDgu75s5TVbCsNDpLxuIuWnsXVEleE0vQsyTFW6puDSnqbuabn5RXh/+VEctdCYNmPVMUWmb9m6bK4tkk/af917b9lRbUziqFFfv+5Mx6gfdzn1u1CSl9xvMH78eAwbNgxt27ZFu3btMHPmTNy8eRPDhw8HADz22GOoWbMmpk2bBgB47rnn0LlzZ3z88cfo1asXFi5ciF27dmHu3LkAyoL0hx56CLt378bSpUtRUlKinb8eGhoKHx8fuT+S0wz6ahtOWZHNl9RLqaC//FaUc6sIXT9ab/R8w+qVsWp8ZwDAG38fxD86vYEmOkP19Jy5EaUCcFLC8kilpQJOX7mJetUCtJWHWetOIDLED31b17L8ZmY4sjdx2ynjJGEaaFBYXAofL/GIXfemf+VmoXao8JnpvfQr5SK+2nBK9PHr+cV47c+DmDM0TmrRsfxQBpYfysCZ6b3ulN2KY+/f/ReR1CwCD8ZGmtxGEJRtxHL2W+v26Br2mtgTw0itQDsr+7CzR9BYqmQ9L2H4vC0+X3sCn6+1Luv4SzaO5Ph5m2NWojEVVMzbegaD2kVr/10+taph9coYmlDH5vfTPeTcOVDvO2srdr6eCD9vT5te/8PWM0aPmcqUXVhcins+WIcODapixsOtbHo/Q6ZHVLhG8+CbEofji34aO4/LKzfEGwneWXoYv+46JymbvL3LGJb/fBuOXcLfe8/jzQebIcjP2+T2G49dwmPf7cCEpMYY27WBXe+tdubuRy/fztvyY/IZjL6nvrOKpBjZ56gPHDgQH330ESZPnoxWrVph7969WL58uTZhXFpaGi5evNPj1KFDByxYsABz585FbGwsFi9ejL/++gvNmzcHAJw/fx7//PMPzp07h1atWqFGjRrav61bt8r9cZyKQbrytp4QH51gbcugMys7YvV6sR4kADieVRZgFxaX6gXpZfuxfLMvz3dgbu3n3Pwi5BeV4LW/DqD7xxvw9e01qI9czMWHK1LNDg1Ti7SreWgzdRVuSvjdLU2fEARBchZeS0G+KUO+2YZXbi8PJHbDMzdkVspnlMp1l7gR/34MfzYpQ49NfQdSe2PkmHuuBpZGfv1lxcoKN/LVmZQpNdO+Ie5Z1/Ox64zp1QVMHlsWRjgVFpdKHgV18tINJH2yEUv3O3alCzW4XlCMv/caT3mQyprRCYt2piEjNx9/7Lb9/aQ6dCEHk/44gEvXC1wkZLeevdNRTPWYHzxv3T13y4nLSJyxwezypqaUf4Zh3+3AH7vPY8ZK45F1uibeDlBdedUEUwzvpaaqDrqjrD5dfRxHLhr/Xu6WfV/2HnUAGDduHMaNGyf63Pr1640eGzBgAAYMGCC6fZ06ddzuR5DDmiOZ6N6krDFk2YGLCA/yQ1ztKgDcb0i3nFaamLPcfMoKbJvUHbvOXoUgAA+Y6YF0BX+ZqKzMXn8SRSWleLZ7Q5v2e7OgGC3fXAkfLw/tXN9PVh3H6Hvq25R0TUk3CopNVlZ1L0kv62TpLi4pNQqU605ahvphAVjx/D3wsneBdhPKhupewfsPtRQ93/vNNt2oKXZ5qGiXXFPtKI78HtQ0p9waObeK8PaSw+jbuiY6NaymdHEAlPUsuxKph1G7d9eYfV7KqCcxD36xGUczrqNH03C8cG8jNKlhOm9PQXEpUjOvY9wCeUY4KK3Ygdl1zQ3lNpeMTRAE5NwqQoi/+IjQzNx8vLVE+vrQ5SNGLl1X78oa9nL0PembTacw8K4oq8J/DTQY8k3ZsqYnsiyPKjRk+Bks3ROcfRt2Zqxg+F2YeuthOvlebhaW4L5Pjee970nPRpvoKg4snbJcOus7mVa+HvOxzOt4ev5u9NepmFekSnf61Ty89ucBnL58EwfO5eCJH3biRJa0Xo7svEKzFcA/95zHuAV78Mwve5Ar0qOzO+2adr6vlAvercIS/L33vEOX7JDaqJUn0mtXWFyK95eXzZ9OOWvbmtHHbvcoiSXksnWddiW98rt1GZCHfiueROzkpZtOGzEjdgjsSct2ynvLseyckoeNrWv2WktqpndHm7PhJLp9vB6XrpueZ/vhiqP4ffc5PPrtdieWzLyiEte9qdlzOB+6kIsnfzKeqzlr3UlMXWp6WHF5b+LKw5miFd2KpLwhNf1qHq5aOWfa8Nra2syqDuaSnw35Zjtavb0K75j4zcb8vBvfbzmj99jilHN6o1LWpRpnUTfMQm6K2u/Ef+09b1Rvc3Q99p1/j2DKP9IbQ+Rg6TOZO4YEQXDZxl8AWCyyBJ+t3G3uOgN1NydXFnNXMey7HZi/PQ2D5ibjgS82Y/WRLAz7TlrG6df/NL90hu7FIF8kM3G/L7daNURp8t8H8dzCvYh9eyVe/dOeJXGsv+2KXf5LdG4K/Wcna9cyvXKjAJ+uPm5xqQ1LZOpMVpXkU1ccGlhezLmF95YdQfpVad/9C4v24oEv7F/v19ZK0aC52/D1RvE5+Gp2I1/Z4eZDv92B4d/Lnylel0YDTP/vKE5duonP1x43en75wYvoOXMj1h1VphHBlew6cxXjF+11ynutOJSJn0WSzn672b51syuSS9cLcPcH60wun7jt1BX8lHzGqOH7SwnzmMuZu4ZuvZ206xsrfjPDvAnDvxev10i5/6i9mWv/uRwkztgIAPhu82mMnb8bxQaZ7cWSoFpr8/HLokOpTfllp2NyUNxh/pcwdwy9vfQwOk5fix+Tzzi2SGYYfuf2jHZ+efF+yxtVUBWgqlyxyXUBLi4plSW7qbX+2H0OY+fvNtmCVt5rmamzzIRuq2Pr6BCT+7aU5VTKd/uVSJDye8o55OYX4b5PN+HDFXd66HTXZ12wPU3xuamGvexzb3+W5xftxSerj5lc5ke3YiA2h7L8IXvnL3+z6VTZDdsBN2h7mbs/lS81Zc1rTBn+/U7M3XgKQyX2Zhqu+esI1hb7XZ21UV3FmSvSRjtI+Q0v5tjWy7Eu9ZLREpy2svZaknOryKjSNebn3Tiacd2le23kIFY5fWhOsuhyb2IckcchV+GGJVe34pD55QQHzd2GN/4+ZFcWbMPs8Ka89Ns+Tu804bdd6Xh76WH8e+Ci3moqL/66D7FvrTQ7EkgKa791KQnnzL6fUc4T89ubm6VRPuJi2jL7R32ttHA+AGWrAjR47T8svr0Sy6XrBej0/jp8ZKFzSmrc4Lr5bRyPgXoFc/LSDaOkYYZybhVZnG8z4KtktH1nNQ5dML2kjTOM/3Uf/j1wET8liy9jZ4ld90MrXrzj9J2h4y/+tg8Pfr4ZRy7mYta6Oxd6w7lytt+sBaP/s3TNE0vstOao8VC6j1akarc1VWHXX4td3KXrBXj2lztzHm35rO/8ewT/HrhoMo+AM5lLbLM+1fYeSAFlieGe+GEnBEHQDlk94+SRMo5eR1rtpB6OUr4XsVUEpCqwcg13U5pPWWHV9n/vvYAnf0pxyHu7q5y8IqScvYb209Zg3hbreq/3n8vB8oPmK8NOD9Yc+HauNPRUowFe/8v86LlyaRJHMhnKyMk3Wu7MlMUp5xy6vrY7xTsTdHpddRsff999DjcLS7DI4T3czqV7CoonnL3z2PdWXnPKSTk33zPRuK6baLZ8hYnykR0/bzuL89m38MU68ytqtH1ntaTOldOXb+KZX/bgAhuGGahXNN0/trze9F3vrkbijA1mM06Xz3F1RgZTKa7l2bYe5970bPyecg5Tlx5GtpX70L2O/rIjHeMW7BbdLu1KHq4YzH1zdqB1zkTW93JrRYJyQxqNxuRFONvKefVv/nNIr0xS8/nsPHMVby05hLzCOzcMR2Ypt5UtdWopQd7F7HxsOXEFq49k6S0T5gwXc25Jzk7vbqR+6gNWZgi2lpJ1bDU0gEmlRC9/7Nsr0X/2VmTmFugtMzVynrSpVWN+Nm4I+WbTKW2Abs3QdbXFYgPmJCtdBIfRDRQsdXKY8v1W64Kq/KJSswHVcwv3St6XqWWuCopLUGfiv6gz8V9VjI60lljeG3t7YeVqG5u//axow5vhdat8m7kbT6LFmytw2GA1Hd3P/NaSw7h8o8BoibhbRSX4adtZ0XrR9fwiNJ28XHK5DYvcbMoKXMi+JZqTydz8eUOGqyWI7Q8Aluy7gPG/7tX+25H5m1yJU7K+k2spvxhsOXEFMRGms8ECtmedVZMXb7cIZlk5bEo30PpktellNe75cJ1N5TJ10zG3nvftVxo9Ut76aQ3D31bqT627NJCp+6bhDapUEOAp4R3KK4C6697aWnlyJDmSpgGAp4cGuH1P+8lgHqpcvVYaTdlKEU/P343erSLxv5aROFPBlopcfvCi5Y1QVpGQkzN7w9zgUq64klJBdCSSVO/8ewSNwgNxT6Mwq+Y/O+Q40dlHfzOrQkhharqPqykuKUWH6Wu1/95q5dD37zafxoIdaagR7GdyG7EEdnvSr9mcwFWqNUfuHKc/2jgiUUliv4WpgM/QayZyAMnVYPHanwcRHuiHxKbhZrcrr1G+d3v4+ht/H8TvT3XQPm84xaXtO6tRM6QStkzspvf4G38dxFWRdeK3nboqqVPE3LKDuueDrXTrtutTs/C4ifwKAHDmch7yi0rg5+2JWevN99Zr9+9mdzP2qLu4SX/s12bWFqPbiie18mmNs26UrM7aYfyOan09cjEXY+cb98aLXWreWnIIjV7/T/L62vaU0das7PskDNsz3LVYa+zilHP4yURilKM6CV8srcfsDN0kjFSxhe73NP0//blnSTM3yvKeggBtK/bfey9g1I+79OaZf73plMnfxZwbBcXYduqK3b30V2/K36pubiklZzp92XnX14o5dkJ5hlfZ8kZMa4a+r0u9hBI7zyvdUVEnL1WshjlTrFknXczbSw/jRNYNs/eoV/8wDho/WJ6KjyysqS2FuVt4kQpyuzjaVxvK8uisOZKpnW54o6AYKw5lIL+oBIIg4KmfUzB/u/OHyB+3Yfk2KUyNJsq+ZRyoS72mZOYWYP72s5IbAJ+en2JVo7WHmXqNoYzcfMS8sRxvLTmE6xU0Fwd71F3cLzvS8cfu80h95z6L24752TgYvFlQjABf8cNASm/5ysOZOHAuB4F+XqhTLQBA2bJmM1cfx0NxtdC8ZrDlndigtFSAh04BHVLJtHInjqrY9pm1RXQuqthFsjxhyGdrjuPLIXHax3Pzi/D0z7vxYKtI2daPtCZu33T8EhZsTzNZQTHclUECV5SWCtq5T/c2jUCEQY/EOjvmfbsLuRrJJv99yGzio/Iba1LzCFQPNN1TZGjQ3GQcPJ+Lyf9ralf5Hv7KfYbVWmLLSBiqePalZ+PbzbavrnAs8zp6fCJPw5/aKdH39vXGU6gS4IOH4mrhsBVZxq3lTh0pUl3IvqVdnnjbpO5oP20NAGBwuyg8060h/rOQG0JNUs5eQ05eEYL9ve3e1/X8Ioy2Iu/Ia38eNDsSRNeyA9Z9p7Z0An2/5QwGt4u2+nXugD3qbsCehEOPfWd6CSCpp9IDX2xGl4/WY/3tdTwn/30I87aewf8+t39ZKDEbj11Csykr8JeDM1o7KnGTo963sNh0Zv2ColIc1xlJMXv9SWw+cRkvL97vsOGyts73KiguxdBvd+C/gxmi2aY1Ivs27FHX/dfvDlxfU03UmthXanbidu+u0UuSaMnB2/O5nbl8DJEzpZy1fiSG2GVWNweHVO/Zke25ogbpgOkG6Ov5RbgiMnzYEd5ddsRoeTVyjIs6q/U888udzqlFO9OtmketBLHizd5gX2b5cr/usr4eddHCykfOp+7fTy4M1Cs4cxULjUaD4pJS/LPvAjIknLDl80zkbCEGyhoXbhWV4HkHr1NrbUIiua/53T7egLbvrBZdM3vN0Szc+8lGbebg3Fviw4F3nblqlGzEVo6cL2u4q7eXHDYZwO0/l+24NyaHsqV329mJFEka9VXKXMvWk5fNTkMTIzYUddIfB9B08gpcc1DipL3p2dpGdJKuxZsr0eWj9UoXw6F2p13D91tOI+dWkUvOS5fmzjl1SCcZmwDbs/bLyVKj3K3bz5urx0lZflNNiWFtnVZZUXHou5sw1Tor5dQUBMHketfztp7BO/+WzU/t17omZgxsZXF/SlwQlGgoPXdN3ot+eZKZ9ccuYWj72qLbLE5JR8/mESb38cg32/FgbKRN7+8p07VUo9EYXagX7UoHdgGPJdQp20bnORXdXxxKyjHr7EzvcnFUYxGRWs1adwL3t6hh1WtaT12Fzo3CZCpRmT6ztsi6f3Id/b4sSxL4ls4qBe7G3PKwE37bD6WtM2g0m7pUfym0k5fE57J/s8n0ygF3vbPa6LHyaZLl1BQbT/rjAF7v1QRVAnyULopLYI+6m1icIj6sRUpm6Ni3VmLjMeM5vxoAG3Qe/2PPedSZ+K/F/ekOLzp56YZo9tLc/CIsO3DRpdZbNbR0v+OT84mSENHpXoQN15S3lBXd1G9q2Hhz0IFLUe04Iz5kunw4v+En/m1XOnp9tslh768G93+2SdJIFXfQ+HXpS8IQuSJBgNUJ3bLzivD3XuVXrSB9n6yyP5EbKUM3AaBuHUYQYPUSvHJ43yB52i879BPbiS2hfOVGAT5fe9zkPu1Neuhsv+8+h7eXWt9Y9KfE6a5Z192rXsVA3c1JWW8zN79YfK66SM+nFLp1le4fb0D/2clIMxjuOvrHXXh6/m6bTtaK6sA546z05Tci3Vh+3tYzTiqR490rMlcyO68QExbv1xvG5i7KE90QkWvbevKK6FJbpG6XReahf7rGdFBE6jb02zt1WcPaqxoG52XbMKWl56ebkF9kXw4lw6XdlHby0g3kF5XgaIb06UJSvwMpcY8rYaDuxmZbsQ4rADw0e6vekh1nLt+UvC6lLrGEHQsMWg23nSrrUV1skODiVmEJ0q7kYU/aNXyz6RRuucnQX3vtTruGB74wTs636nAmAMiy3IhcQ6WkzKfSpZalsojIWGFxKTYdv4QcE3kyKpK1dqyhLodJfyg/1FftPlyRqnQRSC4GdRilp5Jl5OQjI9d0b69YQ4JGo8Gl6/av7/6ZyhqfDl/IRcwbHGknBeeou7H3l1uXBXbX2Wt6FY1vN5ueE2OO2Bz1EsP1t27TDQYPX8jF/QbDmy9dL8Ck+5vYVA53sWT/RaP5Rroe+XqbLO+r8gSpRKSw4pJSNHr9P+2/m9QIwoks6xKquZP9IqOelPTLjnSli+ByUq3o4bPX0/NTbMrwT9Koad3tUkGwOIIuI8c4obHUtc9dTbG7Jh+SAXvUSY+1c+wMzVp3AhdE5t1+bSIRhu67zVp3wuj5nSbmMhvvR8CetGvoPWuL6Jx4V7bj9FWcunzT5PNbT16R5X2n/HNIlv1K4a43JyJ3Ypgp/sjFXBSV8Nwl15U003lL1S07kCE69J7cz00JIwmPZYonkqOKjYE6OZS1w8g0Jv9Rxpo58g9/lYx96dnoPzsZQ7/dLunCSEREREQkly+tnIpa7ge3XUaPpGKgTnqWHXBSJnMRYkG5NYG6bk/OpuOXXTqpGhERERERVVyco056pCw5JjZE3RHEQvJDF+7M+SsuKTXduigy2tKWRHhERCSNuSWDiIiIyD7sUSerOTJLakGx+eUWbupk6VywIw1TrVjOraiYcyVd1TUbljAhIuf61WDVDiIiInIcBuqkuPSrZWusn72aZ3Y7sXXEzZm31bas9aSsv/eeRy+D7P9ERERERBUJh76T0204dknv36cv34Svtwf2pWebfZ25/vGvNp4yeoyrP7im5xbuVboIRERERESKYo86Od3fe8/r/dvTQ4N271paXzJfdH12IiIiIiIid8MedXKa9Kt5qFWlklHXuKXM7utTs/D49ztlLBkREREREZF6sEednObuD9aJZozfa2HIO4N0IiIiIiKqSBiok1N9tPIYTl66offY+8uPKlQaIiIiIiIi9WGgTk63z8rs7URERERERBUJA3UiIiIiIiIiFWGgTkRERERERKQiDNSJiIiIiIiIVISBOhEREREREZGKMFAnIiIiIiIiUhEG6kREREREREQqwkCdiIiIiIiISEUYqBMRERERERGpCAN1IiIiIiIiIhVhoE5ERERERESkIgzUiYiIiIiIiFSEgToRERERERGRijBQJyIiIiIiIlIRBupEREREREREKsJAnYiIiIiIiEhFGKgTERERERERqQgDdSIiIiIiIiIVcUqgPmvWLNSpUwd+fn6Ij4/Hjh07zG7/22+/ISYmBn5+fmjRogWWLVum97wgCJg8eTJq1KiBSpUqITExEcePH5fzIxARERERERE5heyB+qJFizB+/HhMmTIFu3fvRmxsLJKSkpCVlSW6/datWzF48GCMHDkSe/bsQZ8+fdCnTx8cPHhQu80HH3yAzz77DHPmzMH27dsREBCApKQk5Ofny/1xiIiIiIiIiGSlEQRBkPMN4uPjcdddd+GLL74AAJSWliIqKgrPPPMMJk6caLT9wIEDcfPmTSxdulT7WPv27dGqVSvMmTMHgiAgMjISL774Il566SUAQE5ODsLDwzFv3jwMGjTIYplyc3MRHByMnJwcBAUFOeiTOl6LKStwvaBY6WIQERERERGp3pnpvZQuglnWxKGy9qgXFhYiJSUFiYmJd97QwwOJiYlITk4WfU1ycrLe9gCQlJSk3f706dPIyMjQ2yY4OBjx8fEm91lQUIDc3Fy9P1cQFuSrdBGIiIiIiIjIyWQN1C9fvoySkhKEh4frPR4eHo6MjAzR12RkZJjdvvy/1uxz2rRpCA4O1v5FRUXZ9HmIiIiIiIiI5FYhsr5PmjQJOTk52r/09HSliySJRukCEBERERERkdPJGqhXq1YNnp6eyMzM1Hs8MzMTERERoq+JiIgwu335f63Zp6+vL4KCgvT+iIiIiIiIiNRI1kDdx8cHcXFxWLNmjfax0tJSrFmzBgkJCaKvSUhI0NseAFatWqXdvm7duoiIiNDbJjc3F9u3bze5TyIiIiIiIiJX4SX3G4wfPx7Dhg1D27Zt0a5dO8ycORM3b97E8OHDAQCPPfYYatasiWnTpgEAnnvuOXTu3Bkff/wxevXqhYULF2LXrl2YO3cuAECj0eD555/HO++8g4YNG6Ju3bp44403EBkZiT59+sj9cZzq5KWbSheBiIiIiIiInEz2QH3gwIG4dOkSJk+ejIyMDLRq1QrLly/XJoNLS0uDh8edjv0OHTpgwYIFeP311/Hqq6+iYcOG+Ouvv9C8eXPtNi+//DJu3ryJ0aNHIzs7G506dcLy5cvh5+cn98chIiIiIiIikpXs66irkauso15n4r9KF4GIiIiIiMglcB11IiIiIiIiIpIFA3UiIiIiIiIiFWGgTkRERERERKQiDNRVrIq/t9JFICIiIiIiIidjoK5ilf1kT8pPREREREREKsNAnYiIiIiIiEhFGKirmAYapYtARERERERETsZAnYiIiIiIiEhFGKgTERERERERqQgDdRXr2jhM6SIQERERERGRkzFQV7FqlX2VLgIRERERERE5GQN1FdMwlxwREREREVGFw0BdxTSM1ImIiIiIiCocBuoq5m5x+k8j2xk99taDzTC9XwsFSkNERERERKROXkoXgExzt3XU726onxxv26TuiAj2AwAkn7qCv/deUKJYREREREREqsIedVJMeZAOAMWlgtltPx3USubSEBERERERqQMDdVKFwuJSs8/3blVT+/+NwwPlLg4REREREZFiGKirmL+Pp9JFcJqiEvOBui5PD/eaEkBE5GoG3RWldBGIiIjcGgN1Fbu/RQ2li2CzgW2jMM2KJHH3NY8w+VzNkEp6/3a3JHtERK4ovm6o0kUgIiJyWwzUVczH03V/nvcfaonB7aIlbz8gTrx3ZubAVljyTCeTr6tbLQDRof5Wl4+IiOzzxSNtlC4CERGR23LdSLACEGA+wZqa3N2wml2v9/DQ4OG2tfQeC67kjT6tayI0wMdo+96tIgEA84bfpfd4L4NRCF0b62eaJyIi+2k0QFigL4L8uHgMuY8h8dI7GIhIffa8ca/SRXAoBurkEC1qBtu9j8cS6uj9u0fTcNHtGocH4tNBrXFmei/Urhqg99z0/vrD7e9r7rrTB4iI1M51mpOJLIutFaJ0EYjIDlVEOvdcGQN1cghLlbX6YQEWtgAEg51MebCZ3r+XjOuExzvUweQHmuo9bnbOusFz7etxTiUREREZYw4cIlITBurkEKWGUbYBKb0uukP95w2/C5V99YdUtqgVjDcfbIYQf/3WMnP31VCDbRc80V5CSVzP/1q638iBxzvUMfs8h9wSKY/z1MmdaNw4Unfjj0bkthiokx5LwZEpFuJ0lJZaDtV19+HnLX1pujNX8u7sw+C5huGV9f7trjeqp7s0ULoIRFQBdW4Uhld6xihdDCKHcNMqAgD3/mzuqFF4Zfw4op3D9nd0ak/sm9IDCfWqOmyfJD8G6iqmUeCy2jQyyKbXCRYidQlxul6QzbXSpRnXtQEOv51k8++mtAdiI00+Z6lRhXNjidTBz5tVCXIP7tqYD1jXAULKW/lCZ9zTKAxhgb56jxv+Wyo/b08EV/LGL6Pdc2Spu+LdVcVcKeu7pUDc0tB4Q142BuqGrzJs7FDzsLYpBnPvpXgpqTH8fcqGgNep6nrL1AX42FFxcJ3Tg8itqfeqSmQdFVcR7OZvz/2WFBMXXUXv398Oa6tQSUgJDNRJT1SVO8Hed4+3xfqXukh6XSODIeblGlYve/z+FpbnUOv2ytvao64bu73xv6YuddP9X0vTvctSrHyhs4NKoh6mGi844IJIPdTcAEpkDSVGMjqPO38203y9GOqQ6+LRq2JK3DAS6lfF1N7NsGBUPLrFhMNDYgXsobgo0ccXPZmAzwe3xvh7G1lVDqnvCwAh/t6ijxuuqa529tZ1fVzwZmTpMw/vWBefDmpl9PjBt5LkKRARWX0tYZxOrqxa5TtDiYMridcnbBETEeiwfZHtDryZBB9P16sflRvTpb7SRXAZjcPd75xz3SOXHO6R+GgAwNCEOuhQv5rZbSv7emHOo3GoFxaAn0a2M9kDHhrggwdiI62eG2VNj3qAj3j2bwGC7OspPttNuSRuXw5x/WzL5nriyhuqereqaZTV3t/HiyPfK6hKnGcpuzXjLY/OCa7kXmvVUsX0YGwkmtS4U7lv5qL5XqSKrRWsdBGczsfLAx4KRzt3NzRfpzanVVQI9r/ZQ/tvVx/1ERboi3USR+tay8vTtb8bMQzUCQCw4Il4vPlAM6PHdeOoXjrB0sNto9CzeQTWvtgFdzcMAwA8270hAGDifbZlANYNvKzpUdfdNNDXCwn1qiKudhVEBPkZLfHmaPYGi7rZN625vCwc3V7SdAI1q1stAP1a15S0ranGGHINdasFOGxfu9+412H7ImOrx3dGVKjpfBcPt62FLo3D8HTXO7087lc1Int80L+l0kWQTK7RIAn1qiI8yE/y9nLlmNFdyUejAZpGVrxAHbCuTulo1QN9bU4AVy7I785ID8NRpJ8Pbm3XvpUg169hZTosl8BAXcU0En+dn0fG2/1eHRpUszjc8bX7m2DzK13xdu9mmJDU2Oj5FxIbInlSN4zpbNswHd0TzNZRShqNBgtGxWPxmARtb+07fZoDAFa+cI9tOzXD384AMqiSOgJQUwFzeY4BOax9sbNN31/b2lUsb0Sq8X7/Fg4792qGVEIlJkSSVQML53zf1rUwb3g7vYpjdSsCEnfzycBY1KpSSeliqEaLmsGoFug6oy3kChgWjIp3aCNAPRsbO9988E4HjCMbTF3NnEfj4OWhwfR+LRR5/9haIVZt379NLaPH5jwah/f7t0BUqD+q3w78E5uEm109R43kbDKxNnG1K2CgrmK6FSFzOtkxpMYaGg1Qq4o/HkuoI1pZ1mg0qBFse4VF9wSzJzmRRqPRe/2j7WvjzPReaOTguSt3N6yGYR1q27UP3WuKNZ/Z1JaWhu2ZGu0wY2ArbJjQxejx+aPibcpGb6hL4zCsfbGzXiOORqNB1cp3KnS/jGqPWY9YHs4/f1RZw5Ru8kFXnJ+vNoF+jm80iokIxMC7ouHtwvMDybJ7m4QrXQRJos2MFLBV39a1ME2hyr+h3W/ci6m9jUfGmVIvzPGB289PxLvU0Fy5EiGa2u/AtuL5fMzp3CgMXz7aBo3DAzF3aBy+ecy2rN8Vec78PY3CcHRqTwxqF63I+w+Jl/6+j7aPxscPxxo93rN5BAbeVbafP57ugAlJjfHRAGVHr4jlELJEgPSRLNZcz9wVa09kljNHC+kGra6Q+OOnkfF296jbylQlYMGo9vj6sbb4fvhdGNmprtl9GKYBqF3VuNJWPdAPwzua348lMx6OxWeDW6NeWGWjnqfwID/MeqQNfhjRDgn1q+pNr9D9iLpLFfp6GTcS6U4hIPWIDHFsT2Of1s7tOTDMjeDuujYOs+l1Hh4aPGHhekPyCw3wwdCEOiafXzKuk35jhQydT45MxuYMhndSL4l1D2tHUWyY0AVrX+yM9x+yPrAK8fdGTEQQVrxwD3o0i7D69RXZ32M7av9f6m/raIKV7+0lYUJ9rSr+GNu1AUL8yzo7lKoz924lbfqiIbka792wQ52BOknniFZycy26ugnkzM2RdFeOaBMJruSNe5uGo2vj6njjf+Z7wj8Z2MoB72hZvza1zI4O6dWyBjo3sj5AGHVPPQDA/S0isOHYJZvLR67jue7WrR5hr9G3j7GKwp7rritkfrd3nqgpSs5/tUaLWsF4rVcTpYuhKoaN3qEBPni6S32M69oAkcFlUzrEgqAIK6d71K4agHphtk0lq1fNMVPQDI/SAXG1MMLOhni1i40KMXqsRrD7TdVp4mJJECNDKuGxhNp4srP5e6y1cbfghmmGGagTFo9JMPmco4eFmRuibOva2C5SRwJgnLHa1rJLfV1Vg6z3uq2NXWOqw9tTg3Z1Qy3up0kN598ELH3EZ7s1xF9jO2LmQNdLpOIoYrkiXMHiMWXLNnaob91ICE5xkFfVgDuB7JaJ3TD5dmOfbk+7qWuPK6ylbk9+i0NmloRU8pOHWrmyyZUbhdr/l1ql1V2+zN2IHbYv94zBS0mNseHlrjjydk/4eRtfd5wVDozpXN8omLH1VKtdNQCPti8bOn13w2r4cEAsYqMqXnK5BCvvO5Y8FGc8n1yXM64PD7jg6K+3ezfHpPukNxz6Srj/l7pfnM5AnYC2dUwHaroXGFsDaVP7M9SyVghaR4fInhjjhUTn9srpGmwwP0p/jrr0/Ujd9NcxCejUQDyHQZCfNw6+lYRFo9tb3M9PI9tJL5ydyrPf6g6DFxtC7eGhQauoEJcN3qztkZHDppe7av+/S+PqTnnPN/7XFG3rhOKB2Ei3G6bm7eJLw+heg2qGVMKITnWxb0oPfDvsLu3jrvibNYsMwgcPtbR6mdBycbWrIMDMCiK1bUzSZcv8Tnvp9jgJcv2Yrn0aaHl7ephMXinbd2dg4n0xNh+35RaObo+nu9THo+1ro1lkMPa8cS9+GO68e7ojPdy2Fv577m6li6HnibuljUpY8EQ8Bt1lOUeBLSN0hnesi+8fv8vyhi5MyhnnrPPSmVyzhkuKcESPyfT+LREW6Iv3+hon3/H00ODPpzvKvtTEc4kNJfUiW8uW4VRS1nyc8kBToykDMRJ7uOuHVdZLdGQ4LMjXy1PS72rYo/K6jMMnlz9/DzZO6IrW0Xd6v568pz4Gt4vC98PVfSMKsiIh26ZXulreyAJ7T0ndoc6JTapj8ytdJVUketnRel/bjae1mJuf+++znZxYEtuI9VgEV/KGh4RWWjXHZi8lNcbDNiTxKmep8lczpBJ+MzMyzZTuDkjC1/F2Q6ypYf21DZb90v0opj5VpMG97EMb5lW7imqVfW1qfFJjOPDRAOMEZADQvl5VvNwzRtuoXSXAR/Sctmetb2f54KFYoxF+rjKyrEODapgsITmvLfd1Tw8NusbI39g+Iakx2pnp3Cvn5aHBrtcTtf+WmrjScNURa89NNZ6X9mKg7qYclSlR94LhiJGNTWoEYcer3fGIFRkw5XCzoNjh+7Tl64mtFYLOjcIwJD7aZA6A4R3r6vUaH3izh+zrw5vTu1UknrhbfyjeXzoJW8yRchH18/ZEtEHlspKPJ6b1a4muTur1tZW1mfvLhyHaYvL/mjokb8TiMQmYdF8MHmgZiVpV/PV6bw6/nYQDb/bA2wbXkx5NpQUYrt667cjiN1P5+sWto0PwaHvLq1iYOsRdYd6nnKPz75JQeZXDu32bY9J9MZKvwbpJ0Ibe/r0NR119NfROVvHUd3o6JQBQwn3NIzCuWwOL24ldBqRcG0xts3ViN9zX/E5SuF4tHDNsua/BMqtrXuxs1et/csBSv85SvkpJYpNwjO1q+Te0lamRb5N1cgA5OjGapSUylST2XceLdHxFhfrrdfCYGyVwz+0cRW/3boZVZpZylXL5dvEqhygG6m7Kw0MjutyWoccSpC8v5qiEOWqYy2hLZtp3+zbX/r+XI+YBoKzi+MOIdnhXZISB/nZ33i9Q4rJ9chG7ELYySNhSfuFNauYayzYpRXdOsLVGdKqLxCbmK9BSevjb1gnFk53ra3tYdINrfx8vBPp54zEzmaStZdgIU+7Z7g0d9h5q4wpzfP98uqPZ4d2WPBJfG48l1Ma3w2xbOsoelparUv6OI58gP2882bk+akpcYaGNzjz9ER3r4s+nO+Abg9+sRa1g/PpkAja/0lV0lY0/n+7gUrlhTJn9aJy0Rm+Re549S/1FhlTSy88xY6B4T7i1DKsl9W1MXucKlj17N17pGYNPbPjuGluxVK+p43xEp7p4qkt9DLoryuIa93odXmauRr8/Vbbkmj2jf5Qw4vaKH7qr7xg20outC1/u68fisPSZThjavrZeXbdReGXJjf3lDZBjLCSnc0UM1F2cuYp47aoBODO9l9nXW1rSQW8OtVUlcx5behUHigzvFcsOqmtI/J1GDbFkJHY3QJh5eXWZshXL5YXEhtgwoQu+HBKn93iAifl+avd0l/qWN7KSIxqsGoYHmpwq8kH/lvhRRT0kf43tiDmPxqGRiUrS+HuVyx0ht4fbmk825EpM9TD5eHng7d7NHTKc2xqPd6iDxKbhmHRfjGzvIVfjstwjThaObm90Wwny88a+KT1wdGpPeHho0Dq6Cvy8PbUV6d6tynLEtKsbilpVxIPR1tFVHNZYrQa2ZIpubOea5LrHlFhjiDVSXk/Evik9bDpO5VomS5fh9Atdr/S07byNCvXHU13q29RxMbxjXdFcRWJJc82doq/0jMH0/i0tfu9STvP6YQGIq10FY7s20FsBSZUMipfULALrX+qCH3VyGRl+5PAg03VYXy9PNK8ZbPQ9emg0aFHL8ki01ePvwYYJXbHupS7adebdCQN1FxQW6IvFYxLQtnYVLBglnghM6v3f0nVddzeusgSNFGINFFN7N8NPI9thwRPxaFc3FB/0N56XVz5/V2xpMymVLlu/wnf6NEfnRmH47nH7equkHhdRoZWw9BnxObVSqzS1qwYY3XAeiI3EvU3DZZ3jLoeXRSoTY7saB+/W/r6OqKZ3N9Gr/vBdUajir541jVtFhaBnc/01gKXkaFCStb1m7jjsrtzC0e0x65E2qGNj4jS51JVQHldNOGlvLhVTa30HV/I2SlD2bt/m+GFEO7wvct/TJZYBncSZux8Y3hv9fWwfzVK1sq/RKEGpv1Nik3C0rV0FoyQmRLPFH091kG3ftvDx8sBzicYjuN7u3cwowaPURhypiSENj4noUH/88XQH/D1O/TlMyoWIjEitUy1Ar9HH8F4YEeSnPeZja4WY3X/s7eD8obhaiKtt+RrYoHogPD00ku4FrohXXBc0+K4otK0TisVPdUDzmuKtTbrnyPwn4i0OzTFFN/jUqPRoeblnWSIRa+b7it1Afbw8cHfDMHRoUA2/PpmApiLrUk7v3xKnp90v+1DW9/q2QN/WNbVDOsOD/PDDiHboFuOc3qr3+7c0eWzZw9vTA18/1tZojrsrmpCkH7xvmdjNaaNOdI91sQre+/3LplI4MkmSboZ4R3nrwWaIDPZzWE4NR6ti5dJX7qx9vaqSkwg+K2Her72qVS77be69nS/B3KHevm7ZCChH5HSQ21dD74xC+vXJBLOjkEwl0Vo0uj2+GhpnskdcjJ+3Jzo3CrOYYbx8RIUrfJeOIj5H3b5WuQdjIxEd6o/B7coa/2cOaoUG1StLCvjMNQD8NiYBsVEhWDRaWnJDHy8PLH6qA17rZT7JWX2JycDEVFX51J9H20fj5Z6NRfNMvHq/tE6F3q1qInlSN6vf20MDtImuomjeIWtNfqApYqNCzB6r5Q0c3w5ri1d6xiChflWseP5uPHlPPXxgITnl/FHtsXB0ewzvWNZ4VJ4PQIlVMtTAdY6MCqpfm5r4Z+8FFFtYHHD7q93x2p8HsfpIptFzHRtUw7/P3o0mk5db/f6uMPT9fy0jEV+3qrbi5ihKrhfcNSbMYQn3dItrT+WikrcnbhWVoHOjMNHnfb08UFBcavP+XZ3UOaK6bD2S3ukjntPggdhITO3dDCH+jg8wo2yYk2npulUvrDK2Tupua5Gc4vPBrfHML3skbWv6mmH9+z7eoQ7mbT1j/QtV4JnuDfHZ2hOy7PvUe/cjv7gEPp4euFlYou1JNHdpk5K1Xi0M72OmTqGDbyWZrNzH13PsOtFWc4GRJbqZ7G1q0LQjmRwABPh6YcOELtr6RKPwQKwe3xnFJaV4buFeAMA8E6ucmBvdeFedUPwtMbGgNWzJ6+MqereqKRqkL3v2bjQMr6z9PSwxda7q/lyWppvaq0P9qjhyMRfX8opke49aVfwtHmPlx373JuHa6VANqgdikoSGj8q+Xmivcw0b0akuHomPtnuZQlcl6xFz9epVDBkyBEFBQQgJCcHIkSNx48YNs6/Jz8/H2LFjUbVqVVSuXBn9+/dHZuad4HPfvn0YPHgwoqKiUKlSJTRp0gSffvqpnB9DUTMeboWjU3ta3C48yA/t6+lcaGQYg6nmoe9hgb5WBtDG2zqjh8DcO6j46wUAbHi5C757vC36GWSWLecCdTOzejaLsLyRgzn6O9MAekG6Lft35KVj0/HLjtuZQh6IjdT2eulKfcf4uuzI7+7NB5vpZYZ2JXLOX/bw0MDfxwtenh56wUP/NuLXJV3WXGPtnWZkqzbRVTCmc/07o2JMnMVSe+DKh/j2k/D9WEXl9ysxO1690yjYo6n0c0usgdvwEVvOVbE6i+5jpqYudGzgnGXU2uokHrTV70+Z79lXQ71H9+fVDQZD/L2Nrunv92+BHa+JNy5LCcI9PDQ49FbSnfe2rqgWzX8iHjteS7S4nRxLFOtydAhSUYN0QOZAfciQITh06BBWrVqFpUuXYuPGjRg9erTZ17zwwgtYsmQJfvvtN2zYsAEXLlxAv379tM+npKSgevXq+Pnnn3Ho0CG89tprmDRpEr744gs5P4qipAagQTa0eFqTBEMNF1Q5Gc4Zs7ZhwpbeZFdqpa4e6IduMeGq7526V+LSYYYccXw7Y7SFuezo5u6NXRvrj4QY3E58xIbURDZqvR54emjw/fC7MHtIGwfuVb4P+6aZdXXV3DhqjkajweZXumKgE7MXVzeR5M5WDcLsSxZmK41Gg4n3xWiTIr3du7mFV5jXt3UtbJnYDR895JjM4pLqGa552JpUPg1MNxArlSkhhZSvztvTAyM6yjenXFsWB/yO9qwkAUhff9seug0xuivYaDTG98OBd0WjeqD4tSYs0BcT74sxe00H7P9OzNFoNJISBH49tC0+GRiL1tEhkvf9w4h2ljcih5MtUD9y5AiWL1+Ob775BvHx8ejUqRM+//xzLFy4EBcuXBB9TU5ODr799lvMmDED3bp1Q1xcHL7//nts3boV27ZtAwCMGDECn376KTp37ox69erh0UcfxfDhw/HHH3/I9VEUZ3StNHH11F1D0/AWYusFV7c131UrjWIMP0pSs3CjOVjWftwrNwutet8HYyPRz8SSFXIlpXLnZFflvrawVJM54+9tZDLx1IyH7a/oGs7FbmPFTTI0wAdHp/a0Kju6bgWke5Nw3N2wrCcmJiIQ0/qJD58f27UBalWpJJoVV9fCUe1RM6SS2e+7UbjzlwcSBAFdG1fHfQ5am9gUR43Aedygwl3F3xs/qyhbv61qVfHH+xbmIlprQJwy2fPluvMZXo5/EUkO+3DbKJOJPaWqGVLJ7gbWuUPjEFsrWJtI1RVrA7rXdk8rEll+Nrg1hiXUxr/P3vkdlL6XvpTUCJPui8G6l7o45f1s/bjmrpMtTOTB0R398YaFufOOoPvZDEvr6aGxapnZMZ3rG13TK5npDVbqPAr290bf1rX0Rub88XQHk6vIPNGprslpj2LkXtGik5NGlaiBbM06ycnJCAkJQdu2dypxiYmJ8PDwwPbt29G3b1+j16SkpKCoqAiJiXeGbcTExCA6OhrJyclo3148w3lOTg5CQ00P4ygoKEBBQYH237m5ubZ8JNUwdWKby7hoiqXhWhWhRz2xSXV8NdQ42HDkUPiYiECj4WqfmbggOlqN4EqoEewHHy8PVJK4PJpNjTI6x4orrBst5tnuDRER7IeXF+83eq5fm1qY/t9RZF0vEHmlNLrzrjQAOjcKw9ePtcWoH3dJer21w7/0KiAa4LNBrfHrrnS9Rj1DYYG+2PyK5aQ48fWqYsvEbigxMw893MG9nHIIruSNnFuOmc9n6puoGiD9fNj9xr3akRmto0Pw74GLDiiZexjWoY7Vr+kWc2dVBKsmRylwvxNb9hNQR1LDHs0i0EOB6UGOFOLvgwlJjeGh0egFKJbqS+FBfnjLhpENtqy6oXvcVfY1/Xp/Hy882dnxy4YqrX5YAD58KBZ/7D4PQNl6Z3kdsGWtEKw4ZJz/SSrDZWrVRLeu1ya6Ci6J1G9C/L3xlAxL1Nrj0fbRGNahjsnpIe5Eth71jIwMVK+uv2yQl5cXQkNDkZGRYfI1Pj4+CAkJ0Xs8PDzc5Gu2bt2KRYsWmR1SP23aNAQHB2v/oqKcNxzPEQwvVA0l9FIZtmaZqky3jjY/B0m/pdFNI3UTHDnCe/nz9+CN/zU1OzRarm/X00ODTS93xdoXu1gMwAe3i0Z83VDRxCqGfhjRDjVDKmHBE8a9f7YkHlMNc0mpTHx/fW6vPaz7rJTcEhqNRm+o/scDYvWSHFmbRTa4kvm21yoBPniyc327hwkr3ZvkSLrru654/h588Yi0BjSpFcj+bWphiFUrUtzZsW6QSdbx8fRAj6bhmGkiU3DPZhF4MDbSuYUixY3t2sAhQUd1M+tCl3u1VxN0qF8Vsx6RPg1Ho9Hg00Gt8F7fFogIVk9D50s9xFcYkIPucHNnrClu6n5mTyNBl9tTzXo2ixBdQUgtDL9esY+8YUJXyZn7pzzQFBoN8JEDRiCaV1Z3alJDvd+to1gdqE+cOBEajcbs39GjR+Uoq5GDBw+id+/emDJlCnr06GFyu0mTJiEnJ0f7l56e7pTyySW+rvUZXXWvQ090KhuWI2WpA73l2SpWnC5pno9cHB0HeXl6wNNDY3G/0/q1wKInEyTdHDs3CsOWid3Qwc2HIOkuNWUqsVP5sFLdc0Ss99vSOVQt0BeBfnd6UWoES2stnjmwFTo2qIrx9+pXpvRXbZDnBFbbZcHaPAEeGg32TemBPW/ci8YRgfD1Mv7dxnSuJ+n6J7bJxw/Havf5Xt8WaFEzGPcYDCEMNdFj6oycB+4q9Z2emPtYWwTpnE+6X+ecoXGYYmEuqaOYup766gzFblDddAO8Ox0FDyk0fcHRoqr46wXgYsFe9UA/LBjVXvKyhuV6t6rpsFVfHKVjg2rY/6bperYp5efcu31tz7XQwcRIEzX7fHBrfDqoFT6WPWC1j6OntA7vWBfH37kPHerLXS90o94CC6we+v7iiy/i8ccfN7tNvXr1EBERgaysLL3Hi4uLcfXqVUREiA+fioiIQGFhIbKzs/V61TMzM41ec/jwYXTv3h2jR4/G66+/brY8vr6+8PV1zaG4gHFlTcp5ZXgIV/b1wqPto1FSKuD1/zXFC/c2kpTQwtzcHXcnR69wRfsOXYn2vDL4kXSHnRpWxvx9PJFXWIIujauLPi/yLnf2JfJsWcOY9TegPq1roo/IcHa5GtrcLX60lNSxdtUAHHvnPjR87T/tY2JfgaVf7pH4aDwSH43dadew8dgl7RrZpuYwutnXrBXg44mbhSVWv86akRxijRwtaoVY/Z6O0CCsMlIzr2v//c+4jvDQaODr5YnXezXBJ6uOYebtud/u7qMBsVicck7pYugx1QBr/jVAr5Y1MHaB48ujVrqNXlKF3B7+PyS+Nu5rXgNtpq6y6vWCIP/9JtBPpy6sEf1fG/bpjd6tHLzSggwMR22INSpa+/17KdjJ5Y6sDtTDwsIQFmY5oUBCQgKys7ORkpKCuLiy+Rlr165FaWkp4uPFE+XExcXB29sba9asQf/+/QEAqampSEtLQ0LCnSUeDh06hG7dumHYsGF49913rf0IFZbu2stSs05GVfGHj6cHAnw9nTIESU2U/LRyJeKQM8HH272bYeIfB/C0yuYySdUgTLxHy9xXtmFCVxzNyJWc2MSWCkevFjXw74GLGH1PPetfrPvedr1anzsNfTf8LFJygNirTXQV/Pfc3YgMqXS7DOJfqBt9zXoWjGqP3rO2OP1972lYDV8OaYNG4Y7J6F6enNFaLXUaDJ64ux5GdKyr+tU0DLlTY50t57bhOetO30e5kZ3qYeeZFKun4Gg0wA/D2yGvsEQvQ7qpkUO62hmMGBUg32iw9/q2wLlredqs/kbc8Dc1FGMwdLxTw2poFF4ZVQN8kXzqCgC13u8rwI9zm2zJ5Jo0aYKePXti1KhRmDNnDoqKijBu3DgMGjQIkZFl88LOnz+P7t2748cff0S7du0QHByMkSNHYvz48QgNDUVQUBCeeeYZJCQkaBPJHTx4EN26dUNSUhLGjx+vnbvu6ekpqQHBHUg5PBtWd0xFxMfLA/vf7AGP29Ma3IXuJ5FyEXLUR4+pYfp3cfXvd1C7aNzbNFzyXCZnqBlSCeezb5nd5venOmD1kUw83bVsiHtMhOnfyPBQCQv0RVhgmMnnDdWqUgmeHhoE+HiazIFgeDzOHNQKT3etj6Y2zMUyTCYnB7UdtrrFmTf8Ljz+/U6rXi91JI2956ta5tY1qRHk9MY1S1/dtH4tkJmbj5mrj6N6oK/kBI71wwJw8tJNxNYSr3hrNBrcb8dqAA/F1cLus9ewYFR7rDqSiQdbOmaOu6sF6ZaYy3KtRm/3bo5Hv9mOMVacB4bXenUGM/bp2TwCm17uqm1QlEoDGE3vkeq1Xk1sep0t1Da9QAmGVx5fL0+seP4eZOTmI2HaWkXKJIWPl3tdM82RbzE/APPnz8e4cePQvXt3eHh4oH///vjss8+0zxcVFSE1NRV5eXnaxz755BPttgUFBUhKSsKXX36pfX7x4sW4dOkSfv75Z/z888/ax2vXro0zZ87I+XFUo4q/6VbJpc90QmrGdXSysaVfjLWZpl2NqUqjxsohULWr+uPslTyz2/SOrYmcvCK0qW0+iZ9cHNWTZIqagnSgbM1fS4F6XO0qiNP5PVrWCsG3w9pi5A/SMrHrsrS2rq+XJw69lQSNRjzQEwD4GWTm9/b0QLNIEy3+VqhoySAB01m0dRn+DI0jAvH54NaoYUMip3ubhGPRLutzoMhdx/fQAKaS8386qJXs1wVrDW4XjeKSUjSpEYS42lXQ9p3Vkl7308h4/LIjDY+2r23T+z7VpT5mrz9p9Hj5MfLRgFgIggCNRoOhNr6HLSxNzVCb+Lqh6Ne6JgpKSvHvfvWvWlC3WgC2TLQucafcy0+phZyJYcXqXpVFRns6tTFY52f1lPGNyzsREptIX/pNDmIfUaPRqLa+8HSX+jh4IRedG1WcRKuyBuqhoaFYsMD0BJ46deoYXez8/Pwwa9YszJo1S/Q1b775Jt58801HFtOlLH2mk9nW9+Y1g00P4yGbSUm4IeWy5uGhMVpj05nublgNHz7UEjER6ujNk5utt5ruJm6er93fBM8v2ovhHetI2s+GCV3Q+cP1eo9Zavi6p2EY7mseYVMPuiG56pLVA+80yOg2OPRuFYkq/j6Yt/WMPG8sA7Hv6AErs4H/Mqo9zl65iQdbRdoWqJvKOmz1nsT5eHkgOtQfxzJvOGiP8vPy9ECSwXJgluYSR4ZUwot2ZKeONNE4o79MqfMrsAG+XvhrbEf0UWC6gC00Gg1mDGyFwxdy9QL18fc2UrBUjvFAbCQOX8gxWm6V7lDiHBnTuT7mbNBvZAuXkJnfkP4oNPk+x59jO2DTsctWJxp0NFMBuS15G5zh5Z4xShfB6WQN1MnxKsKagc6gewly5tB3qeQKsDQaDQa0da3lCW3Ro2k4Vh7OxKh76uKFRfsctt8+rWuiU8NqqGpirp3h71a7aoBV+69XLQCeHhrMftQx667q3mwdcQx//VhbHMu8brKnenjHumgVFeLUQP3Ue/ej3qvLtP9uo7PkpJy9Arp7Dgv0kdR7b4rclSJz34Ojs/66MjVPP2oVFYJqlX1w+Uah0kUBYNu5JWWOstp9Pri1dlQFADx5Tz18s/k0XuzRCMsPiS8jTPKbeF8MBreLwuz1JzG4XTRCA3xQzYYRfrr3cDlnpFQP9EN/GVdA+Gxwa/yecg4bjl0yu52KL3l0GwN1F7H+pS7ILy5BiJlh7+RYupU2ZwwD4vXScb4c0gbnrt1CnWoBNgfqSc3Cse7oJfRupd+7au7mb+twyJUv3IMrNwqtDuwtqRHk2Ia9e5uG6637rgaGI4y+GHJnHXRn9QqofRTspPtj8PO2s3qPxUQEom61ANQPc+wxJyc5v+f3+rYwebyopTKr9uPMVknNwrHiUKbSxZBMt24w6f4meCmpsaLLuaqNrafLsmfvNnpMt1HEktpVAzC9f0sb371Mqd5KKSo58W3wYGwkHoyNRJ2J/5rdztQnVOvQ94qIVxYXUadaQIUZruwMupegBuGm16/Vbm/lNeuJTnVRxd+15hW6Ey9PD9SpZl8AMufROBx8K8mqefe2VqQbhQfa1SNrSnAFPAZ1swzLyRl1OGveI9DESh4tawXjsYQ6Rsfme/1aYPajcS5dGXWkHs3CEeDDvgt7/DW2o96/a0pMQtZaZxSMK2KQrs/WJG1NI5Wv4+oG6m6W41GUqcu/Woe+V0S8ulCFJ2VtUCl12TCdebuv/68pwoOcEzCQPDQaDXy8eIm0R0UJAu2t0sjZU2pLUjy5qbW3pnuTOwmK1HjoqrFMulpFhej9O9jfG2tf7Kz9N6v+FcNz3RsqXQSb6Q99LzvhHJEvRq3Uei2mO9h8TCSBlItZaIAPfn0yweWWpqnIHB3EqLki6oyyVaRbviMbIUz9NnL21LnSbxUW6ItL1wtkzU6vAeCp04Wml0DOpb4tdakXJmHEmhPKQc4T5OBVCpya9F0vcWTZf7s0DsPHA2JVs6SmQ5la9YhnpWqwu4gqJN2KsZQ5t1KGQAkC0K5uKFqYWMPXErX3lrij5c/f49D9DW5Xlqjvbgcuj1gRSR0yqxb2jp7pfTvLfDODoZ+RIZXweIc6GNNZ2vrOzlwyzJm2TuyGI2/3RCUf+RpBzTVkqWUYqJrmqNt0vzLxAZyR0FDqSh0kneGygdtf7Y4dr3V3aAOjsw953XO9/LjUaDToH1dLFUPzHc3UmaeWax6xR51IUi+NLRUJa3vcKnl7IjzIF/lFpYhQ4XBVd+To9YknJMWgY4NquKtOqEP36wiu1A4UGxWM89m3lC6GRRsmdEFhcandx9GEno3RpnYVdBDJU/Dmg80AAPXDArA3PRvzt6eZ3M/bvZvB00MjmnXfsNpVI1iZxpDfn+pg9Wu8PT0gx0Cl0AAftKsTCgECqgb44FZRifY5Npw6z6B2UXh32RGTz/dvUwurj2Qi51aRze/xP4WXwXJHS5/phLs/WKf9ty0NllJOM2eei6UiPeruTFI9lTG7otijThWS1ddfpySO0mDzK92w87VEJqexUlSoOnpgfbw80KVxdQSYSOylJCXutUrXczxlrmnVrhqAhg4Yju3r5Yn7W9Qwu6rHgLZReKab+bmfGo1GG9ibs2BUvGKNgXG11ZM4TKPRYNGT7fHrkwkOmcpgy7rN1nDXwCHQQp6Y/nE1sXfyvUZz4K2hptEI7sLXSTlcnHnY6yeTc9MTTgezvqsfowEiCWy5ZNnyGm9PDyYws0HD6vLNXbVXeWXG1NrrJB8vTw/tdARnaauiQNSUDvWVnZphblhltcrOPU80Go3FIF1qpfWvsR3xdu9mmHhfjNFzr95f9hiHYIubkNTY7PMajYYde2rjjFjOyT+6UNECdUlDGmQvBpnBiIBIAsO1mqV4r18LeHtqMEmk0kaOZev65c7wx9MdkNikOhaMaq90UWQXersxIvZ2z9fDbZ0TJCc2MZ1nomvj6kaPmdveXoueTMCz3RrIsu+qIkFs+Xf+Xr8WsrynHI5n3lC6CKLsvYzUCK6ExxLqwN9gLv3Au6Iw6u562DihKyb/r6l9b6ISNk1RN/OcOzRgBPqVjaRqUN1yAj13YEuva4TO8Hip55szVw/RG/rutHdVjqSvVr3VqwpBfeMziVQoO8/6uXGtokJw5O2e8OIwdtkVl6r3TtIsMhjfDLtL6WJIWobQVnOHxiH7VhGiQv0BAItGt8fZK3loFO6cCmuIlevFP5/YEKuPZMpSFk8PjcOzHpfz9vTAwbeSoAHQbMoKAMDYrg0w8K4oVDYx3aK8Mq2mxqwSFZXFFEcFB4vHJKBNdBVoNBpEV/V3yD7VIMTfBzcL1Z9HopwzYr0/n+6ArzacsjhFhcpoNOqbziGW9d2dcYi7+jFQJ5IRg3RS2vR+LbA3PRs9JKxuYKsezSL0/u3n7YnGEc6bjmCuqlHeeOAuDANyjchjulSZvVeFRTJkT8OG7vHYVoWJJR3hm2Ft8crv+1Ej2A8rDmXiwdsrF9hKSsCg9pCiQfVAfDggVuliOI2zAllrG2LtUft2Y5qXh+UpMe6gAnxEl8dAnchBEkQyNpPylj17NzYev4Tp/x1VuiiKGNQuGoPaRStdDFmZq2y45dq3bo01R1fQpEYQ/hnXCYIg4NTlm6hTNcDia8y1fUhpULKnfccFBnGoipTg2N5RWhpIa6CZdF8TZOTkY7AT7mN+3p448GYPeHlUjE6WitAY4eoqxpFIZMCR6/FuerkrZjwc67ZrGLu6ppFBktehJnIHnw5qpf3/8oowK2TWUeP3NaJTXQDAvTKOjrGWRqNB/bDK8LQhjwup16C7xINi3fwLPl4euLuhfYkpOzYoe72XmeMnLNAXC0a1xwN2jtqQKtDP26F1RDXjWat+7FGnCqlj/Wp4IDYSMQ4YnhsV6u92w2uJlBRftyqWHciQvH1FnGcXExGIoxnX0aOZcdDWu1VNPLdwr95japqjbq73VMn42GSpVHJ4jbmnPjrWr4aYGupd5YIqlggr1043PL+bRgZh5Qv3oHqg+NKG9cIsj9Qg26mwPZIMMFCnCsnDQ4PPB7dWuhhEpGPTy12x88xVPBgbiSn/HJL8utrVzDeUhfh76yWEdIfekqXPdMKNgmKza6+rlW6bwaC7orB0/0XcKChWrkAuwsNDo11RwRXZ21jkzV57p5EawDki0GsUbtzwtHp8Z1y5UYDaEqZUkO0qYiO3q+HQdyIiUoWoUH/0a1PL6iSMIzrWxROd6mLBqHjR5yODK2n/f0zn+qgf5vrLJ3l5ekgK0utXV7ai+3DbWkaP6YZrUx5ohn1Temj/zWojmTK9v+ssQejqTLWpGD5ubaDXvp60XD4NqldGvMRtyXbsUVc/BupEROTS/Lw98fr/mqJDffH5kl1jwgCUrTk+8b4YZxZNMb8/1QFPdq6HcV3LlopSauD7+/1bmn1egKDK+c0a3Fnbe0JSYytfrL7Powb2HoMNqgfi2e62LX3Gn0Qd3urdTOkikA5Tp0WA751RZ77eDBWVxKHvRBJUqyw+f4qI1O/Z7g1Rp2oA7m4YZvRc6+gQ5xfICeJqV0Fc7SpKF8PqpGxqCqimPNAMLyfFuMVUCVfmiAzcKkrR4BKknoeJTcOxaFc6As0sEalLL1O8mk72CsrUTxDo540fR7SDh0YDP29e/5TEQJ1IAnMZSUl5/qxIkxm+Xp4Y0DZK77HV4zvj3/0XMaJTHWUKVYGV6kRNapojGeDjic6NwlBQXIIawWVJsmwJ0h+MjcSMlamiDUNkne4x1dFWBQ1OVMYwEWRik+r49ckENKju+tOJKqJWUabPrXsa8fqlBgzUiSRgnK5ukx9ohrSrtzC8Qx2li0IuokH1yngu0bphtIPbReOXHWno1bKGTKVyT4bJ/JrqrG0vZf1sZ9FoNPhhRDsIgmDX8mzBlbyx6/V7VTmkX0nW9mrH1grGt4/fJU9hyCE0Gg3a1Q1VuhhkgaklHSOC/bDp5a4IquQt+jwpj4E6kQRqXFOX7qgZUgn/PXe35O3b1Q1Fl8ZsLSbrvPlgU9zfIgJ31XHBiqmC8XBkcCW9QF3tU4kccb1nkK4MDw1Qqp62H7eTX1SqdBHIBuaW0ePywurGQJ1IAsbp7uXXJxOULgK5IF8vTw5nJrJRlQB5e+0S6lVFgK8XVh/JlPV9yDFYrSKyjIE6kQQejNSJiBzC3OVUTXPWyTFmPByLHaev4sHYmnbvy9zRwVEMjpNzq8jyRuQyWIV1Xcy5TyQBL3JERI4RqJP52REZvUnd+rWphen9W5oNpP28pCXtszSqnfdqx1iwPU30cT8u1UXkVDzjiCRgjzqRc/08Mh6RwX6IDDY9t46k69O6rDeziU4iN6UEV/LG94/fhZ9GtoOPl341hJfaisnDQ4O3HrR/jW0uw+YYpuY0sy7kWoL8ygZOd28inkyO1I9D34kk4K2JyLk6NayGrZO6o8cnG4AcpUvj+p7uUh8tagWjTbTzl7oKDfAxeqxrTHWnl4PUrW+bmpjyzyGli0EABrStJft7MOaX38aXu+L05ZtorcB1nxyDPepEEvCGQkRSqbFXz8vTA10bV0ewAsvwTOvXAu3qhGLu0Dinvze5jiA/LhGlFrqrNOhy5LXNx5MhiNxC/H0YpLs4niVEEnC4F5EymFzM9UWF+uPXMQno0SzC4rb8tcla9aoFAACe7FxP4ZK4jyX7L4g+LjhgnccP+rdEnar+mNavhd37InJ3DNSJJOjYoJrSRSCqkNhGRkTmfDa4NXa9nmh26cQAX870tEaXRuLf5Us9Gtu974fvisL6CV1RL6yy3fsicncM1IkkSKhfVekiEJGLYOOC7TT88qicFcdCtcq+Jp97plsDVSRRdCVeJoal164a4OSSEFVsbGIkIiLVYuBWMfh5eyC/qBRxtTmfkm6zYUL0vU2rY/WRTIT4e2Na3xYI8PXCPSZ6h8l6ghoTcBC5MQbqRESkWo3DK+PIxVyli0Ey+++5e/D33vMY3rGu0kUhme16PRHfbj6N2etPOnzfA+KiEB7kh+Y1g832spO4miGVcD77Fu5vYTmfBBHJj4E6kQTs0yNSRvOawfhrr3hiI7Vip5P16lYLwPOJjZQuBjlBtcq+iK0VIsu+PTw06NKYS//Zavnzd+PslTw0ixSfKsARTkTOxUCdiIiIiJyIrVlqFOjnjeY1g00+z6HvRM7FZHJEErAVmYiIyIkk3ncZOxKRu2KgTmRGs8ggeHpo0L5eqNJFISIXwXY9IiIisheHvhOZsWRcJxSWlMLP21PpohBVSBzNQuR+2AtORGQZe9SJzPDw0DBIJyIiUoHHO9RBeJAvRna6szqAwPnuROSm2KNORESq5Yr96ewtJDIv0M/b4jZD4qONHgsN8MG2Sd2h0Wjw7ebTchSNzAgN8FG6CEQVCgN1IqoQIoP9cCEnX+liEBFVeB0bVMUj8dGIiQgUfb5fm5oYEFdL9DlOh1FOXO0qeLZ7Q9SrFqB0UYgqBAbqREREROQ0Go0G7/VtYfL5JhFBDMhVSKPRYPy9jZQuBlGFwTnqRESkWqyrExERUUXEQJ2IKgROGyZnYeMCkW18vcqqpXc3qmZx26Y1glA1wAeNTQyfJyJydbIG6levXsWQIUMQFBSEkJAQjBw5Ejdu3DD7mvz8fIwdOxZVq1ZF5cqV0b9/f2RmZopue+XKFdSqVQsajQbZ2dkyfAIiIlKSK8a8TCZHZJudrydizYudERMRZHHbpc90wrZXu8PXiyuzEJF7kjVQHzJkCA4dOoRVq1Zh6dKl2LhxI0aPHm32NS+88AKWLFmC3377DRs2bMCFCxfQr18/0W1HjhyJli1bylF0IiIiInKiID9v1A+rLGlbDw8NvD05MJSI3JdsV7gjR45g+fLl+OabbxAfH49OnTrh888/x8KFC3HhwgXR1+Tk5ODbb7/FjBkz0K1bN8TFxeH777/H1q1bsW3bNr1tZ8+ejezsbLz00ktyfQQiIlIYE0oRERFRRSRboJ6cnIyQkBC0bdtW+1hiYiI8PDywfft20dekpKSgqKgIiYmJ2sdiYmIQHR2N5ORk7WOHDx/G22+/jR9//BEeHpY/QkFBAXJzc/X+iIhI/RinExERUUUkW6CekZGB6tWr6z3m5eWF0NBQZGRkmHyNj48PQkJC9B4PDw/XvqagoACDBw/Ghx9+iOjoaEllmTZtGoKDg7V/UVFR1n8gIiJyuthaIUoXgYiIiMjprA7UJ06cCI1GY/bv6NGjcpQVADBp0iQ0adIEjz76qFWvycnJ0f6lp6fLVj4iInKc2KgQLHgiHhsndFW6KJJxFAARERHZy8vaF7z44ot4/PHHzW5Tr149REREICsrS+/x4uJiXL16FREREaKvi4iIQGFhIbKzs/V61TMzM7WvWbt2LQ4cOIDFixcDAITb6XWrVauG1157DW+99ZbRfn19feHr6yv1IxIRkYp0aGB5qSY1YdZ3IiIispfVgXpYWBjCwsIsbpeQkIDs7GykpKQgLi4OQFmQXVpaivj4eNHXxMXFwdvbG2vWrEH//v0BAKmpqUhLS0NCQgIA4Pfff8etW7e0r9m5cydGjBiBTZs2oX79+tZ+HCIiIiIiIiJVsTpQl6pJkybo2bMnRo0ahTlz5qCoqAjjxo3DoEGDEBkZCQA4f/48unfvjh9//BHt2rVDcHAwRo4cifHjxyM0NBRBQUF45plnkJCQgPbt2wOAUTB++fJl7fsZzm0nIiIiIiIicjWyBeoAMH/+fIwbNw7du3eHh4cH+vfvj88++0z7fFFREVJTU5GXl6d97JNPPtFuW1BQgKSkJHz55ZdyFpOIiIiIiIhINWQN1ENDQ7FgwQKTz9epU0c7x7ycn58fZs2ahVmzZkl6jy5duhjtg4jIUHAlb1zMyVe6GEREREREFsm2PBsRkZp88UgbxEaF4LvH2ypdFCIiIiIis2TtUSciUosG1Svj77EdlS4GEREREZFF7FEnIiIiIiIiUhEG6kREREREREQqwkCdiIiIiIiISEUYqBMRERERERGpCAN1IiIiB0qoX1XpIhAREZGLY9Z3IiIiB2peMxhLxnVCRLCf0kUhIiIiF8VAnYiIyMFa1ApWughERETkwjj0nYiIiIiIiEhFGKgTERERERERqQgDdSIiIiIiIiIVYaBOREREREREpCIM1ImIiIiIiIhUhIE6ERERERERkYowUCciIiIiIiJSEQbqRERERERERCrCQJ2IiIiIiIhIRRioExEREREREakIA3UiIiIiIiIiFWGgTkRERERERKQiDNSJiIiIiIiIVISBOhEREREREZGKMFAnIiIiIiIiUhEG6kREREREREQqwkCdiIiIiIiISEUYqBMRERERERGpCAN1IiIiIiIiIhVhoE5ERERERESkIgzUiYiIiIiIiFSEgToRERERERGRijBQJyIiIiIiIlIRBupEREREREREKsJAnYiIiIiIiEhFGKgTERERERERqQgDdSIiIiIiIiIVYaBOREREREREpCIM1ImIiIiIiIhUhIE6ERERERERkYowUCciIiIiIiJSEQbqRETkUh6KqwUAeKJTXYVLQkRERCQPL6ULQEREZI1p/VrgkfhotKwZrHRRiIiIiGTBQJ2IiFyKt6cH2kRXUboYRERERLLh0HciIiIiIiIiFWGgTkRERERERKQisgXqV69exZAhQxAUFISQkBCMHDkSN27cMPua/Px8jB07FlWrVkXlypXRv39/ZGZmGm03b948tGzZEn5+fqhevTrGjh0r18cgIiIiIiIicirZAvUhQ4bg0KFDWLVqFZYuXYqNGzdi9OjRZl/zwgsvYMmSJfjtt9+wYcMGXLhwAf369dPbZsaMGXjttdcwceJEHDp0CKtXr0ZSUpJcH4OIiIiIiIjIqTSCIAiO3umRI0fQtGlT7Ny5E23btgUALF++HPfffz/OnTuHyMhIo9fk5OQgLCwMCxYswEMPPQQAOHr0KJo0aYLk5GS0b98e165dQ82aNbFkyRJ0795dcnkKCgpQUFCg/Xdubi6ioqKQk5ODoKAgOz8tERERERERkXm5ubkIDg6WFIfK0qOenJyMkJAQbZAOAImJifDw8MD27dtFX5OSkoKioiIkJiZqH4uJiUF0dDSSk5MBAKtWrUJpaSnOnz+PJk2aoFatWnj44YeRnp5utjzTpk1DcHCw9i8qKsoBn5KIiIiIiIjI8WQJ1DMyMlC9enW9x7y8vBAaGoqMjAyTr/Hx8UFISIje4+Hh4drXnDp1CqWlpXjvvfcwc+ZMLF68GFevXsW9996LwsJCk+WZNGkScnJytH+WAnsiIiIiIiIipVgVqE+cOBEajcbs39GjR+UqK0pLS1FUVITPPvsMSUlJaN++PX755RccP34c69atM/k6X19fBAUF6f0RERERERERqZGXNRu/+OKLePzxx81uU69ePURERCArK0vv8eLiYly9ehURERGir4uIiEBhYSGys7P1etUzMzO1r6lRowYAoGnTptrnw8LCUK1aNaSlpVnzUYiIiIiIiIhUyapAPSwsDGFhYRa3S0hIQHZ2NlJSUhAXFwcAWLt2LUpLSxEfHy/6mri4OHh7e2PNmjXo378/ACA1NRVpaWlISEgAAHTs2FH7eK1atQCULQN3+fJl1K5d25qPQkRERERERKRKsmR9B4D77rsPmZmZmDNnDoqKijB8+HC0bdsWCxYsAACcP38e3bt3x48//oh27doBAJ566iksW7YM8+bNQ1BQEJ555hkAwNatW7X77dOnD06cOIG5c+ciKCgIkyZNwqlTp7B37154e3tLKltOTg5CQkKQnp7OYfBEREREREQku/LVx7KzsxEcHGx+Y0EmV65cEQYPHixUrlxZCAoKEoYPHy5cv35d+/zp06cFAMK6deu0j926dUt4+umnhSpVqgj+/v5C3759hYsXL+rtNycnRxgxYoQQEhIihIaGCn379hXS0tKsKlt6eroAgH/84x//+Mc//vGPf/zjH//4xz+n/qWnp1uMWWXrUVez0tJSXLhwAYGBgdBoNEoXx6TyFhf2/FNFxOOfKjIe/1SR8finiorHvvsTBAHXr19HZGQkPDzM53W3ao66u/Dw8NDOcXcFzFRPFRmPf6rIePxTRcbjnyoqHvvuzeKQ99tkWUediIiIiIiIiGzDQJ2IiIiIiIhIRRioq5ivry+mTJkCX19fpYtC5HQ8/qki4/FPFRmPf6qoeOyTrgqZTI6IiIiIiIhIrdijTkRERERERKQiDNSJiIiIiIiIVISBOhEREREREZGKMFAnIiIiIiIiUhEG6kREREREREQqwkBdxWbNmoU6derAz88P8fHx2LFjh9JFIjJp2rRpuOuuuxAYGIjq1aujT58+SE1N1dsmPz8fY8eORdWqVVG5cmX0798fmZmZetukpaWhV69e8Pf3R/Xq1TFhwgQUFxfrbbN+/Xq0adMGvr6+aNCgAebNm2dUHp4/pKTp06dDo9Hg+eef1z7G45/c2fnz5/Hoo4+iatWqqFSpElq0aIFdu3ZpnxcEAZMnT0aNGjVQqVIlJCYm4vjx43r7uHr1KoYMGYKgoCCEhIRg5MiRuHHjht42+/fvx9133w0/Pz9ERUXhgw8+MCrLb7/9hpiYGPj5+aFFixZYtmyZPB+aKrySkhK88cYbqFu3LipVqoT69etj6tSp0F1Ui8c+2UwgVVq4cKHg4+MjfPfdd8KhQ4eEUaNGCSEhIUJmZqbSRSMSlZSUJHz//ffCwYMHhb179wr333+/EB0dLdy4cUO7zZgxY4SoqChhzZo1wq5du4T27dsLHTp00D5fXFwsNG/eXEhMTBT27NkjLFu2TKhWrZowadIk7TanTp0S/P39hfHjxwuHDx8WPv/8c8HT01NYvny5dhueP6SkHTt2CHXq1BFatmwpPPfcc9rHefyTu7p69apQu3Zt4fHHHxe2b98unDp1SlixYoVw4sQJ7TbTp08XgoODhb/++kvYt2+f8OCDDwp169YVbt26pd2mZ8+eQmxsrLBt2zZh06ZNQoMGDYTBgwdrn8/JyRHCw8OFIUOGCAcPHhR++eUXoVKlSsJXX32l3WbLli2Cp6en8MEHHwiHDx8WXn/9dcHb21s4cOCAc74MqlDeffddoWrVqsLSpUuF06dPC7/99ptQuXJl4dNPP9Vuw2OfbMVAXaXatWsnjB07VvvvkpISITIyUpg2bZqCpSKSLisrSwAgbNiwQRAEQcjOzha8vb2F3377TbvNkSNHBABCcnKyIAiCsGzZMsHDw0PIyMjQbjN79mwhKChIKCgoEARBEF5++WWhWbNmeu81cOBAISkpSftvnj+klOvXrwsNGzYUVq1aJXTu3FkbqPP4J3f2yiuvCJ06dTL5fGlpqRARESF8+OGH2seys7MFX19f4ZdffhEEQRAOHz4sABB27typ3ea///4TNBqNcP78eUEQBOHLL78UqlSpoj0fyt+7cePG2n8//PDDQq9evfTePz4+XnjyySft+5BEInr16iWMGDFC77F+/foJQ4YMEQSBxz7Zh0PfVaiwsBApKSlITEzUPubh4YHExEQkJycrWDIi6XJycgAAoaGhAICUlBQUFRXpHdcxMTGIjo7WHtfJyclo0aIFwsPDtdskJSUhNzcXhw4d0m6ju4/ybcr3wfOHlDR27Fj06tXL6Bjl8U/u7J9//kHbtm0xYMAAVK9eHa1bt8bXX3+tff706dPIyMjQOy6Dg4MRHx+vd/yHhISgbdu22m0SExPh4eGB7du3a7e555574OPjo90mKSkJqampuHbtmnYbc+cIkSN16NABa9aswbFjxwAA+/btw+bNm3HfffcB4LFP9vFSugBk7PLlyygpKdGrrAFAeHg4jh49qlCpiKQrLS3F888/j44dO6J58+YAgIyMDPj4+CAkJERv2/DwcGRkZGi3ETvuy58zt01ubi5u3bqFa9eu8fwhRSxcuBC7d+/Gzp07jZ7j8U/u7NSpU5g9ezbGjx+PV199FTt37sSzzz4LHx8fDBs2THv8ih2Xusd29erV9Z738vJCaGio3jZ169Y12kf5c1WqVDF5jpTvg8iRJk6ciNzcXMTExMDT0xMlJSV49913MWTIEADgsU92YaBORA43duxYHDx4EJs3b1a6KEROkZ6ejueeew6rVq2Cn5+f0sUhcqrS0lK0bdsW7733HgCgdevWOHjwIObMmYNhw4YpXDoi+fz666+YP38+FixYgGbNmmHv3r14/vnnERkZyWOf7Mah7ypUrVo1eHp6GmUDzszMREREhEKlIpJm3LhxWLp0KdatW4datWppH4+IiEBhYSGys7P1ttc9riMiIkSP+/LnzG0TFBSESpUq8fwhRaSkpCArKwtt2rSBl5cXvLy8sGHDBnz22Wfw8vJCeHg4j39yWzVq1EDTpk31HmvSpAnS0tIA3Dl+zR2XERERyMrK0nu+uLgYV69edcg5wuOf5DBhwgRMnDgRgwYNQosWLTB06FC88MILmDZtGgAe+2QfBuoq5OPjg7i4OKxZs0b7WGlpKdasWYOEhAQFS0ZkmiAIGDduHP7880+sXbvWaIhWXFwcvL299Y7r1NRUpKWlaY/rhIQEHDhwQO+GtWrVKgQFBWkrgQkJCXr7KN+mfB88f0gJ3bt3x4EDB7B3717tX9u2bTFkyBDt//P4J3fVsWNHo+U4jx07htq1awMA6tati4iICL3jMjc3F9u3b9c7/rOzs5GSkqLdZu3atSgtLUV8fLx2m40bN6KoqEi7zapVq9C4cWNUqVJFu425c4TIkfLy8uDhoR9OeXp6orS0FACPfbKT0tnsSNzChQsFX19fYd68ecLhw4eF0aNHCyEhIXrZgInU5KmnnhKCg4OF9evXCxcvXtT+5eXlabcZM2aMEB0dLaxdu1bYtWuXkJCQICQkJGifL1+eqkePHsLevXuF5cuXC2FhYaLLU02YMEE4cuSIMGvWLNHlqXj+kNJ0s74LAo9/cl87duwQvLy8hHfffVc4fvy4MH/+fMHf31/4+eeftdtMnz5dCAkJEf7++29h//79Qu/evUWXqGrdurWwfft2YfPmzULDhg31lqjKzs4WwsPDhaFDhwoHDx4UFi5cKPj7+xstUeXl5SV89NFHwpEjR4QpU6ZwiSqSzbBhw4SaNWtql2f7448/hGrVqgkvv/yydhse+2QrBuoq9vnnnwvR0dGCj4+P0K5dO2Hbtm1KF4nIJACif99//712m1u3bglPP/20UKVKFcHf31/o27evcPHiRb39nDlzRrjvvvuESpUqCdWqVRNefPFFoaioSG+bdevWCa1atRJ8fHyEevXq6b1HOZ4/pDTDQJ3HP7mzJUuWCM2bNxd8fX2FmJgYYe7cuXrPl5aWCm+88YYQHh4u+Pr6Ct27dxdSU1P1trly5YowePBgoXLlykJQUJAwfPhw4fr163rb7Nu3T+jUqZPg6+sr1KxZU5g+fbpRWX799VehUaNGgo+Pj9CsWTPh33//dfwHJhIEITc3V3juueeE6Ohowc/PT6hXr57w2muv6S2jxmOfbKURBEFQskefiIiIiIiIiO7gHHUiIiIiIiIiFWGgTkRERERERKQiDNSJiIiIiIiIVISBOhEREREREZGKMFAnIiIiIiIiUhEG6kREREREREQqwkCdiIiIiIiISEUYqBMRERERERGpCAN1IiIiIiIiIhVhoE5ERERERESkIgzUiYiIiIiIiFTk/5YnMWTfCaUIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot librosa data\n",
    "### Lets plot the librosa audio data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(librosa_audio_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the same audio file using scipy package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile as wav\n",
    "wave_sample_rate, wave_audio = wav.read(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 206,  163],\n",
       "       [ 221,  164],\n",
       "       [ 268,  232],\n",
       "       ...,\n",
       "       [-413,  173],\n",
       "       [-459,  124],\n",
       "       [-479,   19]], dtype=int16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave_audio # 2 channels using scipy with unnormalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x156a68b50>,\n",
       " <matplotlib.lines.Line2D at 0x1558dce10>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#original audio with 2 channels in blue and orange\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(wave_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take these signals and attempt to create some independent features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will utilize Mel-Frequency Cepstral Coefficients (MFCC) from the audio samples. MFCC captures the frequency distribution within the window size, enabling the analysis of both frequency and time characteristics of the sound. These audio representations will help us identify features for classification.\n",
    "\n",
    "Link for reference: https://www.youtube.com/watch?v=4_SH2nfbQZ8&t=0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 173)\n"
     ]
    }
   ],
   "source": [
    "mfcc = librosa.feature.mfcc(y = librosa_audio_data, sr = librosa_sample_rate, n_mfcc=40) #this 40 is being assigned to the number of MFCCs\n",
    "print(mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.1925809e+02, -2.9483157e+02, -3.0291397e+02, ...,\n",
       "        -3.1739627e+02, -3.1440588e+02, -3.2856140e+02],\n",
       "       [ 8.4317780e+01,  8.2091766e+01,  8.1065536e+01, ...,\n",
       "         8.6607742e+01,  8.9827988e+01,  9.8324295e+01],\n",
       "       [ 4.0132279e+00,  2.0044267e-01, -8.1244411e+00, ...,\n",
       "        -1.3994555e+01, -1.5255758e+01, -8.0216970e+00],\n",
       "       ...,\n",
       "       [ 3.9292572e+00,  6.8303270e+00,  1.8434331e+00, ...,\n",
       "        -1.4527726e-01, -1.8950844e+00, -1.6281416e+00],\n",
       "       [ 5.5113354e+00,  4.0100150e+00, -1.2197342e+00, ...,\n",
       "         4.7535372e+00,  6.6015987e+00,  4.5735531e+00],\n",
       "       [-3.4027443e+00, -6.8166747e+00, -7.5914321e+00, ...,\n",
       "        -1.7982340e+00,  3.3550448e+00,  2.8928797e+00]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc #patterns extracted based on the frequency and time characteristics to uniquely identify the audio signals to corresponding class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.conda/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.conda/lib/python3.11/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing what we did above throughout all files in the audio folder\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "audio_dataset_path = 'UrbanSound8K/audio/'\n",
    "metadata = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define feature extraction function, which takes a file name and uses librosa to get the audio and sample rate. We will use MFCC to get the mfcc features. Then, we will take the mean of the transpose of the MFCCs to get the scaled features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extract(file):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "    mfcc_features = librosa.feature.mfcc(y=audio, sr = sample_rate, n_mfcc = 40)\n",
    "    mfcc_scaled_features = np.mean(mfcc_features.T, axis = 0)\n",
    "\n",
    "    return mfcc_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in ./.conda/lib/python3.11/site-packages (4.67.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: resampy in ./.conda/lib/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.conda/lib/python3.11/site-packages (from resampy) (2.0.2)\n",
      "Requirement already satisfied: numba>=0.53 in ./.conda/lib/python3.11/site-packages (from resampy) (0.60.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./.conda/lib/python3.11/site-packages (from numba>=0.53->resampy) (0.43.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install resampy #librosa depends on resampy for resampling audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3555it [01:48, 32.96it/s]/Users/palakprashant/Audio_Classification/Audio_Classification_Deep_Learning/.conda/lib/python3.11/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "8324it [04:16, 45.07it/s]/Users/palakprashant/Audio_Classification/Audio_Classification_Deep_Learning/.conda/lib/python3.11/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "/Users/palakprashant/Audio_Classification/Audio_Classification_Deep_Learning/.conda/lib/python3.11/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n",
      "8732it [04:27, 32.59it/s]\n"
     ]
    }
   ],
   "source": [
    "#iterate through the csv file to extract the audio file and extract corresponding features\n",
    "from tqdm import tqdm\n",
    "import resampy\n",
    "extracted_features = []\n",
    "for index, row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"])) #we will take the dataset path and map it with folder, folder number, and get the slice_file_name\n",
    "    final_class_labels = row['class']\n",
    "    data=features_extract(file_name)\n",
    "    extracted_features.append([data, final_class_labels]) #appending dependent and independent features into a list, we will make a dataset out of this\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-217.35526, 70.22339, -130.38527, -53.282898,...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-424.09818, 109.34076, -52.919525, 60.86475, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-458.79114, 121.3842, -46.520653, 52.00812, -...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-413.89984, 101.66371, -35.42945, 53.036358, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-446.60352, 113.68541, -52.402218, 60.302044,...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature             class\n",
       "0  [-217.35526, 70.22339, -130.38527, -53.282898,...          dog_bark\n",
       "1  [-424.09818, 109.34076, -52.919525, 60.86475, ...  children_playing\n",
       "2  [-458.79114, 121.3842, -46.520653, 52.00812, -...  children_playing\n",
       "3  [-413.89984, 101.66371, -35.42945, 53.036358, ...  children_playing\n",
       "4  [-446.60352, 113.68541, -52.402218, 60.302044,...  children_playing"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting the extracted features into a dataset\n",
    "efdf = pd.DataFrame(extracted_features, columns = ['feature', 'class'])\n",
    "efdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split efdf into independent and dependent features\n",
    "X = np.array(efdf['feature'].tolist())\n",
    "y = np.array(efdf['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 40)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding dependent variable\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape #10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6985, 40)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1747, 40)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6985, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1747, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3110471e+02,  1.1250591e+02, -2.2574696e+01, ...,\n",
       "         3.2466526e+00, -1.3690237e+00,  2.7557547e+00],\n",
       "       [-1.3670342e+01,  9.1085083e+01, -7.7927332e+00, ...,\n",
       "        -3.2530508e+00, -5.2774529e+00, -1.5569718e+00],\n",
       "       [-4.9871544e+01,  2.6535299e-01, -2.0500937e+01, ...,\n",
       "         2.8545945e+00, -1.6092044e+00,  3.5248058e+00],\n",
       "       ...,\n",
       "       [-4.2701236e+02,  9.2623047e+01,  3.1293974e+00, ...,\n",
       "         7.4264091e-01,  7.3349088e-01,  7.1100920e-01],\n",
       "       [-1.4575461e+02,  1.3626578e+02, -3.3515522e+01, ...,\n",
       "         1.4681193e+00, -2.0091701e+00, -8.8218188e-01],\n",
       "       [-4.2103134e+02,  2.1065454e+02,  3.4906609e+00, ...,\n",
       "        -5.3888669e+00, -3.3713605e+00, -1.5665118e+00]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train #independent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./.conda/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.conda/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.conda/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.conda/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.conda/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.conda/lib/python3.11/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.conda/lib/python3.11/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./.conda/lib/python3.11/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.conda/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.conda/lib/python3.11/site-packages (from tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in ./.conda/lib/python3.11/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.conda/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in ./.conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in ./.conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in ./.conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages to create ANN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get number of labels/classes\n",
    "num_labels = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/palakprashant/Audio_Classification/Audio_Classification_Deep_Learning/.conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Creating ANN with 3 dense layers\n",
    "model = Sequential()\n",
    "#first layer\n",
    "model.add(Dense(100, input_shape = (40,))) #100 neurons, and input shape is 40 since training dataset has 40 features\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5)) #question - why is dropout used?\n",
    "#second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "#final output layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax')) #we use softmax since this is a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m4,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m20,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,410</span> (177.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,410\u001b[0m (177.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,410</span> (177.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m45,410\u001b[0m (177.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m163/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.1230 - loss: 31.7726 \n",
      "Epoch 1: val_loss improved from inf to 2.29238, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1217 - loss: 27.3090 - val_accuracy: 0.1196 - val_loss: 2.2924\n",
      "Epoch 2/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.1223 - loss: 2.9087\n",
      "Epoch 2: val_loss improved from 2.29238 to 2.27919, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.1213 - loss: 2.8499 - val_accuracy: 0.1191 - val_loss: 2.2792\n",
      "Epoch 3/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.1116 - loss: 2.3654\n",
      "Epoch 3: val_loss improved from 2.27919 to 2.23563, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.1131 - loss: 2.3597 - val_accuracy: 0.1151 - val_loss: 2.2356\n",
      "Epoch 4/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.1181 - loss: 2.3195\n",
      "Epoch 4: val_loss improved from 2.23563 to 2.21180, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.1185 - loss: 2.3138 - val_accuracy: 0.1133 - val_loss: 2.2118\n",
      "Epoch 5/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.1203 - loss: 2.2659\n",
      "Epoch 5: val_loss improved from 2.21180 to 2.17572, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.1239 - loss: 2.2621 - val_accuracy: 0.1551 - val_loss: 2.1757\n",
      "Epoch 6/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.1394 - loss: 2.2326\n",
      "Epoch 6: val_loss improved from 2.17572 to 2.14507, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.1439 - loss: 2.2268 - val_accuracy: 0.1677 - val_loss: 2.1451\n",
      "Epoch 7/1000\n",
      "\u001b[1m164/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.1560 - loss: 2.2042\n",
      "Epoch 7: val_loss improved from 2.14507 to 2.12057, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.1574 - loss: 2.1982 - val_accuracy: 0.1626 - val_loss: 2.1206\n",
      "Epoch 8/1000\n",
      "\u001b[1m159/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.1613 - loss: 2.1732\n",
      "Epoch 8: val_loss improved from 2.12057 to 2.10826, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.1622 - loss: 2.1726 - val_accuracy: 0.1803 - val_loss: 2.1083\n",
      "Epoch 9/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.1555 - loss: 2.1612\n",
      "Epoch 9: val_loss improved from 2.10826 to 2.07446, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.1606 - loss: 2.1544 - val_accuracy: 0.1969 - val_loss: 2.0745\n",
      "Epoch 10/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.1891 - loss: 2.1289\n",
      "Epoch 10: val_loss improved from 2.07446 to 2.05320, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.1891 - loss: 2.1288 - val_accuracy: 0.2112 - val_loss: 2.0532\n",
      "Epoch 11/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.1956 - loss: 2.0859\n",
      "Epoch 11: val_loss improved from 2.05320 to 2.02184, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.1978 - loss: 2.0883 - val_accuracy: 0.2381 - val_loss: 2.0218\n",
      "Epoch 12/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.2270 - loss: 2.0860\n",
      "Epoch 12: val_loss improved from 2.02184 to 1.99438, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.2252 - loss: 2.0852 - val_accuracy: 0.2536 - val_loss: 1.9944\n",
      "Epoch 13/1000\n",
      "\u001b[1m154/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.2231 - loss: 2.0625\n",
      "Epoch 13: val_loss improved from 1.99438 to 1.92339, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.2250 - loss: 2.0560 - val_accuracy: 0.2324 - val_loss: 1.9234\n",
      "Epoch 14/1000\n",
      "\u001b[1m145/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.2495 - loss: 2.0005\n",
      "Epoch 14: val_loss improved from 1.92339 to 1.87862, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.2487 - loss: 2.0013 - val_accuracy: 0.2736 - val_loss: 1.8786\n",
      "Epoch 15/1000\n",
      "\u001b[1m138/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.2654 - loss: 1.9438\n",
      "Epoch 15: val_loss improved from 1.87862 to 1.85945, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.2648 - loss: 1.9492 - val_accuracy: 0.3148 - val_loss: 1.8594\n",
      "Epoch 16/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.2785 - loss: 1.9532\n",
      "Epoch 16: val_loss improved from 1.85945 to 1.79117, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.2798 - loss: 1.9462 - val_accuracy: 0.3429 - val_loss: 1.7912\n",
      "Epoch 17/1000\n",
      "\u001b[1m141/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.3017 - loss: 1.9041\n",
      "Epoch 17: val_loss improved from 1.79117 to 1.73237, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.3027 - loss: 1.8981 - val_accuracy: 0.4053 - val_loss: 1.7324\n",
      "Epoch 18/1000\n",
      "\u001b[1m152/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.3325 - loss: 1.8343\n",
      "Epoch 18: val_loss improved from 1.73237 to 1.66720, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.3313 - loss: 1.8325 - val_accuracy: 0.4442 - val_loss: 1.6672\n",
      "Epoch 19/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.3468 - loss: 1.7798\n",
      "Epoch 19: val_loss improved from 1.66720 to 1.56885, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.3481 - loss: 1.7784 - val_accuracy: 0.4728 - val_loss: 1.5689\n",
      "Epoch 20/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.3713 - loss: 1.7221\n",
      "Epoch 20: val_loss improved from 1.56885 to 1.49216, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.3714 - loss: 1.7220 - val_accuracy: 0.4860 - val_loss: 1.4922\n",
      "Epoch 21/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.3849 - loss: 1.6843\n",
      "Epoch 21: val_loss did not improve from 1.49216\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.3887 - loss: 1.6761 - val_accuracy: 0.5152 - val_loss: 1.5057\n",
      "Epoch 22/1000\n",
      "\u001b[1m167/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.4186 - loss: 1.6062\n",
      "Epoch 22: val_loss improved from 1.49216 to 1.47049, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.4184 - loss: 1.6097 - val_accuracy: 0.5169 - val_loss: 1.4705\n",
      "Epoch 23/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.4197 - loss: 1.6191\n",
      "Epoch 23: val_loss improved from 1.47049 to 1.42010, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.4230 - loss: 1.6129 - val_accuracy: 0.5100 - val_loss: 1.4201\n",
      "Epoch 24/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.4390 - loss: 1.5750\n",
      "Epoch 24: val_loss improved from 1.42010 to 1.36946, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.4382 - loss: 1.5732 - val_accuracy: 0.5363 - val_loss: 1.3695\n",
      "Epoch 25/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.4641 - loss: 1.5275\n",
      "Epoch 25: val_loss improved from 1.36946 to 1.32122, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.4635 - loss: 1.5275 - val_accuracy: 0.5575 - val_loss: 1.3212\n",
      "Epoch 26/1000\n",
      "\u001b[1m154/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.4642 - loss: 1.5215\n",
      "Epoch 26: val_loss did not improve from 1.32122\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.4642 - loss: 1.5206 - val_accuracy: 0.5718 - val_loss: 1.3213\n",
      "Epoch 27/1000\n",
      "\u001b[1m152/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.4697 - loss: 1.4895\n",
      "Epoch 27: val_loss improved from 1.32122 to 1.28421, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.4712 - loss: 1.4882 - val_accuracy: 0.5930 - val_loss: 1.2842\n",
      "Epoch 28/1000\n",
      "\u001b[1m152/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.4675 - loss: 1.5123\n",
      "Epoch 28: val_loss improved from 1.28421 to 1.25745, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.4719 - loss: 1.5026 - val_accuracy: 0.5793 - val_loss: 1.2575\n",
      "Epoch 29/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.5013 - loss: 1.4479\n",
      "Epoch 29: val_loss did not improve from 1.25745\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.4996 - loss: 1.4531 - val_accuracy: 0.5896 - val_loss: 1.2691\n",
      "Epoch 30/1000\n",
      "\u001b[1m164/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.5250 - loss: 1.3866\n",
      "Epoch 30: val_loss improved from 1.25745 to 1.24957, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5234 - loss: 1.3886 - val_accuracy: 0.5799 - val_loss: 1.2496\n",
      "Epoch 31/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.5137 - loss: 1.4086\n",
      "Epoch 31: val_loss improved from 1.24957 to 1.17507, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.5149 - loss: 1.4050 - val_accuracy: 0.6359 - val_loss: 1.1751\n",
      "Epoch 32/1000\n",
      "\u001b[1m154/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.5428 - loss: 1.3638\n",
      "Epoch 32: val_loss improved from 1.17507 to 1.15046, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.5412 - loss: 1.3616 - val_accuracy: 0.6377 - val_loss: 1.1505\n",
      "Epoch 33/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.5319 - loss: 1.3599\n",
      "Epoch 33: val_loss did not improve from 1.15046\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.5340 - loss: 1.3538 - val_accuracy: 0.6354 - val_loss: 1.1571\n",
      "Epoch 34/1000\n",
      "\u001b[1m162/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.5490 - loss: 1.3537\n",
      "Epoch 34: val_loss improved from 1.15046 to 1.09381, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.5505 - loss: 1.3471 - val_accuracy: 0.6623 - val_loss: 1.0938\n",
      "Epoch 35/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.5438 - loss: 1.3334\n",
      "Epoch 35: val_loss did not improve from 1.09381\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.5455 - loss: 1.3295 - val_accuracy: 0.6457 - val_loss: 1.1014\n",
      "Epoch 36/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.5696 - loss: 1.3086\n",
      "Epoch 36: val_loss improved from 1.09381 to 1.08522, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.5676 - loss: 1.3032 - val_accuracy: 0.6508 - val_loss: 1.0852\n",
      "Epoch 37/1000\n",
      "\u001b[1m136/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.5749 - loss: 1.2998\n",
      "Epoch 37: val_loss did not improve from 1.08522\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.5723 - loss: 1.2910 - val_accuracy: 0.6325 - val_loss: 1.1001\n",
      "Epoch 38/1000\n",
      "\u001b[1m159/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.5780 - loss: 1.2324\n",
      "Epoch 38: val_loss improved from 1.08522 to 1.07385, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.5771 - loss: 1.2388 - val_accuracy: 0.6463 - val_loss: 1.0739\n",
      "Epoch 39/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.5844 - loss: 1.2451\n",
      "Epoch 39: val_loss improved from 1.07385 to 1.05317, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.5815 - loss: 1.2489 - val_accuracy: 0.6394 - val_loss: 1.0532\n",
      "Epoch 40/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.5890 - loss: 1.2376\n",
      "Epoch 40: val_loss improved from 1.05317 to 1.02176, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.5878 - loss: 1.2335 - val_accuracy: 0.6726 - val_loss: 1.0218\n",
      "Epoch 41/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.5900 - loss: 1.2263\n",
      "Epoch 41: val_loss did not improve from 1.02176\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.5898 - loss: 1.2268 - val_accuracy: 0.6674 - val_loss: 1.0331\n",
      "Epoch 42/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.5597 - loss: 1.2337\n",
      "Epoch 42: val_loss improved from 1.02176 to 1.01843, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.5676 - loss: 1.2229 - val_accuracy: 0.6629 - val_loss: 1.0184\n",
      "Epoch 43/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.6023 - loss: 1.1988\n",
      "Epoch 43: val_loss improved from 1.01843 to 0.98285, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6023 - loss: 1.1987 - val_accuracy: 0.6783 - val_loss: 0.9828\n",
      "Epoch 44/1000\n",
      "\u001b[1m182/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.5990 - loss: 1.2237\n",
      "Epoch 44: val_loss did not improve from 0.98285\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.5987 - loss: 1.2186 - val_accuracy: 0.6920 - val_loss: 0.9859\n",
      "Epoch 45/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.6035 - loss: 1.1648\n",
      "Epoch 45: val_loss did not improve from 0.98285\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.6046 - loss: 1.1655 - val_accuracy: 0.6846 - val_loss: 0.9869\n",
      "Epoch 46/1000\n",
      "\u001b[1m159/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.6089 - loss: 1.1953\n",
      "Epoch 46: val_loss improved from 0.98285 to 0.95580, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.6101 - loss: 1.1860 - val_accuracy: 0.7144 - val_loss: 0.9558\n",
      "Epoch 47/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.6135 - loss: 1.1554\n",
      "Epoch 47: val_loss improved from 0.95580 to 0.94204, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.6141 - loss: 1.1531 - val_accuracy: 0.6938 - val_loss: 0.9420\n",
      "Epoch 48/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.6218 - loss: 1.1258\n",
      "Epoch 48: val_loss improved from 0.94204 to 0.93214, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.6212 - loss: 1.1272 - val_accuracy: 0.7081 - val_loss: 0.9321\n",
      "Epoch 49/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.6160 - loss: 1.1459\n",
      "Epoch 49: val_loss did not improve from 0.93214\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.6159 - loss: 1.1460 - val_accuracy: 0.6972 - val_loss: 0.9574\n",
      "Epoch 50/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.6084 - loss: 1.1513\n",
      "Epoch 50: val_loss did not improve from 0.93214\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6087 - loss: 1.1511 - val_accuracy: 0.6989 - val_loss: 0.9329\n",
      "Epoch 51/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.6317 - loss: 1.1223\n",
      "Epoch 51: val_loss improved from 0.93214 to 0.92216, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6318 - loss: 1.1227 - val_accuracy: 0.7001 - val_loss: 0.9222\n",
      "Epoch 52/1000\n",
      "\u001b[1m140/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.6316 - loss: 1.0934\n",
      "Epoch 52: val_loss did not improve from 0.92216\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.6310 - loss: 1.0975 - val_accuracy: 0.7098 - val_loss: 0.9261\n",
      "Epoch 53/1000\n",
      "\u001b[1m142/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.6281 - loss: 1.1259\n",
      "Epoch 53: val_loss improved from 0.92216 to 0.89821, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.6281 - loss: 1.1178 - val_accuracy: 0.7069 - val_loss: 0.8982\n",
      "Epoch 54/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.6378 - loss: 1.0918\n",
      "Epoch 54: val_loss improved from 0.89821 to 0.88374, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.6371 - loss: 1.0928 - val_accuracy: 0.7167 - val_loss: 0.8837\n",
      "Epoch 55/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.6204 - loss: 1.0988\n",
      "Epoch 55: val_loss improved from 0.88374 to 0.87482, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.6261 - loss: 1.0922 - val_accuracy: 0.7281 - val_loss: 0.8748\n",
      "Epoch 56/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.6369 - loss: 1.0857\n",
      "Epoch 56: val_loss did not improve from 0.87482\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.6370 - loss: 1.0861 - val_accuracy: 0.7207 - val_loss: 0.8837\n",
      "Epoch 57/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.6479 - loss: 1.0641\n",
      "Epoch 57: val_loss did not improve from 0.87482\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.6460 - loss: 1.0674 - val_accuracy: 0.7058 - val_loss: 0.8951\n",
      "Epoch 58/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.6417 - loss: 1.0950\n",
      "Epoch 58: val_loss did not improve from 0.87482\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.6421 - loss: 1.0918 - val_accuracy: 0.7098 - val_loss: 0.8823\n",
      "Epoch 59/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.6413 - loss: 1.0782\n",
      "Epoch 59: val_loss did not improve from 0.87482\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.6405 - loss: 1.0797 - val_accuracy: 0.7092 - val_loss: 0.9066\n",
      "Epoch 60/1000\n",
      "\u001b[1m169/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.6377 - loss: 1.0968\n",
      "Epoch 60: val_loss did not improve from 0.87482\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.6386 - loss: 1.0947 - val_accuracy: 0.7189 - val_loss: 0.8922\n",
      "Epoch 61/1000\n",
      "\u001b[1m143/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.6558 - loss: 1.0338\n",
      "Epoch 61: val_loss improved from 0.87482 to 0.85155, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.6562 - loss: 1.0347 - val_accuracy: 0.7275 - val_loss: 0.8516\n",
      "Epoch 62/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6558 - loss: 1.0356\n",
      "Epoch 62: val_loss did not improve from 0.85155\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6563 - loss: 1.0429 - val_accuracy: 0.7350 - val_loss: 0.8784\n",
      "Epoch 63/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.6478 - loss: 1.0533\n",
      "Epoch 63: val_loss did not improve from 0.85155\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.6476 - loss: 1.0536 - val_accuracy: 0.7212 - val_loss: 0.8527\n",
      "Epoch 64/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.6512 - loss: 1.0446\n",
      "Epoch 64: val_loss did not improve from 0.85155\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.6521 - loss: 1.0440 - val_accuracy: 0.7252 - val_loss: 0.8607\n",
      "Epoch 65/1000\n",
      "\u001b[1m162/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.6461 - loss: 1.0290\n",
      "Epoch 65: val_loss did not improve from 0.85155\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.6471 - loss: 1.0323 - val_accuracy: 0.7258 - val_loss: 0.8632\n",
      "Epoch 66/1000\n",
      "\u001b[1m166/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.6420 - loss: 1.0566\n",
      "Epoch 66: val_loss improved from 0.85155 to 0.82440, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.6431 - loss: 1.0572 - val_accuracy: 0.7344 - val_loss: 0.8244\n",
      "Epoch 67/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.6688 - loss: 1.0075\n",
      "Epoch 67: val_loss did not improve from 0.82440\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.6659 - loss: 1.0166 - val_accuracy: 0.7504 - val_loss: 0.8440\n",
      "Epoch 68/1000\n",
      "\u001b[1m144/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.6590 - loss: 1.0322\n",
      "Epoch 68: val_loss improved from 0.82440 to 0.82189, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.6598 - loss: 1.0281 - val_accuracy: 0.7441 - val_loss: 0.8219\n",
      "Epoch 69/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.6676 - loss: 1.0004\n",
      "Epoch 69: val_loss did not improve from 0.82189\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.6671 - loss: 1.0024 - val_accuracy: 0.7413 - val_loss: 0.8391\n",
      "Epoch 70/1000\n",
      "\u001b[1m166/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.6602 - loss: 1.0277\n",
      "Epoch 70: val_loss did not improve from 0.82189\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.6591 - loss: 1.0285 - val_accuracy: 0.7207 - val_loss: 0.8242\n",
      "Epoch 71/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.6528 - loss: 1.0690\n",
      "Epoch 71: val_loss did not improve from 0.82189\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.6516 - loss: 1.0675 - val_accuracy: 0.7361 - val_loss: 0.8411\n",
      "Epoch 72/1000\n",
      "\u001b[1m171/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.6450 - loss: 1.0540\n",
      "Epoch 72: val_loss did not improve from 0.82189\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.6473 - loss: 1.0509 - val_accuracy: 0.7350 - val_loss: 0.8457\n",
      "Epoch 73/1000\n",
      "\u001b[1m162/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.6463 - loss: 1.0361\n",
      "Epoch 73: val_loss improved from 0.82189 to 0.80370, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.6489 - loss: 1.0344 - val_accuracy: 0.7521 - val_loss: 0.8037\n",
      "Epoch 74/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.6708 - loss: 0.9938\n",
      "Epoch 74: val_loss did not improve from 0.80370\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.6677 - loss: 0.9990 - val_accuracy: 0.7321 - val_loss: 0.8234\n",
      "Epoch 75/1000\n",
      "\u001b[1m162/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.6396 - loss: 1.0568\n",
      "Epoch 75: val_loss did not improve from 0.80370\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.6439 - loss: 1.0512 - val_accuracy: 0.7447 - val_loss: 0.8273\n",
      "Epoch 76/1000\n",
      "\u001b[1m172/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.6662 - loss: 0.9997\n",
      "Epoch 76: val_loss did not improve from 0.80370\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.6654 - loss: 1.0048 - val_accuracy: 0.7544 - val_loss: 0.8278\n",
      "Epoch 77/1000\n",
      "\u001b[1m162/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.6581 - loss: 1.0355\n",
      "Epoch 77: val_loss did not improve from 0.80370\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.6600 - loss: 1.0304 - val_accuracy: 0.7470 - val_loss: 0.8286\n",
      "Epoch 78/1000\n",
      "\u001b[1m168/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.6583 - loss: 1.0339\n",
      "Epoch 78: val_loss did not improve from 0.80370\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.6591 - loss: 1.0302 - val_accuracy: 0.7521 - val_loss: 0.8188\n",
      "Epoch 79/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.6736 - loss: 1.0111\n",
      "Epoch 79: val_loss did not improve from 0.80370\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.6731 - loss: 1.0120 - val_accuracy: 0.7453 - val_loss: 0.8503\n",
      "Epoch 80/1000\n",
      "\u001b[1m161/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.6836 - loss: 0.9641\n",
      "Epoch 80: val_loss did not improve from 0.80370\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.6819 - loss: 0.9678 - val_accuracy: 0.7499 - val_loss: 0.8038\n",
      "Epoch 81/1000\n",
      "\u001b[1m169/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.6600 - loss: 0.9871\n",
      "Epoch 81: val_loss did not improve from 0.80370\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.6584 - loss: 0.9949 - val_accuracy: 0.7487 - val_loss: 0.8327\n",
      "Epoch 82/1000\n",
      "\u001b[1m162/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.6794 - loss: 0.9608\n",
      "Epoch 82: val_loss improved from 0.80370 to 0.79832, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.6792 - loss: 0.9625 - val_accuracy: 0.7567 - val_loss: 0.7983\n",
      "Epoch 83/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.6577 - loss: 1.0333\n",
      "Epoch 83: val_loss improved from 0.79832 to 0.78236, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.6617 - loss: 1.0236 - val_accuracy: 0.7539 - val_loss: 0.7824\n",
      "Epoch 84/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.6786 - loss: 0.9834\n",
      "Epoch 84: val_loss did not improve from 0.78236\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.6789 - loss: 0.9825 - val_accuracy: 0.7459 - val_loss: 0.8348\n",
      "Epoch 85/1000\n",
      "\u001b[1m142/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.6546 - loss: 1.0100\n",
      "Epoch 85: val_loss did not improve from 0.78236\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.6562 - loss: 1.0033 - val_accuracy: 0.7390 - val_loss: 0.8040\n",
      "Epoch 86/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.6687 - loss: 0.9974\n",
      "Epoch 86: val_loss did not improve from 0.78236\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.6712 - loss: 0.9919 - val_accuracy: 0.7481 - val_loss: 0.7902\n",
      "Epoch 87/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.6842 - loss: 0.9733\n",
      "Epoch 87: val_loss improved from 0.78236 to 0.77969, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.6803 - loss: 0.9780 - val_accuracy: 0.7699 - val_loss: 0.7797\n",
      "Epoch 88/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.6514 - loss: 1.0411\n",
      "Epoch 88: val_loss improved from 0.77969 to 0.77201, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.6571 - loss: 1.0280 - val_accuracy: 0.7630 - val_loss: 0.7720\n",
      "Epoch 89/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.6850 - loss: 0.9685\n",
      "Epoch 89: val_loss did not improve from 0.77201\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.6835 - loss: 0.9713 - val_accuracy: 0.7539 - val_loss: 0.8036\n",
      "Epoch 90/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.6799 - loss: 0.9687\n",
      "Epoch 90: val_loss did not improve from 0.77201\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.6798 - loss: 0.9688 - val_accuracy: 0.7624 - val_loss: 0.7742\n",
      "Epoch 91/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.6964 - loss: 0.9537\n",
      "Epoch 91: val_loss did not improve from 0.77201\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.6957 - loss: 0.9548 - val_accuracy: 0.7579 - val_loss: 0.7754\n",
      "Epoch 92/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.6683 - loss: 1.0084\n",
      "Epoch 92: val_loss did not improve from 0.77201\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6689 - loss: 1.0067 - val_accuracy: 0.7590 - val_loss: 0.7827\n",
      "Epoch 93/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.6752 - loss: 1.0005\n",
      "Epoch 93: val_loss did not improve from 0.77201\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.6766 - loss: 0.9896 - val_accuracy: 0.7544 - val_loss: 0.7970\n",
      "Epoch 94/1000\n",
      "\u001b[1m164/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.6855 - loss: 0.9341\n",
      "Epoch 94: val_loss did not improve from 0.77201\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.6862 - loss: 0.9342 - val_accuracy: 0.7682 - val_loss: 0.7834\n",
      "Epoch 95/1000\n",
      "\u001b[1m161/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.6832 - loss: 1.0172\n",
      "Epoch 95: val_loss did not improve from 0.77201\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.6827 - loss: 1.0131 - val_accuracy: 0.7516 - val_loss: 0.7921\n",
      "Epoch 96/1000\n",
      "\u001b[1m169/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.6757 - loss: 0.9811\n",
      "Epoch 96: val_loss did not improve from 0.77201\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.6767 - loss: 0.9752 - val_accuracy: 0.7436 - val_loss: 0.7919\n",
      "Epoch 97/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.6839 - loss: 0.9555\n",
      "Epoch 97: val_loss did not improve from 0.77201\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.6828 - loss: 0.9594 - val_accuracy: 0.7642 - val_loss: 0.7763\n",
      "Epoch 98/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.6843 - loss: 0.9543\n",
      "Epoch 98: val_loss improved from 0.77201 to 0.75702, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.6836 - loss: 0.9573 - val_accuracy: 0.7596 - val_loss: 0.7570\n",
      "Epoch 99/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.6827 - loss: 0.9660\n",
      "Epoch 99: val_loss did not improve from 0.75702\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.6849 - loss: 0.9615 - val_accuracy: 0.7590 - val_loss: 0.7825\n",
      "Epoch 100/1000\n",
      "\u001b[1m163/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.6690 - loss: 0.9847\n",
      "Epoch 100: val_loss did not improve from 0.75702\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.6699 - loss: 0.9840 - val_accuracy: 0.7659 - val_loss: 0.7682\n",
      "Epoch 101/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.6885 - loss: 0.9574\n",
      "Epoch 101: val_loss did not improve from 0.75702\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.6882 - loss: 0.9578 - val_accuracy: 0.7670 - val_loss: 0.7733\n",
      "Epoch 102/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.6889 - loss: 0.9722\n",
      "Epoch 102: val_loss did not improve from 0.75702\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.6881 - loss: 0.9641 - val_accuracy: 0.7705 - val_loss: 0.7685\n",
      "Epoch 103/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.7002 - loss: 0.8986\n",
      "Epoch 103: val_loss improved from 0.75702 to 0.75329, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.6991 - loss: 0.9065 - val_accuracy: 0.7722 - val_loss: 0.7533\n",
      "Epoch 104/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.7012 - loss: 0.9200\n",
      "Epoch 104: val_loss improved from 0.75329 to 0.74807, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.6967 - loss: 0.9262 - val_accuracy: 0.7687 - val_loss: 0.7481\n",
      "Epoch 105/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.6830 - loss: 0.9593\n",
      "Epoch 105: val_loss did not improve from 0.74807\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.6833 - loss: 0.9575 - val_accuracy: 0.7665 - val_loss: 0.7557\n",
      "Epoch 106/1000\n",
      "\u001b[1m163/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.6980 - loss: 0.9100\n",
      "Epoch 106: val_loss improved from 0.74807 to 0.72872, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.6967 - loss: 0.9149 - val_accuracy: 0.7779 - val_loss: 0.7287\n",
      "Epoch 107/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.6883 - loss: 0.9418\n",
      "Epoch 107: val_loss did not improve from 0.72872\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.6882 - loss: 0.9435 - val_accuracy: 0.7836 - val_loss: 0.7355\n",
      "Epoch 108/1000\n",
      "\u001b[1m159/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.6963 - loss: 0.9328\n",
      "Epoch 108: val_loss did not improve from 0.72872\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.6937 - loss: 0.9352 - val_accuracy: 0.7642 - val_loss: 0.7421\n",
      "Epoch 109/1000\n",
      "\u001b[1m166/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.6812 - loss: 0.9681\n",
      "Epoch 109: val_loss did not improve from 0.72872\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.6827 - loss: 0.9623 - val_accuracy: 0.7682 - val_loss: 0.7364\n",
      "Epoch 110/1000\n",
      "\u001b[1m145/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.6957 - loss: 0.9088\n",
      "Epoch 110: val_loss improved from 0.72872 to 0.72617, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.6971 - loss: 0.9135 - val_accuracy: 0.7796 - val_loss: 0.7262\n",
      "Epoch 111/1000\n",
      "\u001b[1m177/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.6957 - loss: 0.9252\n",
      "Epoch 111: val_loss did not improve from 0.72617\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6949 - loss: 0.9277 - val_accuracy: 0.7773 - val_loss: 0.7406\n",
      "Epoch 112/1000\n",
      "\u001b[1m152/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.6931 - loss: 0.9349\n",
      "Epoch 112: val_loss did not improve from 0.72617\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.6922 - loss: 0.9387 - val_accuracy: 0.7745 - val_loss: 0.7618\n",
      "Epoch 113/1000\n",
      "\u001b[1m167/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.6948 - loss: 0.9534\n",
      "Epoch 113: val_loss did not improve from 0.72617\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.6923 - loss: 0.9554 - val_accuracy: 0.7819 - val_loss: 0.7401\n",
      "Epoch 114/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.7117 - loss: 0.8853\n",
      "Epoch 114: val_loss did not improve from 0.72617\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.7092 - loss: 0.8906 - val_accuracy: 0.7693 - val_loss: 0.7308\n",
      "Epoch 115/1000\n",
      "\u001b[1m168/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.7036 - loss: 0.8944\n",
      "Epoch 115: val_loss did not improve from 0.72617\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.7007 - loss: 0.9062 - val_accuracy: 0.7733 - val_loss: 0.7443\n",
      "Epoch 116/1000\n",
      "\u001b[1m168/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.6948 - loss: 0.9128\n",
      "Epoch 116: val_loss did not improve from 0.72617\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.6943 - loss: 0.9147 - val_accuracy: 0.7779 - val_loss: 0.7373\n",
      "Epoch 117/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.6909 - loss: 0.9278\n",
      "Epoch 117: val_loss did not improve from 0.72617\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.6912 - loss: 0.9274 - val_accuracy: 0.7768 - val_loss: 0.7336\n",
      "Epoch 118/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.6859 - loss: 0.9129\n",
      "Epoch 118: val_loss did not improve from 0.72617\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6860 - loss: 0.9130 - val_accuracy: 0.7745 - val_loss: 0.7406\n",
      "Epoch 119/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.6913 - loss: 0.9439\n",
      "Epoch 119: val_loss did not improve from 0.72617\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.6914 - loss: 0.9414 - val_accuracy: 0.7871 - val_loss: 0.7376\n",
      "Epoch 120/1000\n",
      "\u001b[1m159/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.6867 - loss: 0.9546\n",
      "Epoch 120: val_loss did not improve from 0.72617\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.6893 - loss: 0.9471 - val_accuracy: 0.7653 - val_loss: 0.7574\n",
      "Epoch 121/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.7008 - loss: 0.9179\n",
      "Epoch 121: val_loss improved from 0.72617 to 0.71930, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.7014 - loss: 0.9171 - val_accuracy: 0.7831 - val_loss: 0.7193\n",
      "Epoch 122/1000\n",
      "\u001b[1m154/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.6923 - loss: 0.9416\n",
      "Epoch 122: val_loss did not improve from 0.71930\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.6934 - loss: 0.9376 - val_accuracy: 0.7790 - val_loss: 0.7343\n",
      "Epoch 123/1000\n",
      "\u001b[1m159/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.7063 - loss: 0.8974\n",
      "Epoch 123: val_loss did not improve from 0.71930\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.7046 - loss: 0.9020 - val_accuracy: 0.7882 - val_loss: 0.7351\n",
      "Epoch 124/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.7087 - loss: 0.9117\n",
      "Epoch 124: val_loss did not improve from 0.71930\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.7070 - loss: 0.9139 - val_accuracy: 0.7842 - val_loss: 0.7328\n",
      "Epoch 125/1000\n",
      "\u001b[1m139/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.6887 - loss: 0.9530\n",
      "Epoch 125: val_loss did not improve from 0.71930\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.6929 - loss: 0.9433 - val_accuracy: 0.7756 - val_loss: 0.7299\n",
      "Epoch 126/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.7093 - loss: 0.8964\n",
      "Epoch 126: val_loss did not improve from 0.71930\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.7089 - loss: 0.8979 - val_accuracy: 0.7745 - val_loss: 0.7318\n",
      "Epoch 127/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.7058 - loss: 0.9025\n",
      "Epoch 127: val_loss did not improve from 0.71930\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.7043 - loss: 0.9066 - val_accuracy: 0.7831 - val_loss: 0.7266\n",
      "Epoch 128/1000\n",
      "\u001b[1m159/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.7115 - loss: 0.9090\n",
      "Epoch 128: val_loss did not improve from 0.71930\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.7076 - loss: 0.9144 - val_accuracy: 0.7831 - val_loss: 0.7328\n",
      "Epoch 129/1000\n",
      "\u001b[1m163/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.7022 - loss: 0.8909\n",
      "Epoch 129: val_loss did not improve from 0.71930\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.7014 - loss: 0.8950 - val_accuracy: 0.7773 - val_loss: 0.7416\n",
      "Epoch 130/1000\n",
      "\u001b[1m161/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.6951 - loss: 0.9203\n",
      "Epoch 130: val_loss did not improve from 0.71930\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.6971 - loss: 0.9155 - val_accuracy: 0.7796 - val_loss: 0.7334\n",
      "Epoch 131/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.6973 - loss: 0.9274\n",
      "Epoch 131: val_loss did not improve from 0.71930\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.6967 - loss: 0.9281 - val_accuracy: 0.7859 - val_loss: 0.7314\n",
      "Epoch 132/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.6927 - loss: 0.9006\n",
      "Epoch 132: val_loss did not improve from 0.71930\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.6912 - loss: 0.9068 - val_accuracy: 0.7836 - val_loss: 0.7340\n",
      "Epoch 133/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.6951 - loss: 0.9170\n",
      "Epoch 133: val_loss did not improve from 0.71930\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.6961 - loss: 0.9169 - val_accuracy: 0.7779 - val_loss: 0.7304\n",
      "Epoch 134/1000\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.7022 - loss: 0.9040\n",
      "Epoch 134: val_loss improved from 0.71930 to 0.71814, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7024 - loss: 0.9044 - val_accuracy: 0.7831 - val_loss: 0.7181\n",
      "Epoch 135/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.6976 - loss: 0.9036\n",
      "Epoch 135: val_loss did not improve from 0.71814\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6977 - loss: 0.9092 - val_accuracy: 0.7762 - val_loss: 0.7303\n",
      "Epoch 136/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.6880 - loss: 0.9320\n",
      "Epoch 136: val_loss did not improve from 0.71814\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.6905 - loss: 0.9233 - val_accuracy: 0.7779 - val_loss: 0.7270\n",
      "Epoch 137/1000\n",
      "\u001b[1m168/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.7086 - loss: 0.9004\n",
      "Epoch 137: val_loss improved from 0.71814 to 0.71729, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7058 - loss: 0.9023 - val_accuracy: 0.7813 - val_loss: 0.7173\n",
      "Epoch 138/1000\n",
      "\u001b[1m154/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.7153 - loss: 0.8949\n",
      "Epoch 138: val_loss improved from 0.71729 to 0.71573, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.7108 - loss: 0.8963 - val_accuracy: 0.7785 - val_loss: 0.7157\n",
      "Epoch 139/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.7100 - loss: 0.8693\n",
      "Epoch 139: val_loss did not improve from 0.71573\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.7064 - loss: 0.8844 - val_accuracy: 0.7728 - val_loss: 0.7268\n",
      "Epoch 140/1000\n",
      "\u001b[1m167/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.7027 - loss: 0.8853\n",
      "Epoch 140: val_loss did not improve from 0.71573\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.7031 - loss: 0.8869 - val_accuracy: 0.7813 - val_loss: 0.7183\n",
      "Epoch 141/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.7059 - loss: 0.9004\n",
      "Epoch 141: val_loss improved from 0.71573 to 0.70860, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7038 - loss: 0.9015 - val_accuracy: 0.7928 - val_loss: 0.7086\n",
      "Epoch 142/1000\n",
      "\u001b[1m163/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.7199 - loss: 0.8706\n",
      "Epoch 142: val_loss improved from 0.70860 to 0.69999, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.7166 - loss: 0.8751 - val_accuracy: 0.7836 - val_loss: 0.7000\n",
      "Epoch 143/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7186 - loss: 0.8435\n",
      "Epoch 143: val_loss did not improve from 0.69999\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7138 - loss: 0.8592 - val_accuracy: 0.7699 - val_loss: 0.7324\n",
      "Epoch 144/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.7025 - loss: 0.9156\n",
      "Epoch 144: val_loss did not improve from 0.69999\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.7025 - loss: 0.9152 - val_accuracy: 0.7825 - val_loss: 0.7103\n",
      "Epoch 145/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.6956 - loss: 0.9199\n",
      "Epoch 145: val_loss did not improve from 0.69999\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.6979 - loss: 0.9158 - val_accuracy: 0.7916 - val_loss: 0.7054\n",
      "Epoch 146/1000\n",
      "\u001b[1m152/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.7037 - loss: 0.8959\n",
      "Epoch 146: val_loss did not improve from 0.69999\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.7043 - loss: 0.8964 - val_accuracy: 0.7808 - val_loss: 0.7472\n",
      "Epoch 147/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.7061 - loss: 0.8880\n",
      "Epoch 147: val_loss did not improve from 0.69999\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.7061 - loss: 0.8891 - val_accuracy: 0.7939 - val_loss: 0.7095\n",
      "Epoch 148/1000\n",
      "\u001b[1m159/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.7144 - loss: 0.8616\n",
      "Epoch 148: val_loss did not improve from 0.69999\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.7121 - loss: 0.8665 - val_accuracy: 0.7813 - val_loss: 0.7221\n",
      "Epoch 149/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.7077 - loss: 0.8598\n",
      "Epoch 149: val_loss did not improve from 0.69999\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.7070 - loss: 0.8658 - val_accuracy: 0.7848 - val_loss: 0.7149\n",
      "Epoch 150/1000\n",
      "\u001b[1m139/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.6833 - loss: 0.9714\n",
      "Epoch 150: val_loss did not improve from 0.69999\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.6911 - loss: 0.9460 - val_accuracy: 0.7836 - val_loss: 0.7152\n",
      "Epoch 151/1000\n",
      "\u001b[1m159/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.6991 - loss: 0.8864\n",
      "Epoch 151: val_loss did not improve from 0.69999\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.7000 - loss: 0.8903 - val_accuracy: 0.7785 - val_loss: 0.7135\n",
      "Epoch 152/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.7028 - loss: 0.8978\n",
      "Epoch 152: val_loss did not improve from 0.69999\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.7041 - loss: 0.8957 - val_accuracy: 0.7745 - val_loss: 0.7093\n",
      "Epoch 153/1000\n",
      "\u001b[1m162/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.7061 - loss: 0.9304\n",
      "Epoch 153: val_loss did not improve from 0.69999\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.7061 - loss: 0.9277 - val_accuracy: 0.7871 - val_loss: 0.7078\n",
      "Epoch 154/1000\n",
      "\u001b[1m163/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.7078 - loss: 0.8674\n",
      "Epoch 154: val_loss did not improve from 0.69999\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.7075 - loss: 0.8715 - val_accuracy: 0.7808 - val_loss: 0.7084\n",
      "Epoch 155/1000\n",
      "\u001b[1m175/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.7258 - loss: 0.8545\n",
      "Epoch 155: val_loss did not improve from 0.69999\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7239 - loss: 0.8578 - val_accuracy: 0.7825 - val_loss: 0.7102\n",
      "Epoch 156/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.7035 - loss: 0.8803\n",
      "Epoch 156: val_loss improved from 0.69999 to 0.69331, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.7034 - loss: 0.8782 - val_accuracy: 0.7922 - val_loss: 0.6933\n",
      "Epoch 157/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.7107 - loss: 0.9148\n",
      "Epoch 157: val_loss did not improve from 0.69331\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.7092 - loss: 0.9106 - val_accuracy: 0.7876 - val_loss: 0.6964\n",
      "Epoch 158/1000\n",
      "\u001b[1m161/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7038 - loss: 0.9220\n",
      "Epoch 158: val_loss did not improve from 0.69331\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.7036 - loss: 0.9157 - val_accuracy: 0.7916 - val_loss: 0.6966\n",
      "Epoch 159/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.7148 - loss: 0.8748\n",
      "Epoch 159: val_loss did not improve from 0.69331\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.7136 - loss: 0.8758 - val_accuracy: 0.7825 - val_loss: 0.7335\n",
      "Epoch 160/1000\n",
      "\u001b[1m168/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.7137 - loss: 0.8713\n",
      "Epoch 160: val_loss improved from 0.69331 to 0.68523, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.7136 - loss: 0.8733 - val_accuracy: 0.7956 - val_loss: 0.6852\n",
      "Epoch 161/1000\n",
      "\u001b[1m137/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.7255 - loss: 0.8415\n",
      "Epoch 161: val_loss did not improve from 0.68523\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7201 - loss: 0.8527 - val_accuracy: 0.7865 - val_loss: 0.7107\n",
      "Epoch 162/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.7105 - loss: 0.9001\n",
      "Epoch 162: val_loss did not improve from 0.68523\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.7094 - loss: 0.8993 - val_accuracy: 0.7899 - val_loss: 0.7007\n",
      "Epoch 163/1000\n",
      "\u001b[1m159/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.7131 - loss: 0.8638\n",
      "Epoch 163: val_loss did not improve from 0.68523\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.7119 - loss: 0.8685 - val_accuracy: 0.7848 - val_loss: 0.7010\n",
      "Epoch 164/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.7088 - loss: 0.8634\n",
      "Epoch 164: val_loss did not improve from 0.68523\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.7081 - loss: 0.8695 - val_accuracy: 0.7876 - val_loss: 0.7051\n",
      "Epoch 165/1000\n",
      "\u001b[1m166/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.7019 - loss: 0.8997\n",
      "Epoch 165: val_loss did not improve from 0.68523\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.7038 - loss: 0.8966 - val_accuracy: 0.7916 - val_loss: 0.6957\n",
      "Epoch 166/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.7228 - loss: 0.8385\n",
      "Epoch 166: val_loss did not improve from 0.68523\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.7218 - loss: 0.8438 - val_accuracy: 0.7853 - val_loss: 0.7099\n",
      "Epoch 167/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.7108 - loss: 0.8838\n",
      "Epoch 167: val_loss improved from 0.68523 to 0.68246, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7113 - loss: 0.8847 - val_accuracy: 0.7956 - val_loss: 0.6825\n",
      "Epoch 168/1000\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.7205 - loss: 0.8751\n",
      "Epoch 168: val_loss did not improve from 0.68246\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.7194 - loss: 0.8774 - val_accuracy: 0.7928 - val_loss: 0.6890\n",
      "Epoch 169/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.7122 - loss: 0.8611\n",
      "Epoch 169: val_loss did not improve from 0.68246\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.7132 - loss: 0.8589 - val_accuracy: 0.7825 - val_loss: 0.7036\n",
      "Epoch 170/1000\n",
      "\u001b[1m179/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.7007 - loss: 0.8782\n",
      "Epoch 170: val_loss did not improve from 0.68246\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.7019 - loss: 0.8779 - val_accuracy: 0.7871 - val_loss: 0.7055\n",
      "Epoch 171/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7144 - loss: 0.8650\n",
      "Epoch 171: val_loss did not improve from 0.68246\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.7140 - loss: 0.8654 - val_accuracy: 0.7882 - val_loss: 0.6839\n",
      "Epoch 172/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.7231 - loss: 0.8546\n",
      "Epoch 172: val_loss did not improve from 0.68246\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7196 - loss: 0.8652 - val_accuracy: 0.7876 - val_loss: 0.6965\n",
      "Epoch 173/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.7255 - loss: 0.8664\n",
      "Epoch 173: val_loss did not improve from 0.68246\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.7244 - loss: 0.8667 - val_accuracy: 0.7922 - val_loss: 0.7027\n",
      "Epoch 174/1000\n",
      "\u001b[1m159/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.7160 - loss: 0.8553\n",
      "Epoch 174: val_loss did not improve from 0.68246\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.7142 - loss: 0.8587 - val_accuracy: 0.7905 - val_loss: 0.6850\n",
      "Epoch 175/1000\n",
      "\u001b[1m161/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7243 - loss: 0.8515\n",
      "Epoch 175: val_loss improved from 0.68246 to 0.66979, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.7231 - loss: 0.8558 - val_accuracy: 0.7968 - val_loss: 0.6698\n",
      "Epoch 176/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.7112 - loss: 0.9073\n",
      "Epoch 176: val_loss did not improve from 0.66979\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.7139 - loss: 0.9011 - val_accuracy: 0.7888 - val_loss: 0.7014\n",
      "Epoch 177/1000\n",
      "\u001b[1m144/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.7300 - loss: 0.8581\n",
      "Epoch 177: val_loss did not improve from 0.66979\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.7251 - loss: 0.8687 - val_accuracy: 0.7825 - val_loss: 0.6978\n",
      "Epoch 178/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.7156 - loss: 0.8820\n",
      "Epoch 178: val_loss did not improve from 0.66979\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.7161 - loss: 0.8798 - val_accuracy: 0.7916 - val_loss: 0.6821\n",
      "Epoch 179/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.7002 - loss: 0.8902\n",
      "Epoch 179: val_loss did not improve from 0.66979\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.7027 - loss: 0.8857 - val_accuracy: 0.7871 - val_loss: 0.6951\n",
      "Epoch 180/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.7056 - loss: 0.8910\n",
      "Epoch 180: val_loss did not improve from 0.66979\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.7058 - loss: 0.8904 - val_accuracy: 0.7859 - val_loss: 0.7016\n",
      "Epoch 181/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.7089 - loss: 0.9049\n",
      "Epoch 181: val_loss improved from 0.66979 to 0.64781, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.7100 - loss: 0.8976 - val_accuracy: 0.8111 - val_loss: 0.6478\n",
      "Epoch 182/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.7233 - loss: 0.8347\n",
      "Epoch 182: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.7222 - loss: 0.8436 - val_accuracy: 0.7922 - val_loss: 0.6917\n",
      "Epoch 183/1000\n",
      "\u001b[1m167/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.7186 - loss: 0.8552\n",
      "Epoch 183: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.7174 - loss: 0.8614 - val_accuracy: 0.7934 - val_loss: 0.6970\n",
      "Epoch 184/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.7116 - loss: 0.8910\n",
      "Epoch 184: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.7108 - loss: 0.8909 - val_accuracy: 0.7905 - val_loss: 0.7029\n",
      "Epoch 185/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.7126 - loss: 0.8720\n",
      "Epoch 185: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.7129 - loss: 0.8735 - val_accuracy: 0.7934 - val_loss: 0.6854\n",
      "Epoch 186/1000\n",
      "\u001b[1m140/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.7048 - loss: 0.9034\n",
      "Epoch 186: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.7074 - loss: 0.8968 - val_accuracy: 0.7871 - val_loss: 0.6879\n",
      "Epoch 187/1000\n",
      "\u001b[1m156/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.7008 - loss: 0.8981\n",
      "Epoch 187: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.7053 - loss: 0.8878 - val_accuracy: 0.7842 - val_loss: 0.7002\n",
      "Epoch 188/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.7186 - loss: 0.8683\n",
      "Epoch 188: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.7182 - loss: 0.8707 - val_accuracy: 0.7871 - val_loss: 0.6935\n",
      "Epoch 189/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.7197 - loss: 0.8362\n",
      "Epoch 189: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.7192 - loss: 0.8403 - val_accuracy: 0.7945 - val_loss: 0.6833\n",
      "Epoch 190/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.7241 - loss: 0.8446\n",
      "Epoch 190: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.7224 - loss: 0.8504 - val_accuracy: 0.7865 - val_loss: 0.6851\n",
      "Epoch 191/1000\n",
      "\u001b[1m142/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.7191 - loss: 0.8514\n",
      "Epoch 191: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7190 - loss: 0.8537 - val_accuracy: 0.7865 - val_loss: 0.6728\n",
      "Epoch 192/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7290 - loss: 0.8239\n",
      "Epoch 192: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.7290 - loss: 0.8251 - val_accuracy: 0.7808 - val_loss: 0.6895\n",
      "Epoch 193/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.7153 - loss: 0.8933\n",
      "Epoch 193: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.7155 - loss: 0.8888 - val_accuracy: 0.7876 - val_loss: 0.6874\n",
      "Epoch 194/1000\n",
      "\u001b[1m154/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.7048 - loss: 0.8759\n",
      "Epoch 194: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.7061 - loss: 0.8724 - val_accuracy: 0.7796 - val_loss: 0.7009\n",
      "Epoch 195/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.7186 - loss: 0.8692\n",
      "Epoch 195: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.7185 - loss: 0.8693 - val_accuracy: 0.7853 - val_loss: 0.6965\n",
      "Epoch 196/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.7068 - loss: 0.8927\n",
      "Epoch 196: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.7093 - loss: 0.8851 - val_accuracy: 0.7825 - val_loss: 0.7014\n",
      "Epoch 197/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.7046 - loss: 0.9238\n",
      "Epoch 197: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.7056 - loss: 0.9205 - val_accuracy: 0.7865 - val_loss: 0.6730\n",
      "Epoch 198/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7219 - loss: 0.8547\n",
      "Epoch 198: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.7220 - loss: 0.8548 - val_accuracy: 0.7831 - val_loss: 0.6963\n",
      "Epoch 199/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.7112 - loss: 0.8748\n",
      "Epoch 199: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.7122 - loss: 0.8712 - val_accuracy: 0.8008 - val_loss: 0.6759\n",
      "Epoch 200/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.7201 - loss: 0.8409\n",
      "Epoch 200: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.7199 - loss: 0.8414 - val_accuracy: 0.7831 - val_loss: 0.6810\n",
      "Epoch 201/1000\n",
      "\u001b[1m152/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.7227 - loss: 0.8280\n",
      "Epoch 201: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.7219 - loss: 0.8359 - val_accuracy: 0.7905 - val_loss: 0.6793\n",
      "Epoch 202/1000\n",
      "\u001b[1m170/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.7208 - loss: 0.8673\n",
      "Epoch 202: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.7200 - loss: 0.8662 - val_accuracy: 0.7922 - val_loss: 0.6904\n",
      "Epoch 203/1000\n",
      "\u001b[1m152/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.7247 - loss: 0.8316\n",
      "Epoch 203: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.7252 - loss: 0.8341 - val_accuracy: 0.7945 - val_loss: 0.6611\n",
      "Epoch 204/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.7406 - loss: 0.8024\n",
      "Epoch 204: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7404 - loss: 0.8029 - val_accuracy: 0.7859 - val_loss: 0.6883\n",
      "Epoch 205/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7193 - loss: 0.9085\n",
      "Epoch 205: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.7182 - loss: 0.9002 - val_accuracy: 0.8031 - val_loss: 0.6821\n",
      "Epoch 206/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7263 - loss: 0.8522\n",
      "Epoch 206: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.7244 - loss: 0.8592 - val_accuracy: 0.7802 - val_loss: 0.7031\n",
      "Epoch 207/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.7248 - loss: 0.8313\n",
      "Epoch 207: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.7198 - loss: 0.8437 - val_accuracy: 0.7876 - val_loss: 0.6924\n",
      "Epoch 208/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.7156 - loss: 0.8532\n",
      "Epoch 208: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.7157 - loss: 0.8533 - val_accuracy: 0.7922 - val_loss: 0.6847\n",
      "Epoch 209/1000\n",
      "\u001b[1m161/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.7267 - loss: 0.8616\n",
      "Epoch 209: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.7255 - loss: 0.8634 - val_accuracy: 0.7813 - val_loss: 0.7027\n",
      "Epoch 210/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.7173 - loss: 0.8836\n",
      "Epoch 210: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.7182 - loss: 0.8736 - val_accuracy: 0.7956 - val_loss: 0.6812\n",
      "Epoch 211/1000\n",
      "\u001b[1m154/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7219 - loss: 0.8527\n",
      "Epoch 211: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.7213 - loss: 0.8562 - val_accuracy: 0.7871 - val_loss: 0.7143\n",
      "Epoch 212/1000\n",
      "\u001b[1m161/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.7257 - loss: 0.8615\n",
      "Epoch 212: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.7245 - loss: 0.8602 - val_accuracy: 0.8014 - val_loss: 0.6532\n",
      "Epoch 213/1000\n",
      "\u001b[1m163/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7100 - loss: 0.8467\n",
      "Epoch 213: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7114 - loss: 0.8500 - val_accuracy: 0.7922 - val_loss: 0.6788\n",
      "Epoch 214/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.7095 - loss: 0.8938\n",
      "Epoch 214: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.7122 - loss: 0.8827 - val_accuracy: 0.8014 - val_loss: 0.6733\n",
      "Epoch 215/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.7127 - loss: 0.8447\n",
      "Epoch 215: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.7147 - loss: 0.8468 - val_accuracy: 0.7968 - val_loss: 0.6725\n",
      "Epoch 216/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.7122 - loss: 0.9098\n",
      "Epoch 216: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.7160 - loss: 0.8943 - val_accuracy: 0.8002 - val_loss: 0.6704\n",
      "Epoch 217/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.7227 - loss: 0.8410\n",
      "Epoch 217: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.7226 - loss: 0.8413 - val_accuracy: 0.8014 - val_loss: 0.6568\n",
      "Epoch 218/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.7202 - loss: 0.8618\n",
      "Epoch 218: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.7212 - loss: 0.8616 - val_accuracy: 0.7894 - val_loss: 0.6979\n",
      "Epoch 219/1000\n",
      "\u001b[1m152/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.7317 - loss: 0.8438\n",
      "Epoch 219: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.7315 - loss: 0.8460 - val_accuracy: 0.7888 - val_loss: 0.6689\n",
      "Epoch 220/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.7139 - loss: 0.8582\n",
      "Epoch 220: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.7138 - loss: 0.8584 - val_accuracy: 0.7991 - val_loss: 0.6968\n",
      "Epoch 221/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.7149 - loss: 0.8652\n",
      "Epoch 221: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.7148 - loss: 0.8678 - val_accuracy: 0.7911 - val_loss: 0.6859\n",
      "Epoch 222/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.7176 - loss: 0.8509\n",
      "Epoch 222: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.7185 - loss: 0.8480 - val_accuracy: 0.7945 - val_loss: 0.6705\n",
      "Epoch 223/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.7099 - loss: 0.8860\n",
      "Epoch 223: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7103 - loss: 0.8867 - val_accuracy: 0.7962 - val_loss: 0.6567\n",
      "Epoch 224/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.7408 - loss: 0.8091\n",
      "Epoch 224: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.7405 - loss: 0.8098 - val_accuracy: 0.7853 - val_loss: 0.6870\n",
      "Epoch 225/1000\n",
      "\u001b[1m162/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.7166 - loss: 0.9091\n",
      "Epoch 225: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.7166 - loss: 0.8995 - val_accuracy: 0.8025 - val_loss: 0.6491\n",
      "Epoch 226/1000\n",
      "\u001b[1m154/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.7461 - loss: 0.8050\n",
      "Epoch 226: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.7420 - loss: 0.8139 - val_accuracy: 0.7922 - val_loss: 0.6715\n",
      "Epoch 227/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.7161 - loss: 0.8512\n",
      "Epoch 227: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.7169 - loss: 0.8504 - val_accuracy: 0.7894 - val_loss: 0.6916\n",
      "Epoch 228/1000\n",
      "\u001b[1m142/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.7135 - loss: 0.8893\n",
      "Epoch 228: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7177 - loss: 0.8758 - val_accuracy: 0.7968 - val_loss: 0.6646\n",
      "Epoch 229/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.7239 - loss: 0.8366\n",
      "Epoch 229: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.7255 - loss: 0.8342 - val_accuracy: 0.7997 - val_loss: 0.6631\n",
      "Epoch 230/1000\n",
      "\u001b[1m164/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.7051 - loss: 0.8706\n",
      "Epoch 230: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.7087 - loss: 0.8676 - val_accuracy: 0.8019 - val_loss: 0.6625\n",
      "Epoch 231/1000\n",
      "\u001b[1m154/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.7208 - loss: 0.8336\n",
      "Epoch 231: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.7211 - loss: 0.8339 - val_accuracy: 0.7997 - val_loss: 0.6757\n",
      "Epoch 232/1000\n",
      "\u001b[1m141/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.7121 - loss: 0.8626\n",
      "Epoch 232: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7192 - loss: 0.8472 - val_accuracy: 0.8037 - val_loss: 0.6607\n",
      "Epoch 233/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.7301 - loss: 0.8159\n",
      "Epoch 233: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.7260 - loss: 0.8242 - val_accuracy: 0.8008 - val_loss: 0.6556\n",
      "Epoch 234/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7143 - loss: 0.8725\n",
      "Epoch 234: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7168 - loss: 0.8663 - val_accuracy: 0.7991 - val_loss: 0.6682\n",
      "Epoch 235/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.7221 - loss: 0.8507\n",
      "Epoch 235: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.7237 - loss: 0.8474 - val_accuracy: 0.7962 - val_loss: 0.6523\n",
      "Epoch 236/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.7210 - loss: 0.8567\n",
      "Epoch 236: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.7212 - loss: 0.8563 - val_accuracy: 0.7894 - val_loss: 0.6559\n",
      "Epoch 237/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.7332 - loss: 0.8027\n",
      "Epoch 237: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.7315 - loss: 0.8092 - val_accuracy: 0.7808 - val_loss: 0.6796\n",
      "Epoch 238/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.7259 - loss: 0.8444\n",
      "Epoch 238: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.7257 - loss: 0.8443 - val_accuracy: 0.7956 - val_loss: 0.6710\n",
      "Epoch 239/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.7245 - loss: 0.8347\n",
      "Epoch 239: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.7254 - loss: 0.8358 - val_accuracy: 0.7997 - val_loss: 0.6604\n",
      "Epoch 240/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.7275 - loss: 0.8165\n",
      "Epoch 240: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.7266 - loss: 0.8202 - val_accuracy: 0.7859 - val_loss: 0.6805\n",
      "Epoch 241/1000\n",
      "\u001b[1m154/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.7222 - loss: 0.8386\n",
      "Epoch 241: val_loss did not improve from 0.64781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.7226 - loss: 0.8402 - val_accuracy: 0.8019 - val_loss: 0.6545\n",
      "Epoch 242/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.7360 - loss: 0.8218\n",
      "Epoch 242: val_loss improved from 0.64781 to 0.64717, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.7345 - loss: 0.8242 - val_accuracy: 0.7997 - val_loss: 0.6472\n",
      "Epoch 243/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.7396 - loss: 0.7981\n",
      "Epoch 243: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7382 - loss: 0.8009 - val_accuracy: 0.7905 - val_loss: 0.6704\n",
      "Epoch 244/1000\n",
      "\u001b[1m152/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.7318 - loss: 0.8440\n",
      "Epoch 244: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7306 - loss: 0.8413 - val_accuracy: 0.7865 - val_loss: 0.6825\n",
      "Epoch 245/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.7290 - loss: 0.8642\n",
      "Epoch 245: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7285 - loss: 0.8556 - val_accuracy: 0.8014 - val_loss: 0.6663\n",
      "Epoch 246/1000\n",
      "\u001b[1m154/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.7200 - loss: 0.8236\n",
      "Epoch 246: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.7207 - loss: 0.8277 - val_accuracy: 0.7997 - val_loss: 0.6627\n",
      "Epoch 247/1000\n",
      "\u001b[1m165/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7332 - loss: 0.8294\n",
      "Epoch 247: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7317 - loss: 0.8311 - val_accuracy: 0.8100 - val_loss: 0.6485\n",
      "Epoch 248/1000\n",
      "\u001b[1m173/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.7203 - loss: 0.8466\n",
      "Epoch 248: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.7203 - loss: 0.8477 - val_accuracy: 0.7894 - val_loss: 0.6672\n",
      "Epoch 249/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.7279 - loss: 0.8268\n",
      "Epoch 249: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.7279 - loss: 0.8270 - val_accuracy: 0.7853 - val_loss: 0.6907\n",
      "Epoch 250/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.7238 - loss: 0.8361\n",
      "Epoch 250: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7239 - loss: 0.8359 - val_accuracy: 0.7899 - val_loss: 0.6608\n",
      "Epoch 251/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.7287 - loss: 0.8404\n",
      "Epoch 251: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.7282 - loss: 0.8407 - val_accuracy: 0.7905 - val_loss: 0.6740\n",
      "Epoch 252/1000\n",
      "\u001b[1m161/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.7145 - loss: 0.8839\n",
      "Epoch 252: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7157 - loss: 0.8756 - val_accuracy: 0.8025 - val_loss: 0.6642\n",
      "Epoch 253/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.7252 - loss: 0.8396\n",
      "Epoch 253: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.7251 - loss: 0.8363 - val_accuracy: 0.7951 - val_loss: 0.6569\n",
      "Epoch 254/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.7174 - loss: 0.8614\n",
      "Epoch 254: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.7177 - loss: 0.8604 - val_accuracy: 0.7905 - val_loss: 0.6490\n",
      "Epoch 255/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.7092 - loss: 0.8517\n",
      "Epoch 255: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7123 - loss: 0.8506 - val_accuracy: 0.7899 - val_loss: 0.6588\n",
      "Epoch 256/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.7248 - loss: 0.8250\n",
      "Epoch 256: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7251 - loss: 0.8297 - val_accuracy: 0.7899 - val_loss: 0.6685\n",
      "Epoch 257/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.7301 - loss: 0.8525\n",
      "Epoch 257: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.7301 - loss: 0.8520 - val_accuracy: 0.7831 - val_loss: 0.6693\n",
      "Epoch 258/1000\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.7405 - loss: 0.7836\n",
      "Epoch 258: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.7378 - loss: 0.7936 - val_accuracy: 0.7968 - val_loss: 0.6615\n",
      "Epoch 259/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.7267 - loss: 0.8085\n",
      "Epoch 259: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7268 - loss: 0.8149 - val_accuracy: 0.7916 - val_loss: 0.6512\n",
      "Epoch 260/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.7229 - loss: 0.8499\n",
      "Epoch 260: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7221 - loss: 0.8502 - val_accuracy: 0.7911 - val_loss: 0.6660\n",
      "Epoch 261/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7091 - loss: 0.8543\n",
      "Epoch 261: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7121 - loss: 0.8481 - val_accuracy: 0.7997 - val_loss: 0.6627\n",
      "Epoch 262/1000\n",
      "\u001b[1m163/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.7283 - loss: 0.8289\n",
      "Epoch 262: val_loss did not improve from 0.64717\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.7281 - loss: 0.8320 - val_accuracy: 0.7985 - val_loss: 0.6577\n",
      "Epoch 263/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.7202 - loss: 0.8213\n",
      "Epoch 263: val_loss improved from 0.64717 to 0.63542, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7213 - loss: 0.8230 - val_accuracy: 0.8014 - val_loss: 0.6354\n",
      "Epoch 264/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.7308 - loss: 0.8430\n",
      "Epoch 264: val_loss did not improve from 0.63542\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7306 - loss: 0.8427 - val_accuracy: 0.7934 - val_loss: 0.6615\n",
      "Epoch 265/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.7223 - loss: 0.8293\n",
      "Epoch 265: val_loss did not improve from 0.63542\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.7231 - loss: 0.8298 - val_accuracy: 0.7956 - val_loss: 0.6544\n",
      "Epoch 266/1000\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.7258 - loss: 0.8226\n",
      "Epoch 266: val_loss did not improve from 0.63542\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.7260 - loss: 0.8250 - val_accuracy: 0.7922 - val_loss: 0.6511\n",
      "Epoch 267/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.7174 - loss: 0.8433\n",
      "Epoch 267: val_loss did not improve from 0.63542\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.7170 - loss: 0.8442 - val_accuracy: 0.7951 - val_loss: 0.6550\n",
      "Epoch 268/1000\n",
      "\u001b[1m158/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.7089 - loss: 0.8496\n",
      "Epoch 268: val_loss did not improve from 0.63542\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.7118 - loss: 0.8490 - val_accuracy: 0.7956 - val_loss: 0.6628\n",
      "Epoch 269/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.7301 - loss: 0.8304\n",
      "Epoch 269: val_loss did not improve from 0.63542\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.7296 - loss: 0.8308 - val_accuracy: 0.7974 - val_loss: 0.6558\n",
      "Epoch 270/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.7334 - loss: 0.8117\n",
      "Epoch 270: val_loss did not improve from 0.63542\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7334 - loss: 0.8119 - val_accuracy: 0.7968 - val_loss: 0.6456\n",
      "Epoch 271/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.7405 - loss: 0.8015\n",
      "Epoch 271: val_loss did not improve from 0.63542\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.7392 - loss: 0.8049 - val_accuracy: 0.8094 - val_loss: 0.6455\n",
      "Epoch 272/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.7306 - loss: 0.8196\n",
      "Epoch 272: val_loss did not improve from 0.63542\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7292 - loss: 0.8213 - val_accuracy: 0.7934 - val_loss: 0.6617\n",
      "Epoch 273/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.7312 - loss: 0.8341\n",
      "Epoch 273: val_loss did not improve from 0.63542\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.7290 - loss: 0.8345 - val_accuracy: 0.7951 - val_loss: 0.6437\n",
      "Epoch 274/1000\n",
      "\u001b[1m157/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.7403 - loss: 0.8158\n",
      "Epoch 274: val_loss did not improve from 0.63542\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7385 - loss: 0.8184 - val_accuracy: 0.8071 - val_loss: 0.6404\n",
      "Epoch 275/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.7410 - loss: 0.7933\n",
      "Epoch 275: val_loss did not improve from 0.63542\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.7409 - loss: 0.7935 - val_accuracy: 0.8071 - val_loss: 0.6379\n",
      "Epoch 276/1000\n",
      "\u001b[1m145/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.7246 - loss: 0.8274\n",
      "Epoch 276: val_loss improved from 0.63542 to 0.62304, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.7275 - loss: 0.8252 - val_accuracy: 0.8100 - val_loss: 0.6230\n",
      "Epoch 277/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.7421 - loss: 0.8161\n",
      "Epoch 277: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7417 - loss: 0.8167 - val_accuracy: 0.8088 - val_loss: 0.6283\n",
      "Epoch 278/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.7268 - loss: 0.8306\n",
      "Epoch 278: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.7264 - loss: 0.8298 - val_accuracy: 0.8128 - val_loss: 0.6289\n",
      "Epoch 279/1000\n",
      "\u001b[1m145/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.7335 - loss: 0.8086\n",
      "Epoch 279: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.7331 - loss: 0.8127 - val_accuracy: 0.7871 - val_loss: 0.6688\n",
      "Epoch 280/1000\n",
      "\u001b[1m176/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.7304 - loss: 0.8217\n",
      "Epoch 280: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7306 - loss: 0.8202 - val_accuracy: 0.8031 - val_loss: 0.6332\n",
      "Epoch 281/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.7300 - loss: 0.7934\n",
      "Epoch 281: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.7307 - loss: 0.7969 - val_accuracy: 0.8014 - val_loss: 0.6333\n",
      "Epoch 282/1000\n",
      "\u001b[1m183/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.7296 - loss: 0.8287\n",
      "Epoch 282: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.7293 - loss: 0.8288 - val_accuracy: 0.8054 - val_loss: 0.6441\n",
      "Epoch 283/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.7406 - loss: 0.8167\n",
      "Epoch 283: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.7401 - loss: 0.8172 - val_accuracy: 0.8054 - val_loss: 0.6551\n",
      "Epoch 284/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.7424 - loss: 0.7915\n",
      "Epoch 284: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.7377 - loss: 0.8003 - val_accuracy: 0.8031 - val_loss: 0.6473\n",
      "Epoch 285/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.7336 - loss: 0.8200\n",
      "Epoch 285: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.7325 - loss: 0.8235 - val_accuracy: 0.8094 - val_loss: 0.6428\n",
      "Epoch 286/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7268 - loss: 0.8244\n",
      "Epoch 286: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.7271 - loss: 0.8238 - val_accuracy: 0.7991 - val_loss: 0.6410\n",
      "Epoch 287/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.7440 - loss: 0.7787\n",
      "Epoch 287: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7408 - loss: 0.7866 - val_accuracy: 0.7928 - val_loss: 0.6397\n",
      "Epoch 288/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.7173 - loss: 0.8610\n",
      "Epoch 288: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7203 - loss: 0.8513 - val_accuracy: 0.7831 - val_loss: 0.6745\n",
      "Epoch 289/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.7248 - loss: 0.8632\n",
      "Epoch 289: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.7249 - loss: 0.8628 - val_accuracy: 0.7997 - val_loss: 0.6502\n",
      "Epoch 290/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.7555 - loss: 0.7680\n",
      "Epoch 290: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.7542 - loss: 0.7715 - val_accuracy: 0.8105 - val_loss: 0.6358\n",
      "Epoch 291/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.7250 - loss: 0.8535\n",
      "Epoch 291: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.7286 - loss: 0.8425 - val_accuracy: 0.7968 - val_loss: 0.6488\n",
      "Epoch 292/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7346 - loss: 0.8164\n",
      "Epoch 292: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7340 - loss: 0.8179 - val_accuracy: 0.7985 - val_loss: 0.6439\n",
      "Epoch 293/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.7164 - loss: 0.8610\n",
      "Epoch 293: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7189 - loss: 0.8532 - val_accuracy: 0.7934 - val_loss: 0.6468\n",
      "Epoch 294/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.7339 - loss: 0.8093\n",
      "Epoch 294: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.7328 - loss: 0.8158 - val_accuracy: 0.8025 - val_loss: 0.6322\n",
      "Epoch 295/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.7366 - loss: 0.8247\n",
      "Epoch 295: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.7368 - loss: 0.8234 - val_accuracy: 0.8002 - val_loss: 0.6349\n",
      "Epoch 296/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.7413 - loss: 0.8105\n",
      "Epoch 296: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7405 - loss: 0.8104 - val_accuracy: 0.8042 - val_loss: 0.6463\n",
      "Epoch 297/1000\n",
      "\u001b[1m160/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.7287 - loss: 0.8496\n",
      "Epoch 297: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.7305 - loss: 0.8454 - val_accuracy: 0.7991 - val_loss: 0.6505\n",
      "Epoch 298/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7382 - loss: 0.8123\n",
      "Epoch 298: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7380 - loss: 0.8129 - val_accuracy: 0.8019 - val_loss: 0.6573\n",
      "Epoch 299/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7339 - loss: 0.8126  \n",
      "Epoch 299: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7341 - loss: 0.8133 - val_accuracy: 0.7997 - val_loss: 0.6497\n",
      "Epoch 300/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.7307 - loss: 0.8060\n",
      "Epoch 300: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.7308 - loss: 0.8059 - val_accuracy: 0.7951 - val_loss: 0.6513\n",
      "Epoch 301/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7294 - loss: 0.8225\n",
      "Epoch 301: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7302 - loss: 0.8202 - val_accuracy: 0.7962 - val_loss: 0.6652\n",
      "Epoch 302/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.7276 - loss: 0.8442\n",
      "Epoch 302: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7297 - loss: 0.8398 - val_accuracy: 0.8002 - val_loss: 0.6471\n",
      "Epoch 303/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.7406 - loss: 0.7970\n",
      "Epoch 303: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.7413 - loss: 0.8008 - val_accuracy: 0.8014 - val_loss: 0.6515\n",
      "Epoch 304/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.7256 - loss: 0.8225\n",
      "Epoch 304: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.7256 - loss: 0.8227 - val_accuracy: 0.8008 - val_loss: 0.6526\n",
      "Epoch 305/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.7337 - loss: 0.8250\n",
      "Epoch 305: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7329 - loss: 0.8258 - val_accuracy: 0.8025 - val_loss: 0.6435\n",
      "Epoch 306/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.7413 - loss: 0.8075\n",
      "Epoch 306: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.7378 - loss: 0.8113 - val_accuracy: 0.8019 - val_loss: 0.6416\n",
      "Epoch 307/1000\n",
      "\u001b[1m154/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7422 - loss: 0.7811\n",
      "Epoch 307: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7405 - loss: 0.7878 - val_accuracy: 0.8037 - val_loss: 0.6658\n",
      "Epoch 308/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.7471 - loss: 0.7705\n",
      "Epoch 308: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.7434 - loss: 0.7767 - val_accuracy: 0.8025 - val_loss: 0.6416\n",
      "Epoch 309/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.7362 - loss: 0.8177\n",
      "Epoch 309: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7351 - loss: 0.8198 - val_accuracy: 0.8014 - val_loss: 0.6557\n",
      "Epoch 310/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.7299 - loss: 0.8204\n",
      "Epoch 310: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.7298 - loss: 0.8212 - val_accuracy: 0.8054 - val_loss: 0.6485\n",
      "Epoch 311/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.7315 - loss: 0.8293\n",
      "Epoch 311: val_loss did not improve from 0.62304\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.7307 - loss: 0.8307 - val_accuracy: 0.7916 - val_loss: 0.6419\n",
      "Epoch 312/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7227 - loss: 0.8469\n",
      "Epoch 312: val_loss improved from 0.62304 to 0.61412, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7232 - loss: 0.8459 - val_accuracy: 0.8180 - val_loss: 0.6141\n",
      "Epoch 313/1000\n",
      "\u001b[1m145/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.7373 - loss: 0.8274\n",
      "Epoch 313: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.7386 - loss: 0.8239 - val_accuracy: 0.8008 - val_loss: 0.6302\n",
      "Epoch 314/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7392 - loss: 0.7798\n",
      "Epoch 314: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.7863 - val_accuracy: 0.7997 - val_loss: 0.6503\n",
      "Epoch 315/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.7441 - loss: 0.7957\n",
      "Epoch 315: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7439 - loss: 0.7960 - val_accuracy: 0.7979 - val_loss: 0.6496\n",
      "Epoch 316/1000\n",
      "\u001b[1m144/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.7309 - loss: 0.8359\n",
      "Epoch 316: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.7308 - loss: 0.8330 - val_accuracy: 0.8025 - val_loss: 0.6297\n",
      "Epoch 317/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7382 - loss: 0.7908\n",
      "Epoch 317: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.7381 - loss: 0.7914 - val_accuracy: 0.8042 - val_loss: 0.6275\n",
      "Epoch 318/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.7588 - loss: 0.7450\n",
      "Epoch 318: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.7533 - loss: 0.7587 - val_accuracy: 0.8014 - val_loss: 0.6361\n",
      "Epoch 319/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.7320 - loss: 0.7941\n",
      "Epoch 319: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.7335 - loss: 0.7980 - val_accuracy: 0.8048 - val_loss: 0.6231\n",
      "Epoch 320/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.7265 - loss: 0.8598\n",
      "Epoch 320: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.7265 - loss: 0.8593 - val_accuracy: 0.8002 - val_loss: 0.6401\n",
      "Epoch 321/1000\n",
      "\u001b[1m173/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.7207 - loss: 0.8577\n",
      "Epoch 321: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7230 - loss: 0.8484 - val_accuracy: 0.8140 - val_loss: 0.6238\n",
      "Epoch 322/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.7390 - loss: 0.8051\n",
      "Epoch 322: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.7384 - loss: 0.8010 - val_accuracy: 0.8037 - val_loss: 0.6401\n",
      "Epoch 323/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.7483 - loss: 0.7817\n",
      "Epoch 323: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.7478 - loss: 0.7826 - val_accuracy: 0.7974 - val_loss: 0.6342\n",
      "Epoch 324/1000\n",
      "\u001b[1m164/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7344 - loss: 0.8261\n",
      "Epoch 324: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7346 - loss: 0.8238 - val_accuracy: 0.7979 - val_loss: 0.6542\n",
      "Epoch 325/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.7497 - loss: 0.7847\n",
      "Epoch 325: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.7492 - loss: 0.7855 - val_accuracy: 0.8060 - val_loss: 0.6338\n",
      "Epoch 326/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.7398 - loss: 0.8086\n",
      "Epoch 326: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.7401 - loss: 0.8078 - val_accuracy: 0.8065 - val_loss: 0.6297\n",
      "Epoch 327/1000\n",
      "\u001b[1m164/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7288 - loss: 0.8293\n",
      "Epoch 327: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7297 - loss: 0.8276 - val_accuracy: 0.8019 - val_loss: 0.6243\n",
      "Epoch 328/1000\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.7299 - loss: 0.8148\n",
      "Epoch 328: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7302 - loss: 0.8181 - val_accuracy: 0.8037 - val_loss: 0.6643\n",
      "Epoch 329/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.7370 - loss: 0.8082\n",
      "Epoch 329: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7371 - loss: 0.8082 - val_accuracy: 0.7979 - val_loss: 0.6419\n",
      "Epoch 330/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.7253 - loss: 0.8284\n",
      "Epoch 330: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7279 - loss: 0.8237 - val_accuracy: 0.8060 - val_loss: 0.6568\n",
      "Epoch 331/1000\n",
      "\u001b[1m206/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.7502 - loss: 0.7663\n",
      "Epoch 331: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.7493 - loss: 0.7689 - val_accuracy: 0.8054 - val_loss: 0.6344\n",
      "Epoch 332/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.7248 - loss: 0.8285\n",
      "Epoch 332: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7260 - loss: 0.8285 - val_accuracy: 0.7968 - val_loss: 0.6401\n",
      "Epoch 333/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.7293 - loss: 0.7976\n",
      "Epoch 333: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.7281 - loss: 0.8053 - val_accuracy: 0.8105 - val_loss: 0.6255\n",
      "Epoch 334/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.7366 - loss: 0.8121\n",
      "Epoch 334: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7366 - loss: 0.8122 - val_accuracy: 0.8037 - val_loss: 0.6463\n",
      "Epoch 335/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.7350 - loss: 0.8124\n",
      "Epoch 335: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.7356 - loss: 0.8112 - val_accuracy: 0.7934 - val_loss: 0.6607\n",
      "Epoch 336/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.7369 - loss: 0.7947\n",
      "Epoch 336: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.7369 - loss: 0.7947 - val_accuracy: 0.8002 - val_loss: 0.6552\n",
      "Epoch 337/1000\n",
      "\u001b[1m143/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.7325 - loss: 0.8167\n",
      "Epoch 337: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.7324 - loss: 0.8172 - val_accuracy: 0.8031 - val_loss: 0.6425\n",
      "Epoch 338/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.7342 - loss: 0.8044\n",
      "Epoch 338: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7354 - loss: 0.8042 - val_accuracy: 0.8048 - val_loss: 0.6159\n",
      "Epoch 339/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.7433 - loss: 0.7639\n",
      "Epoch 339: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.7433 - loss: 0.7641 - val_accuracy: 0.8037 - val_loss: 0.6272\n",
      "Epoch 340/1000\n",
      "\u001b[1m154/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.7372 - loss: 0.8182\n",
      "Epoch 340: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.7373 - loss: 0.8151 - val_accuracy: 0.8111 - val_loss: 0.6265\n",
      "Epoch 341/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.7341 - loss: 0.8055\n",
      "Epoch 341: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7340 - loss: 0.8054 - val_accuracy: 0.8060 - val_loss: 0.6262\n",
      "Epoch 342/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.7496 - loss: 0.7879\n",
      "Epoch 342: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.7477 - loss: 0.7932 - val_accuracy: 0.8134 - val_loss: 0.6361\n",
      "Epoch 343/1000\n",
      "\u001b[1m152/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.7299 - loss: 0.8118\n",
      "Epoch 343: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.7310 - loss: 0.8099 - val_accuracy: 0.8082 - val_loss: 0.6299\n",
      "Epoch 344/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.7438 - loss: 0.7929\n",
      "Epoch 344: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7434 - loss: 0.7942 - val_accuracy: 0.8203 - val_loss: 0.6239\n",
      "Epoch 345/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.7564 - loss: 0.7391\n",
      "Epoch 345: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7533 - loss: 0.7482 - val_accuracy: 0.8077 - val_loss: 0.6339\n",
      "Epoch 346/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.7240 - loss: 0.8261\n",
      "Epoch 346: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.7242 - loss: 0.8255 - val_accuracy: 0.7951 - val_loss: 0.6565\n",
      "Epoch 347/1000\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.7441 - loss: 0.7858\n",
      "Epoch 347: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.7447 - loss: 0.7857 - val_accuracy: 0.8042 - val_loss: 0.6318\n",
      "Epoch 348/1000\n",
      "\u001b[1m168/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.7353 - loss: 0.8061\n",
      "Epoch 348: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7361 - loss: 0.8057 - val_accuracy: 0.8042 - val_loss: 0.6422\n",
      "Epoch 349/1000\n",
      "\u001b[1m206/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.7316 - loss: 0.8130\n",
      "Epoch 349: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.7319 - loss: 0.8126 - val_accuracy: 0.7979 - val_loss: 0.6368\n",
      "Epoch 350/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.7341 - loss: 0.8364\n",
      "Epoch 350: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7347 - loss: 0.8368 - val_accuracy: 0.7842 - val_loss: 0.6651\n",
      "Epoch 351/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.7318 - loss: 0.8158\n",
      "Epoch 351: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.7318 - loss: 0.8156 - val_accuracy: 0.8008 - val_loss: 0.6509\n",
      "Epoch 352/1000\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.7355 - loss: 0.8035\n",
      "Epoch 352: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.7358 - loss: 0.8068 - val_accuracy: 0.8077 - val_loss: 0.6416\n",
      "Epoch 353/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.7392 - loss: 0.7981\n",
      "Epoch 353: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.7391 - loss: 0.8013 - val_accuracy: 0.7945 - val_loss: 0.6544\n",
      "Epoch 354/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.7357 - loss: 0.8132\n",
      "Epoch 354: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.7357 - loss: 0.8132 - val_accuracy: 0.8117 - val_loss: 0.6317\n",
      "Epoch 355/1000\n",
      "\u001b[1m145/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7258 - loss: 0.8235\n",
      "Epoch 355: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7278 - loss: 0.8167 - val_accuracy: 0.7997 - val_loss: 0.6457\n",
      "Epoch 356/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.7272 - loss: 0.7952\n",
      "Epoch 356: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.7276 - loss: 0.7955 - val_accuracy: 0.8054 - val_loss: 0.6457\n",
      "Epoch 357/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.7281 - loss: 0.8288\n",
      "Epoch 357: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.7312 - loss: 0.8240 - val_accuracy: 0.8019 - val_loss: 0.6579\n",
      "Epoch 358/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.7401 - loss: 0.7915\n",
      "Epoch 358: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.7400 - loss: 0.7917 - val_accuracy: 0.7888 - val_loss: 0.6474\n",
      "Epoch 359/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.7348 - loss: 0.8199\n",
      "Epoch 359: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.7363 - loss: 0.8109 - val_accuracy: 0.8077 - val_loss: 0.6366\n",
      "Epoch 360/1000\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.7438 - loss: 0.7433\n",
      "Epoch 360: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.7430 - loss: 0.7549 - val_accuracy: 0.8002 - val_loss: 0.6463\n",
      "Epoch 361/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7496 - loss: 0.7972\n",
      "Epoch 361: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7481 - loss: 0.8002 - val_accuracy: 0.7848 - val_loss: 0.6713\n",
      "Epoch 362/1000\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.7366 - loss: 0.7865\n",
      "Epoch 362: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7373 - loss: 0.7922 - val_accuracy: 0.8031 - val_loss: 0.6362\n",
      "Epoch 363/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.7488 - loss: 0.7964\n",
      "Epoch 363: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.7487 - loss: 0.7964 - val_accuracy: 0.8071 - val_loss: 0.6406\n",
      "Epoch 364/1000\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.7423 - loss: 0.7870\n",
      "Epoch 364: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.7412 - loss: 0.7911 - val_accuracy: 0.8100 - val_loss: 0.6154\n",
      "Epoch 365/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.7376 - loss: 0.8035\n",
      "Epoch 365: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.7375 - loss: 0.8036 - val_accuracy: 0.8111 - val_loss: 0.6148\n",
      "Epoch 366/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.7488 - loss: 0.8179\n",
      "Epoch 366: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.7448 - loss: 0.8212 - val_accuracy: 0.7922 - val_loss: 0.6484\n",
      "Epoch 367/1000\n",
      "\u001b[1m171/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7422 - loss: 0.7798\n",
      "Epoch 367: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7428 - loss: 0.7778 - val_accuracy: 0.8088 - val_loss: 0.6251\n",
      "Epoch 368/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.7341 - loss: 0.8123\n",
      "Epoch 368: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7375 - loss: 0.8035 - val_accuracy: 0.8054 - val_loss: 0.6228\n",
      "Epoch 369/1000\n",
      "\u001b[1m145/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.7503 - loss: 0.7756\n",
      "Epoch 369: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.7475 - loss: 0.7824 - val_accuracy: 0.7956 - val_loss: 0.6440\n",
      "Epoch 370/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7219 - loss: 0.8434\n",
      "Epoch 370: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.7224 - loss: 0.8421 - val_accuracy: 0.8037 - val_loss: 0.6287\n",
      "Epoch 371/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.7392 - loss: 0.7902\n",
      "Epoch 371: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7391 - loss: 0.7910 - val_accuracy: 0.8088 - val_loss: 0.6487\n",
      "Epoch 372/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.7516 - loss: 0.7694\n",
      "Epoch 372: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7515 - loss: 0.7697 - val_accuracy: 0.8100 - val_loss: 0.6362\n",
      "Epoch 373/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.7400 - loss: 0.7677\n",
      "Epoch 373: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7399 - loss: 0.7719 - val_accuracy: 0.8065 - val_loss: 0.6254\n",
      "Epoch 374/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.7502 - loss: 0.7632\n",
      "Epoch 374: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.7499 - loss: 0.7651 - val_accuracy: 0.8025 - val_loss: 0.6395\n",
      "Epoch 375/1000\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.7478 - loss: 0.7772\n",
      "Epoch 375: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.7479 - loss: 0.7780 - val_accuracy: 0.8042 - val_loss: 0.6200\n",
      "Epoch 376/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.7402 - loss: 0.8153\n",
      "Epoch 376: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.7402 - loss: 0.8150 - val_accuracy: 0.8088 - val_loss: 0.6219\n",
      "Epoch 377/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.7577 - loss: 0.7663\n",
      "Epoch 377: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7546 - loss: 0.7729 - val_accuracy: 0.8100 - val_loss: 0.6387\n",
      "Epoch 378/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.7459 - loss: 0.7592\n",
      "Epoch 378: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.7440 - loss: 0.7662 - val_accuracy: 0.7997 - val_loss: 0.6506\n",
      "Epoch 379/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7430 - loss: 0.7803\n",
      "Epoch 379: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7421 - loss: 0.7867 - val_accuracy: 0.8054 - val_loss: 0.6350\n",
      "Epoch 380/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.7349 - loss: 0.7832\n",
      "Epoch 380: val_loss did not improve from 0.61412\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.7344 - loss: 0.7943 - val_accuracy: 0.8065 - val_loss: 0.6313\n",
      "Epoch 381/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.7458 - loss: 0.7752\n",
      "Epoch 381: val_loss improved from 0.61412 to 0.61270, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7458 - loss: 0.7752 - val_accuracy: 0.8128 - val_loss: 0.6127\n",
      "Epoch 382/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.7522 - loss: 0.7772\n",
      "Epoch 382: val_loss did not improve from 0.61270\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.7521 - loss: 0.7774 - val_accuracy: 0.8077 - val_loss: 0.6216\n",
      "Epoch 383/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.7470 - loss: 0.7925\n",
      "Epoch 383: val_loss did not improve from 0.61270\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7467 - loss: 0.7930 - val_accuracy: 0.8088 - val_loss: 0.6215\n",
      "Epoch 384/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.7326 - loss: 0.8230\n",
      "Epoch 384: val_loss improved from 0.61270 to 0.61011, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7367 - loss: 0.8077 - val_accuracy: 0.8191 - val_loss: 0.6101\n",
      "Epoch 385/1000\n",
      "\u001b[1m182/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.7288 - loss: 0.8437\n",
      "Epoch 385: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7303 - loss: 0.8379 - val_accuracy: 0.8077 - val_loss: 0.6348\n",
      "Epoch 386/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.7391 - loss: 0.7744\n",
      "Epoch 386: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.7391 - loss: 0.7746 - val_accuracy: 0.8122 - val_loss: 0.6184\n",
      "Epoch 387/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.7390 - loss: 0.8244\n",
      "Epoch 387: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.7391 - loss: 0.8229 - val_accuracy: 0.8060 - val_loss: 0.6172\n",
      "Epoch 388/1000\n",
      "\u001b[1m152/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.7409 - loss: 0.7872\n",
      "Epoch 388: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7416 - loss: 0.7865 - val_accuracy: 0.8054 - val_loss: 0.6251\n",
      "Epoch 389/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.7473 - loss: 0.8128\n",
      "Epoch 389: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.7470 - loss: 0.8126 - val_accuracy: 0.8088 - val_loss: 0.6239\n",
      "Epoch 390/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7365 - loss: 0.8021\n",
      "Epoch 390: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7365 - loss: 0.8025 - val_accuracy: 0.7979 - val_loss: 0.6379\n",
      "Epoch 391/1000\n",
      "\u001b[1m170/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.7466 - loss: 0.7921\n",
      "Epoch 391: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.7460 - loss: 0.7921 - val_accuracy: 0.8094 - val_loss: 0.6425\n",
      "Epoch 392/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.7428 - loss: 0.7824\n",
      "Epoch 392: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7429 - loss: 0.7830 - val_accuracy: 0.8065 - val_loss: 0.6314\n",
      "Epoch 393/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.7344 - loss: 0.7884\n",
      "Epoch 393: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.7348 - loss: 0.7884 - val_accuracy: 0.8014 - val_loss: 0.6637\n",
      "Epoch 394/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.7396 - loss: 0.8190\n",
      "Epoch 394: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7400 - loss: 0.8158 - val_accuracy: 0.7985 - val_loss: 0.6433\n",
      "Epoch 395/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.7471 - loss: 0.7903\n",
      "Epoch 395: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7478 - loss: 0.7862 - val_accuracy: 0.8117 - val_loss: 0.6277\n",
      "Epoch 396/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.7378 - loss: 0.7815\n",
      "Epoch 396: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.7377 - loss: 0.7819 - val_accuracy: 0.7985 - val_loss: 0.6254\n",
      "Epoch 397/1000\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.7345 - loss: 0.8298\n",
      "Epoch 397: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.7341 - loss: 0.8265 - val_accuracy: 0.8077 - val_loss: 0.6287\n",
      "Epoch 398/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.7430 - loss: 0.7934\n",
      "Epoch 398: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.7430 - loss: 0.7925 - val_accuracy: 0.8065 - val_loss: 0.6324\n",
      "Epoch 399/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.7490 - loss: 0.7795\n",
      "Epoch 399: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.7489 - loss: 0.7796 - val_accuracy: 0.8060 - val_loss: 0.6282\n",
      "Epoch 400/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.7472 - loss: 0.7795\n",
      "Epoch 400: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7471 - loss: 0.7796 - val_accuracy: 0.8128 - val_loss: 0.6172\n",
      "Epoch 401/1000\n",
      "\u001b[1m143/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.7263 - loss: 0.8103\n",
      "Epoch 401: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.7296 - loss: 0.8072 - val_accuracy: 0.8077 - val_loss: 0.6334\n",
      "Epoch 402/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.7394 - loss: 0.8134\n",
      "Epoch 402: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7387 - loss: 0.8143 - val_accuracy: 0.8094 - val_loss: 0.6169\n",
      "Epoch 403/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.7484 - loss: 0.7935\n",
      "Epoch 403: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7492 - loss: 0.7904 - val_accuracy: 0.8014 - val_loss: 0.6396\n",
      "Epoch 404/1000\n",
      "\u001b[1m206/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.7447 - loss: 0.7930\n",
      "Epoch 404: val_loss did not improve from 0.61011\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.7444 - loss: 0.7936 - val_accuracy: 0.8077 - val_loss: 0.6332\n",
      "Epoch 405/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.7529 - loss: 0.7969\n",
      "Epoch 405: val_loss improved from 0.61011 to 0.60276, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.7498 - loss: 0.7936 - val_accuracy: 0.8180 - val_loss: 0.6028\n",
      "Epoch 406/1000\n",
      "\u001b[1m185/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7416 - loss: 0.8231\n",
      "Epoch 406: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7414 - loss: 0.8206 - val_accuracy: 0.8094 - val_loss: 0.6378\n",
      "Epoch 407/1000\n",
      "\u001b[1m144/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.7488 - loss: 0.7666\n",
      "Epoch 407: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.7484 - loss: 0.7740 - val_accuracy: 0.8111 - val_loss: 0.6412\n",
      "Epoch 408/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.7452 - loss: 0.7698\n",
      "Epoch 408: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7444 - loss: 0.7736 - val_accuracy: 0.8094 - val_loss: 0.6359\n",
      "Epoch 409/1000\n",
      "\u001b[1m152/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.7489 - loss: 0.7799\n",
      "Epoch 409: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.7496 - loss: 0.7765 - val_accuracy: 0.8128 - val_loss: 0.6293\n",
      "Epoch 410/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.7478 - loss: 0.8085\n",
      "Epoch 410: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.7480 - loss: 0.8074 - val_accuracy: 0.7968 - val_loss: 0.6544\n",
      "Epoch 411/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.7509 - loss: 0.7702\n",
      "Epoch 411: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.7500 - loss: 0.7697 - val_accuracy: 0.8094 - val_loss: 0.6320\n",
      "Epoch 412/1000\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.7399 - loss: 0.7825\n",
      "Epoch 412: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.7406 - loss: 0.7847 - val_accuracy: 0.8014 - val_loss: 0.6460\n",
      "Epoch 413/1000\n",
      "\u001b[1m145/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.7579 - loss: 0.7887\n",
      "Epoch 413: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.7554 - loss: 0.7908 - val_accuracy: 0.8111 - val_loss: 0.6281\n",
      "Epoch 414/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.7543 - loss: 0.7668\n",
      "Epoch 414: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.7537 - loss: 0.7689 - val_accuracy: 0.8077 - val_loss: 0.6198\n",
      "Epoch 415/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.7345 - loss: 0.8036\n",
      "Epoch 415: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.7357 - loss: 0.8024 - val_accuracy: 0.8180 - val_loss: 0.6060\n",
      "Epoch 416/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.7496 - loss: 0.7790\n",
      "Epoch 416: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.7494 - loss: 0.7795 - val_accuracy: 0.8151 - val_loss: 0.6086\n",
      "Epoch 417/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7439 - loss: 0.8024\n",
      "Epoch 417: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7438 - loss: 0.8026 - val_accuracy: 0.8048 - val_loss: 0.6171\n",
      "Epoch 418/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.7395 - loss: 0.7985\n",
      "Epoch 418: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.7397 - loss: 0.7978 - val_accuracy: 0.8060 - val_loss: 0.6322\n",
      "Epoch 419/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.7562 - loss: 0.7729\n",
      "Epoch 419: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.7555 - loss: 0.7756 - val_accuracy: 0.8231 - val_loss: 0.6055\n",
      "Epoch 420/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.7537 - loss: 0.7819\n",
      "Epoch 420: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7510 - loss: 0.7844 - val_accuracy: 0.8105 - val_loss: 0.6222\n",
      "Epoch 421/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.7387 - loss: 0.8225\n",
      "Epoch 421: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7392 - loss: 0.8198 - val_accuracy: 0.8054 - val_loss: 0.6277\n",
      "Epoch 422/1000\n",
      "\u001b[1m168/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7460 - loss: 0.7694\n",
      "Epoch 422: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7462 - loss: 0.7683 - val_accuracy: 0.8168 - val_loss: 0.6076\n",
      "Epoch 423/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.7580 - loss: 0.7456\n",
      "Epoch 423: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.7576 - loss: 0.7468 - val_accuracy: 0.8140 - val_loss: 0.6155\n",
      "Epoch 424/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.7400 - loss: 0.8123\n",
      "Epoch 424: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.7403 - loss: 0.8114 - val_accuracy: 0.8014 - val_loss: 0.6374\n",
      "Epoch 425/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.7459 - loss: 0.7750\n",
      "Epoch 425: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.7446 - loss: 0.7816 - val_accuracy: 0.8168 - val_loss: 0.6133\n",
      "Epoch 426/1000\n",
      "\u001b[1m144/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.7443 - loss: 0.7524\n",
      "Epoch 426: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.7428 - loss: 0.7583 - val_accuracy: 0.8134 - val_loss: 0.6153\n",
      "Epoch 427/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.7425 - loss: 0.7693\n",
      "Epoch 427: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.7695 - val_accuracy: 0.8185 - val_loss: 0.6099\n",
      "Epoch 428/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.7596 - loss: 0.7517\n",
      "Epoch 428: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7554 - loss: 0.7649 - val_accuracy: 0.7979 - val_loss: 0.6399\n",
      "Epoch 429/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.7429 - loss: 0.7889\n",
      "Epoch 429: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.7426 - loss: 0.7896 - val_accuracy: 0.8048 - val_loss: 0.6280\n",
      "Epoch 430/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.7263 - loss: 0.8011\n",
      "Epoch 430: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7304 - loss: 0.8004 - val_accuracy: 0.8111 - val_loss: 0.6213\n",
      "Epoch 431/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.7440 - loss: 0.8029\n",
      "Epoch 431: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.7440 - loss: 0.8030 - val_accuracy: 0.8128 - val_loss: 0.6302\n",
      "Epoch 432/1000\n",
      "\u001b[1m145/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.7412 - loss: 0.7929\n",
      "Epoch 432: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.7388 - loss: 0.7934 - val_accuracy: 0.8025 - val_loss: 0.6524\n",
      "Epoch 433/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7373 - loss: 0.7863\n",
      "Epoch 433: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7365 - loss: 0.7908 - val_accuracy: 0.8077 - val_loss: 0.6295\n",
      "Epoch 434/1000\n",
      "\u001b[1m143/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7480 - loss: 0.7666\n",
      "Epoch 434: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.7479 - loss: 0.7753 - val_accuracy: 0.8037 - val_loss: 0.6347\n",
      "Epoch 435/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.7423 - loss: 0.7788\n",
      "Epoch 435: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.7422 - loss: 0.7793 - val_accuracy: 0.8151 - val_loss: 0.6059\n",
      "Epoch 436/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.7419 - loss: 0.8161\n",
      "Epoch 436: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7414 - loss: 0.8172 - val_accuracy: 0.8048 - val_loss: 0.6280\n",
      "Epoch 437/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.7405 - loss: 0.8183\n",
      "Epoch 437: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.7405 - loss: 0.8167 - val_accuracy: 0.8048 - val_loss: 0.6304\n",
      "Epoch 438/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7488 - loss: 0.7778  \n",
      "Epoch 438: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7485 - loss: 0.7790 - val_accuracy: 0.8042 - val_loss: 0.6337\n",
      "Epoch 439/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.7428 - loss: 0.7926\n",
      "Epoch 439: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.7428 - loss: 0.7925 - val_accuracy: 0.8100 - val_loss: 0.6357\n",
      "Epoch 440/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.7671 - loss: 0.7404\n",
      "Epoch 440: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.7654 - loss: 0.7445 - val_accuracy: 0.8088 - val_loss: 0.6420\n",
      "Epoch 441/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.7352 - loss: 0.8042\n",
      "Epoch 441: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.7352 - loss: 0.8042 - val_accuracy: 0.7934 - val_loss: 0.6459\n",
      "Epoch 442/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.7493 - loss: 0.7896\n",
      "Epoch 442: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7488 - loss: 0.7897 - val_accuracy: 0.8014 - val_loss: 0.6437\n",
      "Epoch 443/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7471 - loss: 0.7974\n",
      "Epoch 443: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7473 - loss: 0.7961 - val_accuracy: 0.8037 - val_loss: 0.6503\n",
      "Epoch 444/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.7463 - loss: 0.7632\n",
      "Epoch 444: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.7448 - loss: 0.7678 - val_accuracy: 0.8071 - val_loss: 0.6452\n",
      "Epoch 445/1000\n",
      "\u001b[1m206/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.7430 - loss: 0.7835\n",
      "Epoch 445: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.7428 - loss: 0.7841 - val_accuracy: 0.8077 - val_loss: 0.6275\n",
      "Epoch 446/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.7385 - loss: 0.8005\n",
      "Epoch 446: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.7385 - loss: 0.8004 - val_accuracy: 0.8025 - val_loss: 0.6194\n",
      "Epoch 447/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.7308 - loss: 0.8222\n",
      "Epoch 447: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7315 - loss: 0.8203 - val_accuracy: 0.8100 - val_loss: 0.6162\n",
      "Epoch 448/1000\n",
      "\u001b[1m142/219\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.7502 - loss: 0.7481\n",
      "Epoch 448: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.7504 - loss: 0.7529 - val_accuracy: 0.8151 - val_loss: 0.6340\n",
      "Epoch 449/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.7529 - loss: 0.7808\n",
      "Epoch 449: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.7526 - loss: 0.7808 - val_accuracy: 0.8140 - val_loss: 0.6204\n",
      "Epoch 450/1000\n",
      "\u001b[1m144/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.7335 - loss: 0.8183\n",
      "Epoch 450: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.7357 - loss: 0.8136 - val_accuracy: 0.8128 - val_loss: 0.6196\n",
      "Epoch 451/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.7467 - loss: 0.8138\n",
      "Epoch 451: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.7465 - loss: 0.8139 - val_accuracy: 0.8082 - val_loss: 0.6196\n",
      "Epoch 452/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.7551 - loss: 0.7539\n",
      "Epoch 452: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7545 - loss: 0.7557 - val_accuracy: 0.8088 - val_loss: 0.6203\n",
      "Epoch 453/1000\n",
      "\u001b[1m145/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.7412 - loss: 0.8725\n",
      "Epoch 453: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.7419 - loss: 0.8556 - val_accuracy: 0.8111 - val_loss: 0.6275\n",
      "Epoch 454/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.7444 - loss: 0.7668\n",
      "Epoch 454: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.7447 - loss: 0.7662 - val_accuracy: 0.8060 - val_loss: 0.6157\n",
      "Epoch 455/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.7477 - loss: 0.7807\n",
      "Epoch 455: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7476 - loss: 0.7800 - val_accuracy: 0.8071 - val_loss: 0.6197\n",
      "Epoch 456/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.7506 - loss: 0.7484\n",
      "Epoch 456: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.7509 - loss: 0.7496 - val_accuracy: 0.8100 - val_loss: 0.6053\n",
      "Epoch 457/1000\n",
      "\u001b[1m163/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.7503 - loss: 0.7642\n",
      "Epoch 457: val_loss did not improve from 0.60276\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7508 - loss: 0.7643 - val_accuracy: 0.8122 - val_loss: 0.6209\n",
      "Epoch 458/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.7504 - loss: 0.7572\n",
      "Epoch 458: val_loss improved from 0.60276 to 0.59014, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.7502 - loss: 0.7589 - val_accuracy: 0.8248 - val_loss: 0.5901\n",
      "Epoch 459/1000\n",
      "\u001b[1m175/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.7450 - loss: 0.7928\n",
      "Epoch 459: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.7447 - loss: 0.7934 - val_accuracy: 0.8071 - val_loss: 0.6276\n",
      "Epoch 460/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.7297 - loss: 0.8183\n",
      "Epoch 460: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.7300 - loss: 0.8173 - val_accuracy: 0.8128 - val_loss: 0.6037\n",
      "Epoch 461/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.7427 - loss: 0.7927\n",
      "Epoch 461: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.7433 - loss: 0.7911 - val_accuracy: 0.8185 - val_loss: 0.6026\n",
      "Epoch 462/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.7558 - loss: 0.7530\n",
      "Epoch 462: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7557 - loss: 0.7533 - val_accuracy: 0.8071 - val_loss: 0.6239\n",
      "Epoch 463/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.7407 - loss: 0.7913\n",
      "Epoch 463: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.7408 - loss: 0.7913 - val_accuracy: 0.8128 - val_loss: 0.5986\n",
      "Epoch 464/1000\n",
      "\u001b[1m167/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.7425 - loss: 0.7780\n",
      "Epoch 464: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7434 - loss: 0.7792 - val_accuracy: 0.8031 - val_loss: 0.6035\n",
      "Epoch 465/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.7384 - loss: 0.8055\n",
      "Epoch 465: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.7388 - loss: 0.8043 - val_accuracy: 0.8048 - val_loss: 0.6126\n",
      "Epoch 466/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7360 - loss: 0.8097\n",
      "Epoch 466: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7361 - loss: 0.8093 - val_accuracy: 0.8180 - val_loss: 0.6000\n",
      "Epoch 467/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.7541 - loss: 0.7573\n",
      "Epoch 467: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.7539 - loss: 0.7577 - val_accuracy: 0.8100 - val_loss: 0.6302\n",
      "Epoch 468/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.7460 - loss: 0.7887\n",
      "Epoch 468: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.7455 - loss: 0.7900 - val_accuracy: 0.8105 - val_loss: 0.6114\n",
      "Epoch 469/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.7531 - loss: 0.7646\n",
      "Epoch 469: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7516 - loss: 0.7702 - val_accuracy: 0.8002 - val_loss: 0.6426\n",
      "Epoch 470/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7466 - loss: 0.7786\n",
      "Epoch 470: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7444 - loss: 0.7814 - val_accuracy: 0.8060 - val_loss: 0.6268\n",
      "Epoch 471/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.7312 - loss: 0.8028\n",
      "Epoch 471: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.7317 - loss: 0.8017 - val_accuracy: 0.8094 - val_loss: 0.6159\n",
      "Epoch 472/1000\n",
      "\u001b[1m143/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.7365 - loss: 0.7797\n",
      "Epoch 472: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.7387 - loss: 0.7758 - val_accuracy: 0.8037 - val_loss: 0.6322\n",
      "Epoch 473/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.7393 - loss: 0.7933\n",
      "Epoch 473: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.7399 - loss: 0.7920 - val_accuracy: 0.8157 - val_loss: 0.6184\n",
      "Epoch 474/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.7500 - loss: 0.7567\n",
      "Epoch 474: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7500 - loss: 0.7568 - val_accuracy: 0.8163 - val_loss: 0.5908\n",
      "Epoch 475/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.7439 - loss: 0.7648\n",
      "Epoch 475: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.7439 - loss: 0.7648 - val_accuracy: 0.8151 - val_loss: 0.6159\n",
      "Epoch 476/1000\n",
      "\u001b[1m206/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.7460 - loss: 0.7905\n",
      "Epoch 476: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.7462 - loss: 0.7895 - val_accuracy: 0.8117 - val_loss: 0.6028\n",
      "Epoch 477/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.7438 - loss: 0.8127\n",
      "Epoch 477: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.7440 - loss: 0.8114 - val_accuracy: 0.8151 - val_loss: 0.6025\n",
      "Epoch 478/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.7515 - loss: 0.7673\n",
      "Epoch 478: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.7511 - loss: 0.7684 - val_accuracy: 0.8140 - val_loss: 0.6163\n",
      "Epoch 479/1000\n",
      "\u001b[1m161/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7356 - loss: 0.8148\n",
      "Epoch 479: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7387 - loss: 0.8060 - val_accuracy: 0.8168 - val_loss: 0.6042\n",
      "Epoch 480/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.7384 - loss: 0.7809\n",
      "Epoch 480: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.7417 - loss: 0.7812 - val_accuracy: 0.8180 - val_loss: 0.5982\n",
      "Epoch 481/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.7589 - loss: 0.7445\n",
      "Epoch 481: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7579 - loss: 0.7474 - val_accuracy: 0.8060 - val_loss: 0.6346\n",
      "Epoch 482/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.7382 - loss: 0.7938\n",
      "Epoch 482: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.7383 - loss: 0.7936 - val_accuracy: 0.8128 - val_loss: 0.5966\n",
      "Epoch 483/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.7470 - loss: 0.7756\n",
      "Epoch 483: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7470 - loss: 0.7761 - val_accuracy: 0.8117 - val_loss: 0.6180\n",
      "Epoch 484/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7516 - loss: 0.7509\n",
      "Epoch 484: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7512 - loss: 0.7527 - val_accuracy: 0.8071 - val_loss: 0.6140\n",
      "Epoch 485/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7495 - loss: 0.7955\n",
      "Epoch 485: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.7495 - loss: 0.7952 - val_accuracy: 0.8128 - val_loss: 0.6126\n",
      "Epoch 486/1000\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.7475 - loss: 0.8053\n",
      "Epoch 486: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.7476 - loss: 0.8035 - val_accuracy: 0.8060 - val_loss: 0.6271\n",
      "Epoch 487/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.7547 - loss: 0.7806\n",
      "Epoch 487: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.7545 - loss: 0.7805 - val_accuracy: 0.8122 - val_loss: 0.6056\n",
      "Epoch 488/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.7480 - loss: 0.7859\n",
      "Epoch 488: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7480 - loss: 0.7859 - val_accuracy: 0.8077 - val_loss: 0.6196\n",
      "Epoch 489/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.7412 - loss: 0.7826\n",
      "Epoch 489: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.7417 - loss: 0.7822 - val_accuracy: 0.8134 - val_loss: 0.6422\n",
      "Epoch 490/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.7401 - loss: 0.7993\n",
      "Epoch 490: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.7401 - loss: 0.7991 - val_accuracy: 0.8111 - val_loss: 0.6143\n",
      "Epoch 491/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.7468 - loss: 0.7731\n",
      "Epoch 491: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.7469 - loss: 0.7729 - val_accuracy: 0.8094 - val_loss: 0.6204\n",
      "Epoch 492/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7447 - loss: 0.7758\n",
      "Epoch 492: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7447 - loss: 0.7760 - val_accuracy: 0.8100 - val_loss: 0.6240\n",
      "Epoch 493/1000\n",
      "\u001b[1m180/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.7444 - loss: 0.8082\n",
      "Epoch 493: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7444 - loss: 0.8050 - val_accuracy: 0.8151 - val_loss: 0.6032\n",
      "Epoch 494/1000\n",
      "\u001b[1m181/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.7454 - loss: 0.7797\n",
      "Epoch 494: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.7448 - loss: 0.7818 - val_accuracy: 0.8105 - val_loss: 0.6206\n",
      "Epoch 495/1000\n",
      "\u001b[1m173/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.7518 - loss: 0.7452\n",
      "Epoch 495: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7511 - loss: 0.7523 - val_accuracy: 0.7876 - val_loss: 0.6494\n",
      "Epoch 496/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7434 - loss: 0.7828\n",
      "Epoch 496: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7444 - loss: 0.7815 - val_accuracy: 0.8128 - val_loss: 0.6052\n",
      "Epoch 497/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.7547 - loss: 0.7440\n",
      "Epoch 497: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.7546 - loss: 0.7444 - val_accuracy: 0.8128 - val_loss: 0.5930\n",
      "Epoch 498/1000\n",
      "\u001b[1m185/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.7446 - loss: 0.7834\n",
      "Epoch 498: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.7451 - loss: 0.7823 - val_accuracy: 0.8088 - val_loss: 0.6030\n",
      "Epoch 499/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.7465 - loss: 0.7458\n",
      "Epoch 499: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.7466 - loss: 0.7457 - val_accuracy: 0.8088 - val_loss: 0.6220\n",
      "Epoch 500/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7641 - loss: 0.7496\n",
      "Epoch 500: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7617 - loss: 0.7517 - val_accuracy: 0.8134 - val_loss: 0.6147\n",
      "Epoch 501/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.7385 - loss: 0.7768\n",
      "Epoch 501: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.7391 - loss: 0.7766 - val_accuracy: 0.8019 - val_loss: 0.6222\n",
      "Epoch 502/1000\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.7662 - loss: 0.7505\n",
      "Epoch 502: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.7616 - loss: 0.7567 - val_accuracy: 0.8037 - val_loss: 0.6350\n",
      "Epoch 503/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.7482 - loss: 0.7668\n",
      "Epoch 503: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7474 - loss: 0.7690 - val_accuracy: 0.8105 - val_loss: 0.6209\n",
      "Epoch 504/1000\n",
      "\u001b[1m172/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7585 - loss: 0.7535  \n",
      "Epoch 504: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7571 - loss: 0.7543 - val_accuracy: 0.8117 - val_loss: 0.6137\n",
      "Epoch 505/1000\n",
      "\u001b[1m145/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.7410 - loss: 0.7829\n",
      "Epoch 505: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.7436 - loss: 0.7770 - val_accuracy: 0.8037 - val_loss: 0.6310\n",
      "Epoch 506/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.7579 - loss: 0.7404\n",
      "Epoch 506: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7576 - loss: 0.7409 - val_accuracy: 0.8134 - val_loss: 0.6059\n",
      "Epoch 507/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.7454 - loss: 0.8107\n",
      "Epoch 507: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.7454 - loss: 0.8100 - val_accuracy: 0.8151 - val_loss: 0.6009\n",
      "Epoch 508/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.7506 - loss: 0.7765\n",
      "Epoch 508: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.7507 - loss: 0.7760 - val_accuracy: 0.8214 - val_loss: 0.6059\n",
      "Epoch 509/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7606 - loss: 0.7303\n",
      "Epoch 509: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7598 - loss: 0.7335 - val_accuracy: 0.8054 - val_loss: 0.6342\n",
      "Epoch 510/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.7514 - loss: 0.7715\n",
      "Epoch 510: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.7514 - loss: 0.7715 - val_accuracy: 0.8140 - val_loss: 0.6223\n",
      "Epoch 511/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.7545 - loss: 0.7629\n",
      "Epoch 511: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.7543 - loss: 0.7635 - val_accuracy: 0.8094 - val_loss: 0.6242\n",
      "Epoch 512/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.7441 - loss: 0.7912\n",
      "Epoch 512: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.7439 - loss: 0.7906 - val_accuracy: 0.8100 - val_loss: 0.6212\n",
      "Epoch 513/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.7520 - loss: 0.7540\n",
      "Epoch 513: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7519 - loss: 0.7544 - val_accuracy: 0.8122 - val_loss: 0.6125\n",
      "Epoch 514/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.7397 - loss: 0.7899\n",
      "Epoch 514: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7400 - loss: 0.7892 - val_accuracy: 0.8197 - val_loss: 0.6093\n",
      "Epoch 515/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.7422 - loss: 0.7755\n",
      "Epoch 515: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.7429 - loss: 0.7745 - val_accuracy: 0.8220 - val_loss: 0.6106\n",
      "Epoch 516/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7457 - loss: 0.7739\n",
      "Epoch 516: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.7458 - loss: 0.7746 - val_accuracy: 0.8168 - val_loss: 0.6073\n",
      "Epoch 517/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7663 - loss: 0.7409\n",
      "Epoch 517: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7659 - loss: 0.7414 - val_accuracy: 0.8145 - val_loss: 0.6281\n",
      "Epoch 518/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7649 - loss: 0.7268\n",
      "Epoch 518: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.7643 - loss: 0.7280 - val_accuracy: 0.8226 - val_loss: 0.6026\n",
      "Epoch 519/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.7545 - loss: 0.7822\n",
      "Epoch 519: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.7528 - loss: 0.7837 - val_accuracy: 0.8157 - val_loss: 0.6027\n",
      "Epoch 520/1000\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.7659 - loss: 0.7300\n",
      "Epoch 520: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.7651 - loss: 0.7320 - val_accuracy: 0.8191 - val_loss: 0.6028\n",
      "Epoch 521/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.7529 - loss: 0.7899\n",
      "Epoch 521: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7526 - loss: 0.7893 - val_accuracy: 0.8065 - val_loss: 0.6326\n",
      "Epoch 522/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.7567 - loss: 0.7712\n",
      "Epoch 522: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.7567 - loss: 0.7712 - val_accuracy: 0.8163 - val_loss: 0.6207\n",
      "Epoch 523/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.7444 - loss: 0.7747\n",
      "Epoch 523: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.7446 - loss: 0.7755 - val_accuracy: 0.8157 - val_loss: 0.6176\n",
      "Epoch 524/1000\n",
      "\u001b[1m206/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.7504 - loss: 0.7868\n",
      "Epoch 524: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.7505 - loss: 0.7856 - val_accuracy: 0.8157 - val_loss: 0.5942\n",
      "Epoch 525/1000\n",
      "\u001b[1m165/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.7656 - loss: 0.7227\n",
      "Epoch 525: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7626 - loss: 0.7352 - val_accuracy: 0.8048 - val_loss: 0.6193\n",
      "Epoch 526/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.7412 - loss: 0.8052\n",
      "Epoch 526: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.7414 - loss: 0.8050 - val_accuracy: 0.8122 - val_loss: 0.6287\n",
      "Epoch 527/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.7583 - loss: 0.7752\n",
      "Epoch 527: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.7575 - loss: 0.7759 - val_accuracy: 0.8088 - val_loss: 0.6070\n",
      "Epoch 528/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7526 - loss: 0.7629\n",
      "Epoch 528: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7523 - loss: 0.7651 - val_accuracy: 0.8128 - val_loss: 0.6096\n",
      "Epoch 529/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.7616 - loss: 0.7271\n",
      "Epoch 529: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7606 - loss: 0.7300 - val_accuracy: 0.8082 - val_loss: 0.6203\n",
      "Epoch 530/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.7451 - loss: 0.7695\n",
      "Epoch 530: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.7453 - loss: 0.7697 - val_accuracy: 0.8174 - val_loss: 0.6018\n",
      "Epoch 531/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.7605 - loss: 0.7473\n",
      "Epoch 531: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.7595 - loss: 0.7497 - val_accuracy: 0.7968 - val_loss: 0.6357\n",
      "Epoch 532/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.7477 - loss: 0.8011\n",
      "Epoch 532: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.7477 - loss: 0.8009 - val_accuracy: 0.8157 - val_loss: 0.6193\n",
      "Epoch 533/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.7561 - loss: 0.7718\n",
      "Epoch 533: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7558 - loss: 0.7724 - val_accuracy: 0.8071 - val_loss: 0.6377\n",
      "Epoch 534/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7534 - loss: 0.7700\n",
      "Epoch 534: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7533 - loss: 0.7687 - val_accuracy: 0.8111 - val_loss: 0.6160\n",
      "Epoch 535/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7492 - loss: 0.7851\n",
      "Epoch 535: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.7496 - loss: 0.7852 - val_accuracy: 0.8094 - val_loss: 0.6108\n",
      "Epoch 536/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.7513 - loss: 0.7485\n",
      "Epoch 536: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.7492 - loss: 0.7582 - val_accuracy: 0.8231 - val_loss: 0.6188\n",
      "Epoch 537/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.7418 - loss: 0.7934\n",
      "Epoch 537: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.7428 - loss: 0.7912 - val_accuracy: 0.8088 - val_loss: 0.6339\n",
      "Epoch 538/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.7542 - loss: 0.7467\n",
      "Epoch 538: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7543 - loss: 0.7470 - val_accuracy: 0.8157 - val_loss: 0.6053\n",
      "Epoch 539/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.7672 - loss: 0.7554\n",
      "Epoch 539: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7655 - loss: 0.7568 - val_accuracy: 0.8019 - val_loss: 0.6395\n",
      "Epoch 540/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.7489 - loss: 0.7631\n",
      "Epoch 540: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.7488 - loss: 0.7641 - val_accuracy: 0.8134 - val_loss: 0.6064\n",
      "Epoch 541/1000\n",
      "\u001b[1m144/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.7565 - loss: 0.7719\n",
      "Epoch 541: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.7546 - loss: 0.7711 - val_accuracy: 0.8082 - val_loss: 0.6126\n",
      "Epoch 542/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.7452 - loss: 0.8116\n",
      "Epoch 542: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7451 - loss: 0.8105 - val_accuracy: 0.8248 - val_loss: 0.6085\n",
      "Epoch 543/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.7594 - loss: 0.7529\n",
      "Epoch 543: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7592 - loss: 0.7524 - val_accuracy: 0.8094 - val_loss: 0.6267\n",
      "Epoch 544/1000\n",
      "\u001b[1m144/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.7510 - loss: 0.7688\n",
      "Epoch 544: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.7483 - loss: 0.7745 - val_accuracy: 0.8088 - val_loss: 0.6177\n",
      "Epoch 545/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.7376 - loss: 0.7618\n",
      "Epoch 545: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.7378 - loss: 0.7628 - val_accuracy: 0.8134 - val_loss: 0.6079\n",
      "Epoch 546/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.7571 - loss: 0.7684\n",
      "Epoch 546: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7565 - loss: 0.7686 - val_accuracy: 0.8151 - val_loss: 0.6330\n",
      "Epoch 547/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.7438 - loss: 0.7846\n",
      "Epoch 547: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.7438 - loss: 0.7846 - val_accuracy: 0.8042 - val_loss: 0.6177\n",
      "Epoch 548/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.7508 - loss: 0.7625\n",
      "Epoch 548: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.7508 - loss: 0.7626 - val_accuracy: 0.8151 - val_loss: 0.6106\n",
      "Epoch 549/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.7507 - loss: 0.7800\n",
      "Epoch 549: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.7511 - loss: 0.7787 - val_accuracy: 0.8071 - val_loss: 0.6228\n",
      "Epoch 550/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.7622 - loss: 0.7334\n",
      "Epoch 550: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.7621 - loss: 0.7338 - val_accuracy: 0.8174 - val_loss: 0.6030\n",
      "Epoch 551/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7477 - loss: 0.7887\n",
      "Epoch 551: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7486 - loss: 0.7836 - val_accuracy: 0.8100 - val_loss: 0.6010\n",
      "Epoch 552/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.7584 - loss: 0.7583\n",
      "Epoch 552: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.7577 - loss: 0.7592 - val_accuracy: 0.8008 - val_loss: 0.6253\n",
      "Epoch 553/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.7505 - loss: 0.7679\n",
      "Epoch 553: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.7509 - loss: 0.7674 - val_accuracy: 0.8203 - val_loss: 0.6136\n",
      "Epoch 554/1000\n",
      "\u001b[1m145/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.7639 - loss: 0.7506\n",
      "Epoch 554: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.7598 - loss: 0.7568 - val_accuracy: 0.8100 - val_loss: 0.6080\n",
      "Epoch 555/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7430 - loss: 0.7932\n",
      "Epoch 555: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7439 - loss: 0.7910 - val_accuracy: 0.8163 - val_loss: 0.5963\n",
      "Epoch 556/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.7547 - loss: 0.7608\n",
      "Epoch 556: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7545 - loss: 0.7614 - val_accuracy: 0.8105 - val_loss: 0.6423\n",
      "Epoch 557/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.7445 - loss: 0.7893\n",
      "Epoch 557: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.7444 - loss: 0.7895 - val_accuracy: 0.8145 - val_loss: 0.6228\n",
      "Epoch 558/1000\n",
      "\u001b[1m165/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.7607 - loss: 0.7334\n",
      "Epoch 558: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7588 - loss: 0.7410 - val_accuracy: 0.8185 - val_loss: 0.6202\n",
      "Epoch 559/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.7549 - loss: 0.7325\n",
      "Epoch 559: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.7545 - loss: 0.7352 - val_accuracy: 0.8185 - val_loss: 0.6327\n",
      "Epoch 560/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.7465 - loss: 0.8018\n",
      "Epoch 560: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.7465 - loss: 0.8016 - val_accuracy: 0.8082 - val_loss: 0.6256\n",
      "Epoch 561/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.7527 - loss: 0.7848\n",
      "Epoch 561: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7529 - loss: 0.7842 - val_accuracy: 0.8191 - val_loss: 0.6015\n",
      "Epoch 562/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7590 - loss: 0.7638\n",
      "Epoch 562: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7591 - loss: 0.7635 - val_accuracy: 0.8122 - val_loss: 0.6056\n",
      "Epoch 563/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.7574 - loss: 0.7476\n",
      "Epoch 563: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7573 - loss: 0.7491 - val_accuracy: 0.8140 - val_loss: 0.6152\n",
      "Epoch 564/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.7539 - loss: 0.7384\n",
      "Epoch 564: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.7538 - loss: 0.7405 - val_accuracy: 0.8145 - val_loss: 0.6345\n",
      "Epoch 565/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.7549 - loss: 0.7670\n",
      "Epoch 565: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7547 - loss: 0.7675 - val_accuracy: 0.8208 - val_loss: 0.6054\n",
      "Epoch 566/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.7510 - loss: 0.7528\n",
      "Epoch 566: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.7509 - loss: 0.7537 - val_accuracy: 0.8134 - val_loss: 0.6079\n",
      "Epoch 567/1000\n",
      "\u001b[1m178/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7432 - loss: 0.8007\n",
      "Epoch 567: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.7449 - loss: 0.7959 - val_accuracy: 0.8180 - val_loss: 0.6093\n",
      "Epoch 568/1000\n",
      "\u001b[1m150/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7616 - loss: 0.7683\n",
      "Epoch 568: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7614 - loss: 0.7635 - val_accuracy: 0.8140 - val_loss: 0.6249\n",
      "Epoch 569/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.7548 - loss: 0.7480\n",
      "Epoch 569: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7557 - loss: 0.7462 - val_accuracy: 0.8145 - val_loss: 0.6112\n",
      "Epoch 570/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.7587 - loss: 0.7558\n",
      "Epoch 570: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.7571 - loss: 0.7584 - val_accuracy: 0.8145 - val_loss: 0.6229\n",
      "Epoch 571/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.7385 - loss: 0.8081\n",
      "Epoch 571: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.7392 - loss: 0.8064 - val_accuracy: 0.8180 - val_loss: 0.6088\n",
      "Epoch 572/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.7521 - loss: 0.7407\n",
      "Epoch 572: val_loss did not improve from 0.59014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.7521 - loss: 0.7410 - val_accuracy: 0.8122 - val_loss: 0.6220\n",
      "Epoch 573/1000\n",
      "\u001b[1m162/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7522 - loss: 0.7551\n",
      "Epoch 573: val_loss improved from 0.59014 to 0.58714, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7522 - loss: 0.7621 - val_accuracy: 0.8237 - val_loss: 0.5871\n",
      "Epoch 574/1000\n",
      "\u001b[1m179/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.7560 - loss: 0.7711\n",
      "Epoch 574: val_loss did not improve from 0.58714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.7561 - loss: 0.7686 - val_accuracy: 0.8042 - val_loss: 0.6164\n",
      "Epoch 575/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.7618 - loss: 0.7597\n",
      "Epoch 575: val_loss did not improve from 0.58714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.7613 - loss: 0.7591 - val_accuracy: 0.8163 - val_loss: 0.6124\n",
      "Epoch 576/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.7529 - loss: 0.7688\n",
      "Epoch 576: val_loss did not improve from 0.58714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.7525 - loss: 0.7694 - val_accuracy: 0.8128 - val_loss: 0.6094\n",
      "Epoch 577/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7608 - loss: 0.7640\n",
      "Epoch 577: val_loss did not improve from 0.58714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7602 - loss: 0.7651 - val_accuracy: 0.8203 - val_loss: 0.6018\n",
      "Epoch 578/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.7418 - loss: 0.7715\n",
      "Epoch 578: val_loss did not improve from 0.58714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7434 - loss: 0.7698 - val_accuracy: 0.8180 - val_loss: 0.6023\n",
      "Epoch 579/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.7587 - loss: 0.7623\n",
      "Epoch 579: val_loss did not improve from 0.58714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7585 - loss: 0.7631 - val_accuracy: 0.8019 - val_loss: 0.6273\n",
      "Epoch 580/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7440 - loss: 0.7783  \n",
      "Epoch 580: val_loss did not improve from 0.58714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7440 - loss: 0.7782 - val_accuracy: 0.8157 - val_loss: 0.6201\n",
      "Epoch 581/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.7543 - loss: 0.7772\n",
      "Epoch 581: val_loss did not improve from 0.58714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.7532 - loss: 0.7787 - val_accuracy: 0.8203 - val_loss: 0.6087\n",
      "Epoch 582/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.7482 - loss: 0.7766\n",
      "Epoch 582: val_loss did not improve from 0.58714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.7482 - loss: 0.7767 - val_accuracy: 0.8077 - val_loss: 0.6183\n",
      "Epoch 583/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.7684 - loss: 0.7202\n",
      "Epoch 583: val_loss did not improve from 0.58714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.7663 - loss: 0.7257 - val_accuracy: 0.8088 - val_loss: 0.6193\n",
      "Epoch 584/1000\n",
      "\u001b[1m166/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7481 - loss: 0.7832\n",
      "Epoch 584: val_loss did not improve from 0.58714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7491 - loss: 0.7773 - val_accuracy: 0.8134 - val_loss: 0.6273\n",
      "Epoch 585/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.7563 - loss: 0.7461\n",
      "Epoch 585: val_loss did not improve from 0.58714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7561 - loss: 0.7468 - val_accuracy: 0.8140 - val_loss: 0.6052\n",
      "Epoch 586/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.7588 - loss: 0.7438\n",
      "Epoch 586: val_loss improved from 0.58714 to 0.57023, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7587 - loss: 0.7438 - val_accuracy: 0.8266 - val_loss: 0.5702\n",
      "Epoch 587/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7593 - loss: 0.7430\n",
      "Epoch 587: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7593 - loss: 0.7445 - val_accuracy: 0.8128 - val_loss: 0.6088\n",
      "Epoch 588/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.7568 - loss: 0.7507\n",
      "Epoch 588: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7576 - loss: 0.7497 - val_accuracy: 0.8134 - val_loss: 0.5999\n",
      "Epoch 589/1000\n",
      "\u001b[1m184/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.7600 - loss: 0.7581\n",
      "Epoch 589: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.7604 - loss: 0.7558 - val_accuracy: 0.8157 - val_loss: 0.6108\n",
      "Epoch 590/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.7495 - loss: 0.7719\n",
      "Epoch 590: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7499 - loss: 0.7709 - val_accuracy: 0.8094 - val_loss: 0.6207\n",
      "Epoch 591/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.7670 - loss: 0.7497\n",
      "Epoch 591: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7654 - loss: 0.7522 - val_accuracy: 0.8145 - val_loss: 0.6237\n",
      "Epoch 592/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.7588 - loss: 0.7512\n",
      "Epoch 592: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.7585 - loss: 0.7524 - val_accuracy: 0.8105 - val_loss: 0.6116\n",
      "Epoch 593/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.7430 - loss: 0.7987\n",
      "Epoch 593: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.7444 - loss: 0.7908 - val_accuracy: 0.8122 - val_loss: 0.6071\n",
      "Epoch 594/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.7468 - loss: 0.7752\n",
      "Epoch 594: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.7471 - loss: 0.7734 - val_accuracy: 0.8231 - val_loss: 0.5999\n",
      "Epoch 595/1000\n",
      "\u001b[1m182/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.7524 - loss: 0.7690\n",
      "Epoch 595: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.7532 - loss: 0.7673 - val_accuracy: 0.8203 - val_loss: 0.6168\n",
      "Epoch 596/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.7558 - loss: 0.7433\n",
      "Epoch 596: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7559 - loss: 0.7432 - val_accuracy: 0.8254 - val_loss: 0.6003\n",
      "Epoch 597/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7630 - loss: 0.7475\n",
      "Epoch 597: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7621 - loss: 0.7501 - val_accuracy: 0.8243 - val_loss: 0.5937\n",
      "Epoch 598/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7561 - loss: 0.7572\n",
      "Epoch 598: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7558 - loss: 0.7584 - val_accuracy: 0.8220 - val_loss: 0.6140\n",
      "Epoch 599/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.7621 - loss: 0.7736\n",
      "Epoch 599: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.7618 - loss: 0.7731 - val_accuracy: 0.8163 - val_loss: 0.6276\n",
      "Epoch 600/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.7487 - loss: 0.7822\n",
      "Epoch 600: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.7487 - loss: 0.7820 - val_accuracy: 0.8122 - val_loss: 0.6240\n",
      "Epoch 601/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7517 - loss: 0.7678  \n",
      "Epoch 601: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7519 - loss: 0.7674 - val_accuracy: 0.8243 - val_loss: 0.6084\n",
      "Epoch 602/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.7560 - loss: 0.7717\n",
      "Epoch 602: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.7558 - loss: 0.7705 - val_accuracy: 0.8226 - val_loss: 0.6099\n",
      "Epoch 603/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.7575 - loss: 0.7480\n",
      "Epoch 603: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.7571 - loss: 0.7485 - val_accuracy: 0.8174 - val_loss: 0.6133\n",
      "Epoch 604/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7486 - loss: 0.7792\n",
      "Epoch 604: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7492 - loss: 0.7768 - val_accuracy: 0.8185 - val_loss: 0.6120\n",
      "Epoch 605/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7612 - loss: 0.7605\n",
      "Epoch 605: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7608 - loss: 0.7589 - val_accuracy: 0.8151 - val_loss: 0.6292\n",
      "Epoch 606/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7623 - loss: 0.7577\n",
      "Epoch 606: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7615 - loss: 0.7593 - val_accuracy: 0.8140 - val_loss: 0.6068\n",
      "Epoch 607/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.7511 - loss: 0.7693\n",
      "Epoch 607: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.7510 - loss: 0.7690 - val_accuracy: 0.8191 - val_loss: 0.6089\n",
      "Epoch 608/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7434 - loss: 0.7959\n",
      "Epoch 608: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7439 - loss: 0.7944 - val_accuracy: 0.8185 - val_loss: 0.6076\n",
      "Epoch 609/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.7692 - loss: 0.7300\n",
      "Epoch 609: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.7685 - loss: 0.7317 - val_accuracy: 0.8237 - val_loss: 0.6000\n",
      "Epoch 610/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.7696 - loss: 0.7366\n",
      "Epoch 610: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.7686 - loss: 0.7388 - val_accuracy: 0.8174 - val_loss: 0.6091\n",
      "Epoch 611/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.7599 - loss: 0.7532\n",
      "Epoch 611: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7590 - loss: 0.7540 - val_accuracy: 0.8145 - val_loss: 0.6104\n",
      "Epoch 612/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7642 - loss: 0.7207\n",
      "Epoch 612: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7635 - loss: 0.7279 - val_accuracy: 0.8128 - val_loss: 0.6336\n",
      "Epoch 613/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.7406 - loss: 0.8033\n",
      "Epoch 613: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7414 - loss: 0.8012 - val_accuracy: 0.8254 - val_loss: 0.6036\n",
      "Epoch 614/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7615 - loss: 0.7403\n",
      "Epoch 614: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7615 - loss: 0.7398 - val_accuracy: 0.8134 - val_loss: 0.6081\n",
      "Epoch 615/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7547 - loss: 0.7666\n",
      "Epoch 615: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7548 - loss: 0.7661 - val_accuracy: 0.8266 - val_loss: 0.5972\n",
      "Epoch 616/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.7549 - loss: 0.7572\n",
      "Epoch 616: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.7550 - loss: 0.7573 - val_accuracy: 0.8231 - val_loss: 0.6105\n",
      "Epoch 617/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.7506 - loss: 0.7740\n",
      "Epoch 617: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7505 - loss: 0.7740 - val_accuracy: 0.8191 - val_loss: 0.5937\n",
      "Epoch 618/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.7631 - loss: 0.7467\n",
      "Epoch 618: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.7629 - loss: 0.7479 - val_accuracy: 0.8105 - val_loss: 0.6275\n",
      "Epoch 619/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7505 - loss: 0.7651\n",
      "Epoch 619: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7506 - loss: 0.7635 - val_accuracy: 0.8208 - val_loss: 0.6174\n",
      "Epoch 620/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.7558 - loss: 0.7567\n",
      "Epoch 620: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.7559 - loss: 0.7575 - val_accuracy: 0.8283 - val_loss: 0.5832\n",
      "Epoch 621/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.7592 - loss: 0.7592\n",
      "Epoch 621: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.7584 - loss: 0.7601 - val_accuracy: 0.8140 - val_loss: 0.6066\n",
      "Epoch 622/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.7477 - loss: 0.7820\n",
      "Epoch 622: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7475 - loss: 0.7820 - val_accuracy: 0.8163 - val_loss: 0.6229\n",
      "Epoch 623/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.7478 - loss: 0.7844\n",
      "Epoch 623: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.7477 - loss: 0.7843 - val_accuracy: 0.8077 - val_loss: 0.6217\n",
      "Epoch 624/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7595 - loss: 0.7599\n",
      "Epoch 624: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7592 - loss: 0.7598 - val_accuracy: 0.8122 - val_loss: 0.6156\n",
      "Epoch 625/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.7530 - loss: 0.7707\n",
      "Epoch 625: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.7529 - loss: 0.7712 - val_accuracy: 0.8185 - val_loss: 0.6035\n",
      "Epoch 626/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7550 - loss: 0.7492\n",
      "Epoch 626: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7554 - loss: 0.7491 - val_accuracy: 0.8220 - val_loss: 0.6093\n",
      "Epoch 627/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.7610 - loss: 0.7293\n",
      "Epoch 627: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.7610 - loss: 0.7309 - val_accuracy: 0.8151 - val_loss: 0.6382\n",
      "Epoch 628/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.7375 - loss: 0.8446\n",
      "Epoch 628: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.7404 - loss: 0.8313 - val_accuracy: 0.8220 - val_loss: 0.6008\n",
      "Epoch 629/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7554 - loss: 0.7458\n",
      "Epoch 629: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7551 - loss: 0.7471 - val_accuracy: 0.8174 - val_loss: 0.5956\n",
      "Epoch 630/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.7507 - loss: 0.7642\n",
      "Epoch 630: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7511 - loss: 0.7632 - val_accuracy: 0.8088 - val_loss: 0.6355\n",
      "Epoch 631/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7428 - loss: 0.7838\n",
      "Epoch 631: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.7437 - loss: 0.7818 - val_accuracy: 0.8145 - val_loss: 0.6190\n",
      "Epoch 632/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7549 - loss: 0.7738\n",
      "Epoch 632: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7549 - loss: 0.7733 - val_accuracy: 0.8157 - val_loss: 0.6008\n",
      "Epoch 633/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7697 - loss: 0.7474\n",
      "Epoch 633: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7684 - loss: 0.7492 - val_accuracy: 0.8134 - val_loss: 0.6028\n",
      "Epoch 634/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.7445 - loss: 0.7812\n",
      "Epoch 634: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.7452 - loss: 0.7805 - val_accuracy: 0.8094 - val_loss: 0.6164\n",
      "Epoch 635/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.7470 - loss: 0.7909\n",
      "Epoch 635: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.7473 - loss: 0.7897 - val_accuracy: 0.8191 - val_loss: 0.5934\n",
      "Epoch 636/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7642 - loss: 0.7320\n",
      "Epoch 636: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7638 - loss: 0.7333 - val_accuracy: 0.8208 - val_loss: 0.5957\n",
      "Epoch 637/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.7640 - loss: 0.7192\n",
      "Epoch 637: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7630 - loss: 0.7230 - val_accuracy: 0.8208 - val_loss: 0.6074\n",
      "Epoch 638/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7553 - loss: 0.7544\n",
      "Epoch 638: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7553 - loss: 0.7536 - val_accuracy: 0.8329 - val_loss: 0.5846\n",
      "Epoch 639/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7474 - loss: 0.7675\n",
      "Epoch 639: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7475 - loss: 0.7679 - val_accuracy: 0.8128 - val_loss: 0.5914\n",
      "Epoch 640/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.7473 - loss: 0.7702\n",
      "Epoch 640: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.7474 - loss: 0.7710 - val_accuracy: 0.8140 - val_loss: 0.6136\n",
      "Epoch 641/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.7628 - loss: 0.7510\n",
      "Epoch 641: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7625 - loss: 0.7526 - val_accuracy: 0.8140 - val_loss: 0.5977\n",
      "Epoch 642/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7464 - loss: 0.7728\n",
      "Epoch 642: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.7738 - val_accuracy: 0.8082 - val_loss: 0.6165\n",
      "Epoch 643/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.7645 - loss: 0.7315\n",
      "Epoch 643: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.7644 - loss: 0.7317 - val_accuracy: 0.8231 - val_loss: 0.5878\n",
      "Epoch 644/1000\n",
      "\u001b[1m206/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.7583 - loss: 0.7542\n",
      "Epoch 644: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.7586 - loss: 0.7542 - val_accuracy: 0.8214 - val_loss: 0.5949\n",
      "Epoch 645/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7540 - loss: 0.7747\n",
      "Epoch 645: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7539 - loss: 0.7734 - val_accuracy: 0.8100 - val_loss: 0.6272\n",
      "Epoch 646/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.7577 - loss: 0.7531\n",
      "Epoch 646: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7580 - loss: 0.7542 - val_accuracy: 0.8088 - val_loss: 0.6186\n",
      "Epoch 647/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7419 - loss: 0.7698\n",
      "Epoch 647: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7437 - loss: 0.7666 - val_accuracy: 0.8168 - val_loss: 0.5872\n",
      "Epoch 648/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7654 - loss: 0.7371\n",
      "Epoch 648: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7646 - loss: 0.7399 - val_accuracy: 0.8077 - val_loss: 0.6048\n",
      "Epoch 649/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.7608 - loss: 0.7462\n",
      "Epoch 649: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.7607 - loss: 0.7456 - val_accuracy: 0.8220 - val_loss: 0.5891\n",
      "Epoch 650/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7489 - loss: 0.7469\n",
      "Epoch 650: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7504 - loss: 0.7454 - val_accuracy: 0.8145 - val_loss: 0.6042\n",
      "Epoch 651/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.7523 - loss: 0.7658\n",
      "Epoch 651: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7524 - loss: 0.7653 - val_accuracy: 0.8151 - val_loss: 0.5903\n",
      "Epoch 652/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.7714 - loss: 0.7374\n",
      "Epoch 652: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7711 - loss: 0.7380 - val_accuracy: 0.8220 - val_loss: 0.6094\n",
      "Epoch 653/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.7605 - loss: 0.7405\n",
      "Epoch 653: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.7603 - loss: 0.7412 - val_accuracy: 0.8157 - val_loss: 0.6248\n",
      "Epoch 654/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.7537 - loss: 0.7762\n",
      "Epoch 654: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.7537 - loss: 0.7756 - val_accuracy: 0.8260 - val_loss: 0.5842\n",
      "Epoch 655/1000\n",
      "\u001b[1m151/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7589 - loss: 0.7352\n",
      "Epoch 655: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7608 - loss: 0.7418 - val_accuracy: 0.8214 - val_loss: 0.6118\n",
      "Epoch 656/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.7534 - loss: 0.7929\n",
      "Epoch 656: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.7538 - loss: 0.7912 - val_accuracy: 0.8180 - val_loss: 0.5983\n",
      "Epoch 657/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7602 - loss: 0.7500\n",
      "Epoch 657: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.7601 - loss: 0.7504 - val_accuracy: 0.8248 - val_loss: 0.5983\n",
      "Epoch 658/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.7567 - loss: 0.7374\n",
      "Epoch 658: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7568 - loss: 0.7374 - val_accuracy: 0.8220 - val_loss: 0.6013\n",
      "Epoch 659/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.7500 - loss: 0.7753\n",
      "Epoch 659: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.7505 - loss: 0.7741 - val_accuracy: 0.8248 - val_loss: 0.5937\n",
      "Epoch 660/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.7633 - loss: 0.7577\n",
      "Epoch 660: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.7623 - loss: 0.7590 - val_accuracy: 0.8151 - val_loss: 0.6321\n",
      "Epoch 661/1000\n",
      "\u001b[1m167/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7680 - loss: 0.7046\n",
      "Epoch 661: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7662 - loss: 0.7106 - val_accuracy: 0.8231 - val_loss: 0.5994\n",
      "Epoch 662/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.7524 - loss: 0.7821\n",
      "Epoch 662: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.7525 - loss: 0.7809 - val_accuracy: 0.8203 - val_loss: 0.6097\n",
      "Epoch 663/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.7635 - loss: 0.7393\n",
      "Epoch 663: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.7634 - loss: 0.7400 - val_accuracy: 0.8306 - val_loss: 0.5902\n",
      "Epoch 664/1000\n",
      "\u001b[1m147/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7597 - loss: 0.7696\n",
      "Epoch 664: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7588 - loss: 0.7641 - val_accuracy: 0.8140 - val_loss: 0.6145\n",
      "Epoch 665/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7576 - loss: 0.7750\n",
      "Epoch 665: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.7581 - loss: 0.7730 - val_accuracy: 0.8243 - val_loss: 0.6107\n",
      "Epoch 666/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7413 - loss: 0.7876\n",
      "Epoch 666: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7427 - loss: 0.7845 - val_accuracy: 0.8191 - val_loss: 0.5998\n",
      "Epoch 667/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7550 - loss: 0.7383\n",
      "Epoch 667: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7551 - loss: 0.7392 - val_accuracy: 0.8191 - val_loss: 0.6160\n",
      "Epoch 668/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.7469 - loss: 0.7774\n",
      "Epoch 668: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.7476 - loss: 0.7746 - val_accuracy: 0.8208 - val_loss: 0.5984\n",
      "Epoch 669/1000\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.7633 - loss: 0.7283\n",
      "Epoch 669: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.7633 - loss: 0.7295 - val_accuracy: 0.8203 - val_loss: 0.5902\n",
      "Epoch 670/1000\n",
      "\u001b[1m206/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7718 - loss: 0.7240\n",
      "Epoch 670: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7712 - loss: 0.7247 - val_accuracy: 0.8151 - val_loss: 0.6008\n",
      "Epoch 671/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7594 - loss: 0.7652\n",
      "Epoch 671: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.7594 - loss: 0.7645 - val_accuracy: 0.8208 - val_loss: 0.6170\n",
      "Epoch 672/1000\n",
      "\u001b[1m145/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.7638 - loss: 0.7353\n",
      "Epoch 672: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.7633 - loss: 0.7369 - val_accuracy: 0.8231 - val_loss: 0.6058\n",
      "Epoch 673/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7559 - loss: 0.7557\n",
      "Epoch 673: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7559 - loss: 0.7563 - val_accuracy: 0.8266 - val_loss: 0.6023\n",
      "Epoch 674/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.7592 - loss: 0.7738\n",
      "Epoch 674: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.7592 - loss: 0.7727 - val_accuracy: 0.8248 - val_loss: 0.5910\n",
      "Epoch 675/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.7615 - loss: 0.7563\n",
      "Epoch 675: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.7613 - loss: 0.7557 - val_accuracy: 0.8237 - val_loss: 0.6138\n",
      "Epoch 676/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.7556 - loss: 0.7655\n",
      "Epoch 676: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7556 - loss: 0.7655 - val_accuracy: 0.8237 - val_loss: 0.6099\n",
      "Epoch 677/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.7535 - loss: 0.7611\n",
      "Epoch 677: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7536 - loss: 0.7620 - val_accuracy: 0.8111 - val_loss: 0.6292\n",
      "Epoch 678/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.7474 - loss: 0.7827\n",
      "Epoch 678: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7477 - loss: 0.7831 - val_accuracy: 0.8340 - val_loss: 0.5811\n",
      "Epoch 679/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.7535 - loss: 0.7638\n",
      "Epoch 679: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7529 - loss: 0.7648 - val_accuracy: 0.8185 - val_loss: 0.6009\n",
      "Epoch 680/1000\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7555 - loss: 0.7495\n",
      "Epoch 680: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7555 - loss: 0.7493 - val_accuracy: 0.8197 - val_loss: 0.6023\n",
      "Epoch 681/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.7511 - loss: 0.7809\n",
      "Epoch 681: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.7519 - loss: 0.7777 - val_accuracy: 0.8271 - val_loss: 0.5878\n",
      "Epoch 682/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.7584 - loss: 0.7652\n",
      "Epoch 682: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7591 - loss: 0.7613 - val_accuracy: 0.8220 - val_loss: 0.5953\n",
      "Epoch 683/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7593 - loss: 0.7560\n",
      "Epoch 683: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7591 - loss: 0.7572 - val_accuracy: 0.8134 - val_loss: 0.6082\n",
      "Epoch 684/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.7569 - loss: 0.7644\n",
      "Epoch 684: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.7571 - loss: 0.7642 - val_accuracy: 0.8168 - val_loss: 0.6077\n",
      "Epoch 685/1000\n",
      "\u001b[1m206/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.7678 - loss: 0.7346\n",
      "Epoch 685: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7676 - loss: 0.7348 - val_accuracy: 0.8283 - val_loss: 0.6049\n",
      "Epoch 686/1000\n",
      "\u001b[1m148/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7565 - loss: 0.7443\n",
      "Epoch 686: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7571 - loss: 0.7429 - val_accuracy: 0.8168 - val_loss: 0.5950\n",
      "Epoch 687/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.7570 - loss: 0.7250\n",
      "Epoch 687: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.7565 - loss: 0.7267 - val_accuracy: 0.8191 - val_loss: 0.6066\n",
      "Epoch 688/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7518 - loss: 0.7783\n",
      "Epoch 688: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.7525 - loss: 0.7762 - val_accuracy: 0.8157 - val_loss: 0.5868\n",
      "Epoch 689/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7636 - loss: 0.7371\n",
      "Epoch 689: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7633 - loss: 0.7374 - val_accuracy: 0.8266 - val_loss: 0.5852\n",
      "Epoch 690/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.7498 - loss: 0.7822\n",
      "Epoch 690: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.7499 - loss: 0.7825 - val_accuracy: 0.8094 - val_loss: 0.6160\n",
      "Epoch 691/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7539 - loss: 0.7701\n",
      "Epoch 691: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.7536 - loss: 0.7704 - val_accuracy: 0.8185 - val_loss: 0.6076\n",
      "Epoch 692/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7542 - loss: 0.7650\n",
      "Epoch 692: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7538 - loss: 0.7652 - val_accuracy: 0.8145 - val_loss: 0.6053\n",
      "Epoch 693/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7557 - loss: 0.7476\n",
      "Epoch 693: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.7559 - loss: 0.7476 - val_accuracy: 0.8214 - val_loss: 0.6025\n",
      "Epoch 694/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.7663 - loss: 0.7300\n",
      "Epoch 694: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.7658 - loss: 0.7316 - val_accuracy: 0.8105 - val_loss: 0.6259\n",
      "Epoch 695/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7527 - loss: 0.7744\n",
      "Epoch 695: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7534 - loss: 0.7732 - val_accuracy: 0.8237 - val_loss: 0.6152\n",
      "Epoch 696/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.7629 - loss: 0.7556\n",
      "Epoch 696: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7627 - loss: 0.7555 - val_accuracy: 0.8254 - val_loss: 0.6175\n",
      "Epoch 697/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.7711 - loss: 0.7034\n",
      "Epoch 697: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.7699 - loss: 0.7077 - val_accuracy: 0.8214 - val_loss: 0.6001\n",
      "Epoch 698/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7594 - loss: 0.7515\n",
      "Epoch 698: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7595 - loss: 0.7516 - val_accuracy: 0.8088 - val_loss: 0.6056\n",
      "Epoch 699/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.7624 - loss: 0.7629\n",
      "Epoch 699: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.7625 - loss: 0.7619 - val_accuracy: 0.8128 - val_loss: 0.6173\n",
      "Epoch 700/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.7648 - loss: 0.7420\n",
      "Epoch 700: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7649 - loss: 0.7422 - val_accuracy: 0.8203 - val_loss: 0.5918\n",
      "Epoch 701/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.7633 - loss: 0.7416\n",
      "Epoch 701: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7632 - loss: 0.7417 - val_accuracy: 0.8180 - val_loss: 0.5910\n",
      "Epoch 702/1000\n",
      "\u001b[1m206/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.7700 - loss: 0.7305\n",
      "Epoch 702: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7697 - loss: 0.7308 - val_accuracy: 0.8243 - val_loss: 0.5838\n",
      "Epoch 703/1000\n",
      "\u001b[1m174/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.7542 - loss: 0.7423\n",
      "Epoch 703: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7554 - loss: 0.7445 - val_accuracy: 0.8214 - val_loss: 0.5923\n",
      "Epoch 704/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7691 - loss: 0.7133\n",
      "Epoch 704: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7678 - loss: 0.7185 - val_accuracy: 0.8197 - val_loss: 0.6091\n",
      "Epoch 705/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7543 - loss: 0.7644\n",
      "Epoch 705: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.7548 - loss: 0.7626 - val_accuracy: 0.8226 - val_loss: 0.5857\n",
      "Epoch 706/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7441 - loss: 0.7720\n",
      "Epoch 706: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7442 - loss: 0.7720 - val_accuracy: 0.8180 - val_loss: 0.6004\n",
      "Epoch 707/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.7389 - loss: 0.7826\n",
      "Epoch 707: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7411 - loss: 0.7790 - val_accuracy: 0.8237 - val_loss: 0.5975\n",
      "Epoch 708/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7640 - loss: 0.7187\n",
      "Epoch 708: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.7632 - loss: 0.7211 - val_accuracy: 0.8025 - val_loss: 0.6152\n",
      "Epoch 709/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7476 - loss: 0.7742\n",
      "Epoch 709: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7479 - loss: 0.7739 - val_accuracy: 0.8191 - val_loss: 0.6079\n",
      "Epoch 710/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7611 - loss: 0.7451\n",
      "Epoch 710: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7609 - loss: 0.7468 - val_accuracy: 0.8231 - val_loss: 0.6166\n",
      "Epoch 711/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7665 - loss: 0.7246  \n",
      "Epoch 711: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7661 - loss: 0.7256 - val_accuracy: 0.8163 - val_loss: 0.6163\n",
      "Epoch 712/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.7459 - loss: 0.7931\n",
      "Epoch 712: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.7479 - loss: 0.7889 - val_accuracy: 0.8174 - val_loss: 0.5996\n",
      "Epoch 713/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.7602 - loss: 0.7478\n",
      "Epoch 713: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7602 - loss: 0.7475 - val_accuracy: 0.8311 - val_loss: 0.5933\n",
      "Epoch 714/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.7651 - loss: 0.7357\n",
      "Epoch 714: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7651 - loss: 0.7359 - val_accuracy: 0.8237 - val_loss: 0.6057\n",
      "Epoch 715/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.7544 - loss: 0.7585\n",
      "Epoch 715: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.7546 - loss: 0.7583 - val_accuracy: 0.8243 - val_loss: 0.5924\n",
      "Epoch 716/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7495 - loss: 0.7621\n",
      "Epoch 716: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7501 - loss: 0.7611 - val_accuracy: 0.8208 - val_loss: 0.6055\n",
      "Epoch 717/1000\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7522 - loss: 0.7466\n",
      "Epoch 717: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7525 - loss: 0.7470 - val_accuracy: 0.8197 - val_loss: 0.6105\n",
      "Epoch 718/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7641 - loss: 0.7650\n",
      "Epoch 718: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.7637 - loss: 0.7653 - val_accuracy: 0.8260 - val_loss: 0.6152\n",
      "Epoch 719/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.7701 - loss: 0.7177\n",
      "Epoch 719: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.7691 - loss: 0.7218 - val_accuracy: 0.8180 - val_loss: 0.6116\n",
      "Epoch 720/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7772 - loss: 0.7175\n",
      "Epoch 720: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.7755 - loss: 0.7192 - val_accuracy: 0.8088 - val_loss: 0.6397\n",
      "Epoch 721/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7608 - loss: 0.7489\n",
      "Epoch 721: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.7612 - loss: 0.7468 - val_accuracy: 0.8122 - val_loss: 0.6232\n",
      "Epoch 722/1000\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.7684 - loss: 0.7195\n",
      "Epoch 722: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.7677 - loss: 0.7227 - val_accuracy: 0.8214 - val_loss: 0.6128\n",
      "Epoch 723/1000\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7619 - loss: 0.7579\n",
      "Epoch 723: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7618 - loss: 0.7583 - val_accuracy: 0.8105 - val_loss: 0.6016\n",
      "Epoch 724/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.7653 - loss: 0.7245\n",
      "Epoch 724: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7644 - loss: 0.7270 - val_accuracy: 0.8157 - val_loss: 0.6045\n",
      "Epoch 725/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.7423 - loss: 0.7757\n",
      "Epoch 725: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.7429 - loss: 0.7754 - val_accuracy: 0.8157 - val_loss: 0.6090\n",
      "Epoch 726/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7396 - loss: 0.8176\n",
      "Epoch 726: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7401 - loss: 0.8161 - val_accuracy: 0.8151 - val_loss: 0.5875\n",
      "Epoch 727/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.7511 - loss: 0.7830\n",
      "Epoch 727: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.7518 - loss: 0.7810 - val_accuracy: 0.8306 - val_loss: 0.5886\n",
      "Epoch 728/1000\n",
      "\u001b[1m182/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.7653 - loss: 0.7294\n",
      "Epoch 728: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.7632 - loss: 0.7337 - val_accuracy: 0.8214 - val_loss: 0.5973\n",
      "Epoch 729/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7641 - loss: 0.7419\n",
      "Epoch 729: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7640 - loss: 0.7422 - val_accuracy: 0.8163 - val_loss: 0.5862\n",
      "Epoch 730/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7496 - loss: 0.7576\n",
      "Epoch 730: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7511 - loss: 0.7544 - val_accuracy: 0.8248 - val_loss: 0.5931\n",
      "Epoch 731/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.7574 - loss: 0.7465\n",
      "Epoch 731: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7584 - loss: 0.7430 - val_accuracy: 0.8203 - val_loss: 0.5908\n",
      "Epoch 732/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7569 - loss: 0.7474\n",
      "Epoch 732: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7568 - loss: 0.7474 - val_accuracy: 0.8185 - val_loss: 0.6140\n",
      "Epoch 733/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.7541 - loss: 0.7554\n",
      "Epoch 733: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.7542 - loss: 0.7557 - val_accuracy: 0.8208 - val_loss: 0.5916\n",
      "Epoch 734/1000\n",
      "\u001b[1m177/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7655 - loss: 0.7070\n",
      "Epoch 734: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7644 - loss: 0.7129 - val_accuracy: 0.8185 - val_loss: 0.6012\n",
      "Epoch 735/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.7725 - loss: 0.7189\n",
      "Epoch 735: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.7698 - loss: 0.7232 - val_accuracy: 0.8168 - val_loss: 0.6022\n",
      "Epoch 736/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.7540 - loss: 0.7408\n",
      "Epoch 736: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7542 - loss: 0.7415 - val_accuracy: 0.8157 - val_loss: 0.6011\n",
      "Epoch 737/1000\n",
      "\u001b[1m181/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7604 - loss: 0.7600\n",
      "Epoch 737: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7599 - loss: 0.7604 - val_accuracy: 0.8145 - val_loss: 0.6172\n",
      "Epoch 738/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.7635 - loss: 0.7311\n",
      "Epoch 738: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.7636 - loss: 0.7310 - val_accuracy: 0.8191 - val_loss: 0.5977\n",
      "Epoch 739/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.7554 - loss: 0.7575\n",
      "Epoch 739: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7558 - loss: 0.7568 - val_accuracy: 0.8145 - val_loss: 0.5854\n",
      "Epoch 740/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7560 - loss: 0.7638\n",
      "Epoch 740: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7560 - loss: 0.7638 - val_accuracy: 0.8283 - val_loss: 0.5814\n",
      "Epoch 741/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.7599 - loss: 0.7476\n",
      "Epoch 741: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7598 - loss: 0.7482 - val_accuracy: 0.8254 - val_loss: 0.6014\n",
      "Epoch 742/1000\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.7699 - loss: 0.7414\n",
      "Epoch 742: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.7697 - loss: 0.7410 - val_accuracy: 0.8208 - val_loss: 0.5942\n",
      "Epoch 743/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7556 - loss: 0.7658\n",
      "Epoch 743: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7559 - loss: 0.7649 - val_accuracy: 0.8214 - val_loss: 0.6072\n",
      "Epoch 744/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.7638 - loss: 0.7399\n",
      "Epoch 744: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7636 - loss: 0.7402 - val_accuracy: 0.8248 - val_loss: 0.5893\n",
      "Epoch 745/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.7612 - loss: 0.7443\n",
      "Epoch 745: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.7613 - loss: 0.7443 - val_accuracy: 0.8191 - val_loss: 0.6021\n",
      "Epoch 746/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7568 - loss: 0.7593\n",
      "Epoch 746: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7570 - loss: 0.7583 - val_accuracy: 0.8208 - val_loss: 0.5851\n",
      "Epoch 747/1000\n",
      "\u001b[1m206/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.7559 - loss: 0.7285\n",
      "Epoch 747: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.7563 - loss: 0.7288 - val_accuracy: 0.8248 - val_loss: 0.5970\n",
      "Epoch 748/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7682 - loss: 0.7284\n",
      "Epoch 748: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7686 - loss: 0.7279 - val_accuracy: 0.8191 - val_loss: 0.5986\n",
      "Epoch 749/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.7557 - loss: 0.7783\n",
      "Epoch 749: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7562 - loss: 0.7749 - val_accuracy: 0.8260 - val_loss: 0.5950\n",
      "Epoch 750/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.7614 - loss: 0.7634\n",
      "Epoch 750: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7612 - loss: 0.7624 - val_accuracy: 0.8294 - val_loss: 0.6023\n",
      "Epoch 751/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7626 - loss: 0.7402\n",
      "Epoch 751: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7622 - loss: 0.7402 - val_accuracy: 0.8214 - val_loss: 0.5986\n",
      "Epoch 752/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.7656 - loss: 0.7612\n",
      "Epoch 752: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.7655 - loss: 0.7602 - val_accuracy: 0.8254 - val_loss: 0.5869\n",
      "Epoch 753/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7488 - loss: 0.7919\n",
      "Epoch 753: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7498 - loss: 0.7886 - val_accuracy: 0.8226 - val_loss: 0.5972\n",
      "Epoch 754/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.7547 - loss: 0.7397\n",
      "Epoch 754: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7546 - loss: 0.7415 - val_accuracy: 0.8168 - val_loss: 0.6262\n",
      "Epoch 755/1000\n",
      "\u001b[1m184/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7578 - loss: 0.7750\n",
      "Epoch 755: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.7586 - loss: 0.7712 - val_accuracy: 0.8157 - val_loss: 0.6030\n",
      "Epoch 756/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7574 - loss: 0.7647\n",
      "Epoch 756: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7580 - loss: 0.7622 - val_accuracy: 0.8254 - val_loss: 0.6059\n",
      "Epoch 757/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.7646 - loss: 0.7308\n",
      "Epoch 757: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7654 - loss: 0.7288 - val_accuracy: 0.8283 - val_loss: 0.5924\n",
      "Epoch 758/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.7688 - loss: 0.7233\n",
      "Epoch 758: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.7685 - loss: 0.7245 - val_accuracy: 0.8237 - val_loss: 0.5941\n",
      "Epoch 759/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7522 - loss: 0.7635\n",
      "Epoch 759: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7522 - loss: 0.7634 - val_accuracy: 0.8294 - val_loss: 0.6042\n",
      "Epoch 760/1000\n",
      "\u001b[1m184/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7604 - loss: 0.7444\n",
      "Epoch 760: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.7603 - loss: 0.7455 - val_accuracy: 0.8054 - val_loss: 0.6064\n",
      "Epoch 761/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.7454 - loss: 0.7929\n",
      "Epoch 761: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7474 - loss: 0.7887 - val_accuracy: 0.8019 - val_loss: 0.6246\n",
      "Epoch 762/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.7608 - loss: 0.7362\n",
      "Epoch 762: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.7608 - loss: 0.7359 - val_accuracy: 0.8311 - val_loss: 0.5935\n",
      "Epoch 763/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7611 - loss: 0.7549\n",
      "Epoch 763: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7605 - loss: 0.7552 - val_accuracy: 0.8237 - val_loss: 0.6142\n",
      "Epoch 764/1000\n",
      "\u001b[1m185/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.7702 - loss: 0.7370\n",
      "Epoch 764: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7682 - loss: 0.7393 - val_accuracy: 0.8180 - val_loss: 0.6127\n",
      "Epoch 765/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.7598 - loss: 0.7574\n",
      "Epoch 765: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7598 - loss: 0.7571 - val_accuracy: 0.8243 - val_loss: 0.5972\n",
      "Epoch 766/1000\n",
      "\u001b[1m185/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.7549 - loss: 0.7588\n",
      "Epoch 766: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.7542 - loss: 0.7592 - val_accuracy: 0.8191 - val_loss: 0.6134\n",
      "Epoch 767/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.7516 - loss: 0.7820\n",
      "Epoch 767: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7523 - loss: 0.7779 - val_accuracy: 0.8185 - val_loss: 0.5734\n",
      "Epoch 768/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.7626 - loss: 0.7322\n",
      "Epoch 768: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.7619 - loss: 0.7355 - val_accuracy: 0.8271 - val_loss: 0.5764\n",
      "Epoch 769/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7604 - loss: 0.7523\n",
      "Epoch 769: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7605 - loss: 0.7523 - val_accuracy: 0.8260 - val_loss: 0.5849\n",
      "Epoch 770/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7653 - loss: 0.7493\n",
      "Epoch 770: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7652 - loss: 0.7467 - val_accuracy: 0.8254 - val_loss: 0.5755\n",
      "Epoch 771/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7613 - loss: 0.7683\n",
      "Epoch 771: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7618 - loss: 0.7670 - val_accuracy: 0.8197 - val_loss: 0.5949\n",
      "Epoch 772/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7626 - loss: 0.7160\n",
      "Epoch 772: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7627 - loss: 0.7175 - val_accuracy: 0.8185 - val_loss: 0.5863\n",
      "Epoch 773/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7512 - loss: 0.7623\n",
      "Epoch 773: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.7512 - loss: 0.7611 - val_accuracy: 0.8237 - val_loss: 0.5856\n",
      "Epoch 774/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7646 - loss: 0.7348\n",
      "Epoch 774: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7650 - loss: 0.7358 - val_accuracy: 0.8157 - val_loss: 0.5969\n",
      "Epoch 775/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7601 - loss: 0.7410\n",
      "Epoch 775: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7600 - loss: 0.7413 - val_accuracy: 0.8203 - val_loss: 0.5926\n",
      "Epoch 776/1000\n",
      "\u001b[1m180/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7645 - loss: 0.7457\n",
      "Epoch 776: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7642 - loss: 0.7447 - val_accuracy: 0.8197 - val_loss: 0.6093\n",
      "Epoch 777/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.7743 - loss: 0.6973\n",
      "Epoch 777: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7730 - loss: 0.7018 - val_accuracy: 0.8105 - val_loss: 0.5965\n",
      "Epoch 778/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7596 - loss: 0.7560\n",
      "Epoch 778: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7596 - loss: 0.7562 - val_accuracy: 0.8266 - val_loss: 0.5818\n",
      "Epoch 779/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7660 - loss: 0.7045\n",
      "Epoch 779: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7654 - loss: 0.7088 - val_accuracy: 0.8145 - val_loss: 0.5998\n",
      "Epoch 780/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7580 - loss: 0.7450\n",
      "Epoch 780: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7579 - loss: 0.7453 - val_accuracy: 0.8288 - val_loss: 0.5829\n",
      "Epoch 781/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7519 - loss: 0.7683\n",
      "Epoch 781: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7530 - loss: 0.7659 - val_accuracy: 0.8346 - val_loss: 0.5848\n",
      "Epoch 782/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.7509 - loss: 0.7629\n",
      "Epoch 782: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7524 - loss: 0.7592 - val_accuracy: 0.8191 - val_loss: 0.6023\n",
      "Epoch 783/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7643 - loss: 0.7488\n",
      "Epoch 783: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7642 - loss: 0.7489 - val_accuracy: 0.8134 - val_loss: 0.6105\n",
      "Epoch 784/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.7701 - loss: 0.7014\n",
      "Epoch 784: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.7695 - loss: 0.7048 - val_accuracy: 0.8168 - val_loss: 0.6129\n",
      "Epoch 785/1000\n",
      "\u001b[1m183/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7725 - loss: 0.7329  \n",
      "Epoch 785: val_loss did not improve from 0.57023\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7715 - loss: 0.7340 - val_accuracy: 0.8203 - val_loss: 0.5953\n",
      "Epoch 786/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7680 - loss: 0.7318\n",
      "Epoch 786: val_loss improved from 0.57023 to 0.56313, saving model to saved_models/audio_classification.hdf5.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7676 - loss: 0.7317 - val_accuracy: 0.8283 - val_loss: 0.5631\n",
      "Epoch 787/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.7524 - loss: 0.7498\n",
      "Epoch 787: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.7526 - loss: 0.7496 - val_accuracy: 0.8254 - val_loss: 0.5780\n",
      "Epoch 788/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7676 - loss: 0.7316\n",
      "Epoch 788: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7673 - loss: 0.7317 - val_accuracy: 0.8185 - val_loss: 0.5987\n",
      "Epoch 789/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.7715 - loss: 0.7202\n",
      "Epoch 789: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7712 - loss: 0.7210 - val_accuracy: 0.8300 - val_loss: 0.5923\n",
      "Epoch 790/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7619 - loss: 0.7325  \n",
      "Epoch 790: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7618 - loss: 0.7328 - val_accuracy: 0.8248 - val_loss: 0.5866\n",
      "Epoch 791/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.7633 - loss: 0.7514\n",
      "Epoch 791: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7635 - loss: 0.7511 - val_accuracy: 0.8214 - val_loss: 0.5837\n",
      "Epoch 792/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.7602 - loss: 0.7376\n",
      "Epoch 792: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.7604 - loss: 0.7386 - val_accuracy: 0.8248 - val_loss: 0.5968\n",
      "Epoch 793/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7443 - loss: 0.7810\n",
      "Epoch 793: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7459 - loss: 0.7775 - val_accuracy: 0.8237 - val_loss: 0.5908\n",
      "Epoch 794/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7593 - loss: 0.7339\n",
      "Epoch 794: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.7599 - loss: 0.7340 - val_accuracy: 0.8254 - val_loss: 0.5927\n",
      "Epoch 795/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.7565 - loss: 0.7638\n",
      "Epoch 795: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.7561 - loss: 0.7656 - val_accuracy: 0.8180 - val_loss: 0.5897\n",
      "Epoch 796/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7596 - loss: 0.7487\n",
      "Epoch 796: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7597 - loss: 0.7483 - val_accuracy: 0.8271 - val_loss: 0.5911\n",
      "Epoch 797/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.7626 - loss: 0.7548\n",
      "Epoch 797: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.7622 - loss: 0.7556 - val_accuracy: 0.8122 - val_loss: 0.5927\n",
      "Epoch 798/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7622 - loss: 0.7243\n",
      "Epoch 798: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7616 - loss: 0.7296 - val_accuracy: 0.8231 - val_loss: 0.5916\n",
      "Epoch 799/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.7594 - loss: 0.7595\n",
      "Epoch 799: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.7598 - loss: 0.7583 - val_accuracy: 0.8180 - val_loss: 0.6122\n",
      "Epoch 800/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.7567 - loss: 0.7669\n",
      "Epoch 800: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.7569 - loss: 0.7641 - val_accuracy: 0.8185 - val_loss: 0.6050\n",
      "Epoch 801/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7637 - loss: 0.7460\n",
      "Epoch 801: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7639 - loss: 0.7452 - val_accuracy: 0.8163 - val_loss: 0.6033\n",
      "Epoch 802/1000\n",
      "\u001b[1m169/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.7477 - loss: 0.7713\n",
      "Epoch 802: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7499 - loss: 0.7692 - val_accuracy: 0.8128 - val_loss: 0.6139\n",
      "Epoch 803/1000\n",
      "\u001b[1m168/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7689 - loss: 0.7392  \n",
      "Epoch 803: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7682 - loss: 0.7389 - val_accuracy: 0.8203 - val_loss: 0.5839\n",
      "Epoch 804/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7552 - loss: 0.7469\n",
      "Epoch 804: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7551 - loss: 0.7478 - val_accuracy: 0.8243 - val_loss: 0.5957\n",
      "Epoch 805/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7522 - loss: 0.7582\n",
      "Epoch 805: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.7530 - loss: 0.7581 - val_accuracy: 0.8180 - val_loss: 0.5934\n",
      "Epoch 806/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7548 - loss: 0.7446\n",
      "Epoch 806: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7548 - loss: 0.7444 - val_accuracy: 0.8288 - val_loss: 0.5711\n",
      "Epoch 807/1000\n",
      "\u001b[1m179/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.7670 - loss: 0.7298\n",
      "Epoch 807: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.7661 - loss: 0.7346 - val_accuracy: 0.8191 - val_loss: 0.5869\n",
      "Epoch 808/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7518 - loss: 0.7539  \n",
      "Epoch 808: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7520 - loss: 0.7534 - val_accuracy: 0.8191 - val_loss: 0.5949\n",
      "Epoch 809/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.7555 - loss: 0.7665\n",
      "Epoch 809: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7558 - loss: 0.7652 - val_accuracy: 0.8231 - val_loss: 0.5860\n",
      "Epoch 810/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.7512 - loss: 0.7413\n",
      "Epoch 810: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7513 - loss: 0.7415 - val_accuracy: 0.8065 - val_loss: 0.6285\n",
      "Epoch 811/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7584 - loss: 0.7705\n",
      "Epoch 811: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7585 - loss: 0.7691 - val_accuracy: 0.8180 - val_loss: 0.5910\n",
      "Epoch 812/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7658 - loss: 0.7273\n",
      "Epoch 812: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.7660 - loss: 0.7265 - val_accuracy: 0.8243 - val_loss: 0.5780\n",
      "Epoch 813/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7590 - loss: 0.7486\n",
      "Epoch 813: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7591 - loss: 0.7489 - val_accuracy: 0.8157 - val_loss: 0.6123\n",
      "Epoch 814/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.7698 - loss: 0.7014\n",
      "Epoch 814: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7698 - loss: 0.7025 - val_accuracy: 0.8283 - val_loss: 0.5636\n",
      "Epoch 815/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.7494 - loss: 0.7884\n",
      "Epoch 815: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.7509 - loss: 0.7829 - val_accuracy: 0.8168 - val_loss: 0.5926\n",
      "Epoch 816/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7560 - loss: 0.7562\n",
      "Epoch 816: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7562 - loss: 0.7557 - val_accuracy: 0.8174 - val_loss: 0.6063\n",
      "Epoch 817/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.7645 - loss: 0.7363\n",
      "Epoch 817: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.7641 - loss: 0.7379 - val_accuracy: 0.8220 - val_loss: 0.6029\n",
      "Epoch 818/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7564 - loss: 0.7505\n",
      "Epoch 818: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.7567 - loss: 0.7505 - val_accuracy: 0.8128 - val_loss: 0.6142\n",
      "Epoch 819/1000\n",
      "\u001b[1m206/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7567 - loss: 0.7432\n",
      "Epoch 819: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7570 - loss: 0.7429 - val_accuracy: 0.8197 - val_loss: 0.5962\n",
      "Epoch 820/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.7528 - loss: 0.7540\n",
      "Epoch 820: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.7532 - loss: 0.7538 - val_accuracy: 0.8180 - val_loss: 0.6062\n",
      "Epoch 821/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7563 - loss: 0.7510\n",
      "Epoch 821: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7564 - loss: 0.7506 - val_accuracy: 0.8140 - val_loss: 0.5930\n",
      "Epoch 822/1000\n",
      "\u001b[1m159/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.7803 - loss: 0.6982\n",
      "Epoch 822: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7785 - loss: 0.7041 - val_accuracy: 0.8191 - val_loss: 0.5955\n",
      "Epoch 823/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7632 - loss: 0.7211\n",
      "Epoch 823: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7631 - loss: 0.7215 - val_accuracy: 0.8163 - val_loss: 0.6034\n",
      "Epoch 824/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.7671 - loss: 0.7423\n",
      "Epoch 824: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7669 - loss: 0.7423 - val_accuracy: 0.8277 - val_loss: 0.5995\n",
      "Epoch 825/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.7779 - loss: 0.7249\n",
      "Epoch 825: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.7767 - loss: 0.7244 - val_accuracy: 0.8237 - val_loss: 0.5933\n",
      "Epoch 826/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7568 - loss: 0.7382\n",
      "Epoch 826: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7570 - loss: 0.7376 - val_accuracy: 0.8260 - val_loss: 0.5961\n",
      "Epoch 827/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.7470 - loss: 0.7754\n",
      "Epoch 827: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.7478 - loss: 0.7719 - val_accuracy: 0.8203 - val_loss: 0.5927\n",
      "Epoch 828/1000\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7624 - loss: 0.7324  \n",
      "Epoch 828: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7625 - loss: 0.7325 - val_accuracy: 0.8191 - val_loss: 0.6061\n",
      "Epoch 829/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7592 - loss: 0.7500\n",
      "Epoch 829: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.7590 - loss: 0.7505 - val_accuracy: 0.8117 - val_loss: 0.6215\n",
      "Epoch 830/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.7612 - loss: 0.7279\n",
      "Epoch 830: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.7619 - loss: 0.7272 - val_accuracy: 0.8174 - val_loss: 0.5961\n",
      "Epoch 831/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7617 - loss: 0.7507\n",
      "Epoch 831: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7617 - loss: 0.7506 - val_accuracy: 0.8254 - val_loss: 0.5981\n",
      "Epoch 832/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7601 - loss: 0.7422\n",
      "Epoch 832: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7596 - loss: 0.7444 - val_accuracy: 0.8231 - val_loss: 0.6220\n",
      "Epoch 833/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7540 - loss: 0.7723\n",
      "Epoch 833: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7542 - loss: 0.7712 - val_accuracy: 0.8197 - val_loss: 0.5900\n",
      "Epoch 834/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.7702 - loss: 0.7220\n",
      "Epoch 834: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.7696 - loss: 0.7240 - val_accuracy: 0.8231 - val_loss: 0.5867\n",
      "Epoch 835/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7682 - loss: 0.7274\n",
      "Epoch 835: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.7690 - loss: 0.7252 - val_accuracy: 0.8174 - val_loss: 0.5925\n",
      "Epoch 836/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7701 - loss: 0.7546\n",
      "Epoch 836: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7695 - loss: 0.7560 - val_accuracy: 0.8191 - val_loss: 0.6076\n",
      "Epoch 837/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7735 - loss: 0.7046\n",
      "Epoch 837: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.7724 - loss: 0.7071 - val_accuracy: 0.8191 - val_loss: 0.6227\n",
      "Epoch 838/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7744 - loss: 0.7027\n",
      "Epoch 838: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7742 - loss: 0.7032 - val_accuracy: 0.8214 - val_loss: 0.5965\n",
      "Epoch 839/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.7598 - loss: 0.7714\n",
      "Epoch 839: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.7593 - loss: 0.7720 - val_accuracy: 0.8248 - val_loss: 0.5947\n",
      "Epoch 840/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.7579 - loss: 0.7551\n",
      "Epoch 840: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.7584 - loss: 0.7541 - val_accuracy: 0.8185 - val_loss: 0.5992\n",
      "Epoch 841/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.7708 - loss: 0.7203\n",
      "Epoch 841: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.7706 - loss: 0.7206 - val_accuracy: 0.8208 - val_loss: 0.6049\n",
      "Epoch 842/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.7698 - loss: 0.7280\n",
      "Epoch 842: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.7698 - loss: 0.7278 - val_accuracy: 0.8231 - val_loss: 0.5847\n",
      "Epoch 843/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7572 - loss: 0.7543  \n",
      "Epoch 843: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7573 - loss: 0.7539 - val_accuracy: 0.8185 - val_loss: 0.5995\n",
      "Epoch 844/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.7538 - loss: 0.7565\n",
      "Epoch 844: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.7548 - loss: 0.7550 - val_accuracy: 0.8260 - val_loss: 0.5927\n",
      "Epoch 845/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7640 - loss: 0.7664\n",
      "Epoch 845: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.7640 - loss: 0.7661 - val_accuracy: 0.8288 - val_loss: 0.5892\n",
      "Epoch 846/1000\n",
      "\u001b[1m176/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7680 - loss: 0.7177\n",
      "Epoch 846: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7666 - loss: 0.7229 - val_accuracy: 0.8128 - val_loss: 0.6197\n",
      "Epoch 847/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7640 - loss: 0.7425\n",
      "Epoch 847: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7639 - loss: 0.7425 - val_accuracy: 0.8231 - val_loss: 0.5914\n",
      "Epoch 848/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7538 - loss: 0.7431\n",
      "Epoch 848: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7549 - loss: 0.7417 - val_accuracy: 0.8100 - val_loss: 0.6309\n",
      "Epoch 849/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.7614 - loss: 0.7474\n",
      "Epoch 849: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.7611 - loss: 0.7504 - val_accuracy: 0.8163 - val_loss: 0.6078\n",
      "Epoch 850/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7483 - loss: 0.7918\n",
      "Epoch 850: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7490 - loss: 0.7887 - val_accuracy: 0.8163 - val_loss: 0.5926\n",
      "Epoch 851/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.7686 - loss: 0.7277\n",
      "Epoch 851: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7684 - loss: 0.7285 - val_accuracy: 0.8100 - val_loss: 0.6088\n",
      "Epoch 852/1000\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.7622 - loss: 0.7605\n",
      "Epoch 852: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.7621 - loss: 0.7600 - val_accuracy: 0.8214 - val_loss: 0.5771\n",
      "Epoch 853/1000\n",
      "\u001b[1m176/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7576 - loss: 0.7667\n",
      "Epoch 853: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7584 - loss: 0.7630 - val_accuracy: 0.8294 - val_loss: 0.5834\n",
      "Epoch 854/1000\n",
      "\u001b[1m182/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.7702 - loss: 0.7239\n",
      "Epoch 854: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.7696 - loss: 0.7255 - val_accuracy: 0.8065 - val_loss: 0.6309\n",
      "Epoch 855/1000\n",
      "\u001b[1m175/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7610 - loss: 0.7225\n",
      "Epoch 855: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7612 - loss: 0.7234 - val_accuracy: 0.8163 - val_loss: 0.6187\n",
      "Epoch 856/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.7694 - loss: 0.7232\n",
      "Epoch 856: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.7687 - loss: 0.7250 - val_accuracy: 0.8168 - val_loss: 0.6066\n",
      "Epoch 857/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7545 - loss: 0.7637\n",
      "Epoch 857: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7547 - loss: 0.7633 - val_accuracy: 0.8174 - val_loss: 0.6114\n",
      "Epoch 858/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.7679 - loss: 0.7338\n",
      "Epoch 858: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7677 - loss: 0.7330 - val_accuracy: 0.8294 - val_loss: 0.6003\n",
      "Epoch 859/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.7582 - loss: 0.7368\n",
      "Epoch 859: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.7586 - loss: 0.7384 - val_accuracy: 0.8065 - val_loss: 0.6169\n",
      "Epoch 860/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7651 - loss: 0.7572\n",
      "Epoch 860: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7649 - loss: 0.7572 - val_accuracy: 0.8174 - val_loss: 0.5945\n",
      "Epoch 861/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.7589 - loss: 0.7731\n",
      "Epoch 861: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7583 - loss: 0.7733 - val_accuracy: 0.8117 - val_loss: 0.6001\n",
      "Epoch 862/1000\n",
      "\u001b[1m163/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7625 - loss: 0.7397\n",
      "Epoch 862: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7604 - loss: 0.7449 - val_accuracy: 0.8163 - val_loss: 0.6064\n",
      "Epoch 863/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.7653 - loss: 0.7365\n",
      "Epoch 863: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7656 - loss: 0.7352 - val_accuracy: 0.8243 - val_loss: 0.5879\n",
      "Epoch 864/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.7638 - loss: 0.7380\n",
      "Epoch 864: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7636 - loss: 0.7385 - val_accuracy: 0.8094 - val_loss: 0.6041\n",
      "Epoch 865/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.7494 - loss: 0.7716\n",
      "Epoch 865: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7503 - loss: 0.7686 - val_accuracy: 0.8065 - val_loss: 0.6306\n",
      "Epoch 866/1000\n",
      "\u001b[1m185/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7700 - loss: 0.7095\n",
      "Epoch 866: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.7678 - loss: 0.7159 - val_accuracy: 0.8266 - val_loss: 0.5996\n",
      "Epoch 867/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7650 - loss: 0.7274\n",
      "Epoch 867: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7651 - loss: 0.7274 - val_accuracy: 0.8214 - val_loss: 0.5987\n",
      "Epoch 868/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7543 - loss: 0.7590\n",
      "Epoch 868: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7551 - loss: 0.7570 - val_accuracy: 0.8145 - val_loss: 0.6274\n",
      "Epoch 869/1000\n",
      "\u001b[1m183/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7557 - loss: 0.7697\n",
      "Epoch 869: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7570 - loss: 0.7643 - val_accuracy: 0.8283 - val_loss: 0.5901\n",
      "Epoch 870/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7642 - loss: 0.7471\n",
      "Epoch 870: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.7645 - loss: 0.7466 - val_accuracy: 0.8283 - val_loss: 0.5884\n",
      "Epoch 871/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.7691 - loss: 0.7093\n",
      "Epoch 871: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.7682 - loss: 0.7127 - val_accuracy: 0.8214 - val_loss: 0.6056\n",
      "Epoch 872/1000\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7692 - loss: 0.7087\n",
      "Epoch 872: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7689 - loss: 0.7099 - val_accuracy: 0.8208 - val_loss: 0.5933\n",
      "Epoch 873/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.7731 - loss: 0.6933\n",
      "Epoch 873: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7719 - loss: 0.6972 - val_accuracy: 0.8220 - val_loss: 0.5848\n",
      "Epoch 874/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7604 - loss: 0.7138\n",
      "Epoch 874: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7637 - loss: 0.7162 - val_accuracy: 0.8266 - val_loss: 0.5831\n",
      "Epoch 875/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.7661 - loss: 0.7378\n",
      "Epoch 875: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7659 - loss: 0.7382 - val_accuracy: 0.8237 - val_loss: 0.5904\n",
      "Epoch 876/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.7678 - loss: 0.7358\n",
      "Epoch 876: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7676 - loss: 0.7362 - val_accuracy: 0.8163 - val_loss: 0.5905\n",
      "Epoch 877/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.7667 - loss: 0.7197\n",
      "Epoch 877: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7657 - loss: 0.7234 - val_accuracy: 0.8140 - val_loss: 0.6166\n",
      "Epoch 878/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.7620 - loss: 0.7381\n",
      "Epoch 878: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.7616 - loss: 0.7402 - val_accuracy: 0.8185 - val_loss: 0.5994\n",
      "Epoch 879/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7494 - loss: 0.7457\n",
      "Epoch 879: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7506 - loss: 0.7442 - val_accuracy: 0.8243 - val_loss: 0.5967\n",
      "Epoch 880/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7588 - loss: 0.7590\n",
      "Epoch 880: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.7589 - loss: 0.7570 - val_accuracy: 0.8163 - val_loss: 0.5931\n",
      "Epoch 881/1000\n",
      "\u001b[1m181/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7621 - loss: 0.7301\n",
      "Epoch 881: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7619 - loss: 0.7315 - val_accuracy: 0.8214 - val_loss: 0.5921\n",
      "Epoch 882/1000\n",
      "\u001b[1m183/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7472 - loss: 0.7671\n",
      "Epoch 882: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.7493 - loss: 0.7620 - val_accuracy: 0.8300 - val_loss: 0.5908\n",
      "Epoch 883/1000\n",
      "\u001b[1m164/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7668 - loss: 0.7201\n",
      "Epoch 883: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7646 - loss: 0.7259 - val_accuracy: 0.8283 - val_loss: 0.5915\n",
      "Epoch 884/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.7680 - loss: 0.7357\n",
      "Epoch 884: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.7671 - loss: 0.7359 - val_accuracy: 0.8283 - val_loss: 0.5818\n",
      "Epoch 885/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7633 - loss: 0.7310  \n",
      "Epoch 885: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7634 - loss: 0.7311 - val_accuracy: 0.8317 - val_loss: 0.5822\n",
      "Epoch 886/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7758 - loss: 0.7364\n",
      "Epoch 886: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7748 - loss: 0.7380 - val_accuracy: 0.8197 - val_loss: 0.6133\n",
      "Epoch 887/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.7706 - loss: 0.7655\n",
      "Epoch 887: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.7702 - loss: 0.7630 - val_accuracy: 0.8174 - val_loss: 0.6173\n",
      "Epoch 888/1000\n",
      "\u001b[1m180/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7448 - loss: 0.7830\n",
      "Epoch 888: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.7789 - val_accuracy: 0.8226 - val_loss: 0.6050\n",
      "Epoch 889/1000\n",
      "\u001b[1m185/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.7554 - loss: 0.7405\n",
      "Epoch 889: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.7556 - loss: 0.7410 - val_accuracy: 0.8260 - val_loss: 0.6061\n",
      "Epoch 890/1000\n",
      "\u001b[1m207/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7740 - loss: 0.7188\n",
      "Epoch 890: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7740 - loss: 0.7194 - val_accuracy: 0.8266 - val_loss: 0.5887\n",
      "Epoch 891/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7626 - loss: 0.7348\n",
      "Epoch 891: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.7622 - loss: 0.7369 - val_accuracy: 0.8220 - val_loss: 0.5726\n",
      "Epoch 892/1000\n",
      "\u001b[1m184/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7765 - loss: 0.6962\n",
      "Epoch 892: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.7747 - loss: 0.7019 - val_accuracy: 0.8180 - val_loss: 0.6153\n",
      "Epoch 893/1000\n",
      "\u001b[1m181/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7615 - loss: 0.7163\n",
      "Epoch 893: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7603 - loss: 0.7219 - val_accuracy: 0.8140 - val_loss: 0.6007\n",
      "Epoch 894/1000\n",
      "\u001b[1m185/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.7533 - loss: 0.7420\n",
      "Epoch 894: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.7536 - loss: 0.7410 - val_accuracy: 0.8288 - val_loss: 0.5786\n",
      "Epoch 895/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7784 - loss: 0.6980\n",
      "Epoch 895: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7774 - loss: 0.7003 - val_accuracy: 0.8220 - val_loss: 0.6148\n",
      "Epoch 896/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.7501 - loss: 0.7728\n",
      "Epoch 896: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7511 - loss: 0.7709 - val_accuracy: 0.8226 - val_loss: 0.6110\n",
      "Epoch 897/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.7790 - loss: 0.7088\n",
      "Epoch 897: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.7784 - loss: 0.7110 - val_accuracy: 0.8271 - val_loss: 0.6031\n",
      "Epoch 898/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7714 - loss: 0.6998\n",
      "Epoch 898: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7709 - loss: 0.7016 - val_accuracy: 0.8283 - val_loss: 0.6065\n",
      "Epoch 899/1000\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.7642 - loss: 0.7520\n",
      "Epoch 899: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7642 - loss: 0.7511 - val_accuracy: 0.8220 - val_loss: 0.6173\n",
      "Epoch 900/1000\n",
      "\u001b[1m173/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7642 - loss: 0.7196\n",
      "Epoch 900: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7637 - loss: 0.7216 - val_accuracy: 0.8168 - val_loss: 0.6109\n",
      "Epoch 901/1000\n",
      "\u001b[1m206/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.7601 - loss: 0.7456\n",
      "Epoch 901: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7604 - loss: 0.7454 - val_accuracy: 0.8180 - val_loss: 0.6039\n",
      "Epoch 902/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.7688 - loss: 0.7165\n",
      "Epoch 902: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7686 - loss: 0.7173 - val_accuracy: 0.8214 - val_loss: 0.6075\n",
      "Epoch 903/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.7705 - loss: 0.7336\n",
      "Epoch 903: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.7690 - loss: 0.7378 - val_accuracy: 0.8220 - val_loss: 0.6040\n",
      "Epoch 904/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.7684 - loss: 0.7262\n",
      "Epoch 904: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7684 - loss: 0.7260 - val_accuracy: 0.8226 - val_loss: 0.5974\n",
      "Epoch 905/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7739 - loss: 0.7085\n",
      "Epoch 905: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7733 - loss: 0.7102 - val_accuracy: 0.8214 - val_loss: 0.5899\n",
      "Epoch 906/1000\n",
      "\u001b[1m201/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7619 - loss: 0.7360\n",
      "Epoch 906: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7613 - loss: 0.7381 - val_accuracy: 0.8288 - val_loss: 0.6090\n",
      "Epoch 907/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7623 - loss: 0.7453  \n",
      "Epoch 907: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7619 - loss: 0.7462 - val_accuracy: 0.8088 - val_loss: 0.6215\n",
      "Epoch 908/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.7614 - loss: 0.7541\n",
      "Epoch 908: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.7617 - loss: 0.7530 - val_accuracy: 0.8254 - val_loss: 0.6106\n",
      "Epoch 909/1000\n",
      "\u001b[1m185/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7600 - loss: 0.7338\n",
      "Epoch 909: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7595 - loss: 0.7349 - val_accuracy: 0.8100 - val_loss: 0.6384\n",
      "Epoch 910/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.7713 - loss: 0.7080\n",
      "Epoch 910: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.7711 - loss: 0.7111 - val_accuracy: 0.8082 - val_loss: 0.6122\n",
      "Epoch 911/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7662 - loss: 0.7312\n",
      "Epoch 911: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7663 - loss: 0.7311 - val_accuracy: 0.8191 - val_loss: 0.5967\n",
      "Epoch 912/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7609 - loss: 0.7393\n",
      "Epoch 912: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7604 - loss: 0.7419 - val_accuracy: 0.8220 - val_loss: 0.6035\n",
      "Epoch 913/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7658 - loss: 0.7464\n",
      "Epoch 913: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7658 - loss: 0.7464 - val_accuracy: 0.8248 - val_loss: 0.6102\n",
      "Epoch 914/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7640 - loss: 0.7534\n",
      "Epoch 914: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.7634 - loss: 0.7532 - val_accuracy: 0.8231 - val_loss: 0.5972\n",
      "Epoch 915/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7602 - loss: 0.7516\n",
      "Epoch 915: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7606 - loss: 0.7508 - val_accuracy: 0.8260 - val_loss: 0.5894\n",
      "Epoch 916/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7579 - loss: 0.7494\n",
      "Epoch 916: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.7593 - loss: 0.7474 - val_accuracy: 0.8226 - val_loss: 0.5986\n",
      "Epoch 917/1000\n",
      "\u001b[1m183/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7664 - loss: 0.7155\n",
      "Epoch 917: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7660 - loss: 0.7177 - val_accuracy: 0.8271 - val_loss: 0.5834\n",
      "Epoch 918/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.7670 - loss: 0.7157\n",
      "Epoch 918: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7667 - loss: 0.7179 - val_accuracy: 0.8243 - val_loss: 0.5996\n",
      "Epoch 919/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7683 - loss: 0.7220\n",
      "Epoch 919: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7680 - loss: 0.7228 - val_accuracy: 0.8174 - val_loss: 0.6281\n",
      "Epoch 920/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.7549 - loss: 0.7489\n",
      "Epoch 920: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.7551 - loss: 0.7499 - val_accuracy: 0.8208 - val_loss: 0.5943\n",
      "Epoch 921/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7520 - loss: 0.7672\n",
      "Epoch 921: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7525 - loss: 0.7662 - val_accuracy: 0.8231 - val_loss: 0.6003\n",
      "Epoch 922/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7653 - loss: 0.7445\n",
      "Epoch 922: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.7651 - loss: 0.7431 - val_accuracy: 0.8248 - val_loss: 0.5923\n",
      "Epoch 923/1000\n",
      "\u001b[1m169/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7671 - loss: 0.7447\n",
      "Epoch 923: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7680 - loss: 0.7407 - val_accuracy: 0.8203 - val_loss: 0.6174\n",
      "Epoch 924/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7711 - loss: 0.7432\n",
      "Epoch 924: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.7698 - loss: 0.7448 - val_accuracy: 0.8185 - val_loss: 0.6057\n",
      "Epoch 925/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7635 - loss: 0.7069\n",
      "Epoch 925: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7635 - loss: 0.7078 - val_accuracy: 0.8048 - val_loss: 0.6292\n",
      "Epoch 926/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.7518 - loss: 0.7688\n",
      "Epoch 926: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.7532 - loss: 0.7647 - val_accuracy: 0.8208 - val_loss: 0.6291\n",
      "Epoch 927/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7679 - loss: 0.7370\n",
      "Epoch 927: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7673 - loss: 0.7383 - val_accuracy: 0.8140 - val_loss: 0.6214\n",
      "Epoch 928/1000\n",
      "\u001b[1m182/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7617 - loss: 0.7638\n",
      "Epoch 928: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7611 - loss: 0.7634 - val_accuracy: 0.8260 - val_loss: 0.5987\n",
      "Epoch 929/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7611 - loss: 0.7346\n",
      "Epoch 929: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7613 - loss: 0.7342 - val_accuracy: 0.8168 - val_loss: 0.6012\n",
      "Epoch 930/1000\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7679 - loss: 0.7212\n",
      "Epoch 930: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7675 - loss: 0.7236 - val_accuracy: 0.8208 - val_loss: 0.6059\n",
      "Epoch 931/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7604 - loss: 0.7657\n",
      "Epoch 931: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7607 - loss: 0.7640 - val_accuracy: 0.8185 - val_loss: 0.6206\n",
      "Epoch 932/1000\n",
      "\u001b[1m149/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7656 - loss: 0.7489\n",
      "Epoch 932: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7636 - loss: 0.7471 - val_accuracy: 0.8231 - val_loss: 0.6015\n",
      "Epoch 933/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.7749 - loss: 0.6909\n",
      "Epoch 933: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7744 - loss: 0.6929 - val_accuracy: 0.8237 - val_loss: 0.5914\n",
      "Epoch 934/1000\n",
      "\u001b[1m155/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7553 - loss: 0.7553\n",
      "Epoch 934: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7566 - loss: 0.7543 - val_accuracy: 0.8288 - val_loss: 0.5848\n",
      "Epoch 935/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7567 - loss: 0.7492\n",
      "Epoch 935: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7579 - loss: 0.7480 - val_accuracy: 0.8226 - val_loss: 0.5838\n",
      "Epoch 936/1000\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7624 - loss: 0.7518\n",
      "Epoch 936: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7630 - loss: 0.7501 - val_accuracy: 0.8283 - val_loss: 0.5860\n",
      "Epoch 937/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7621 - loss: 0.7170\n",
      "Epoch 937: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.7621 - loss: 0.7181 - val_accuracy: 0.8294 - val_loss: 0.5815\n",
      "Epoch 938/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7616 - loss: 0.7462  \n",
      "Epoch 938: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7615 - loss: 0.7460 - val_accuracy: 0.8185 - val_loss: 0.5875\n",
      "Epoch 939/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7588 - loss: 0.7508\n",
      "Epoch 939: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.7588 - loss: 0.7513 - val_accuracy: 0.8231 - val_loss: 0.5981\n",
      "Epoch 940/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.7673 - loss: 0.7103\n",
      "Epoch 940: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7673 - loss: 0.7117 - val_accuracy: 0.8243 - val_loss: 0.5914\n",
      "Epoch 941/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.7635 - loss: 0.7616\n",
      "Epoch 941: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7633 - loss: 0.7602 - val_accuracy: 0.8197 - val_loss: 0.6117\n",
      "Epoch 942/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.7723 - loss: 0.7052\n",
      "Epoch 942: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.7713 - loss: 0.7083 - val_accuracy: 0.8231 - val_loss: 0.6151\n",
      "Epoch 943/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7731 - loss: 0.7218\n",
      "Epoch 943: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7727 - loss: 0.7231 - val_accuracy: 0.8283 - val_loss: 0.5760\n",
      "Epoch 944/1000\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.7655 - loss: 0.7404\n",
      "Epoch 944: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.7654 - loss: 0.7409 - val_accuracy: 0.8185 - val_loss: 0.6143\n",
      "Epoch 945/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7577 - loss: 0.7554\n",
      "Epoch 945: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7571 - loss: 0.7558 - val_accuracy: 0.8283 - val_loss: 0.5770\n",
      "Epoch 946/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7499 - loss: 0.7652\n",
      "Epoch 946: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.7518 - loss: 0.7606 - val_accuracy: 0.8231 - val_loss: 0.5804\n",
      "Epoch 947/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7713 - loss: 0.7151\n",
      "Epoch 947: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7713 - loss: 0.7152 - val_accuracy: 0.8237 - val_loss: 0.5892\n",
      "Epoch 948/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.7681 - loss: 0.7090\n",
      "Epoch 948: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7683 - loss: 0.7107 - val_accuracy: 0.8157 - val_loss: 0.5997\n",
      "Epoch 949/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7674 - loss: 0.7379\n",
      "Epoch 949: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7671 - loss: 0.7375 - val_accuracy: 0.8294 - val_loss: 0.5729\n",
      "Epoch 950/1000\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7638 - loss: 0.7429\n",
      "Epoch 950: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.7627 - loss: 0.7461 - val_accuracy: 0.8260 - val_loss: 0.6024\n",
      "Epoch 951/1000\n",
      "\u001b[1m159/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7641 - loss: 0.7254\n",
      "Epoch 951: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7651 - loss: 0.7275 - val_accuracy: 0.8294 - val_loss: 0.5688\n",
      "Epoch 952/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7745 - loss: 0.7171\n",
      "Epoch 952: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7739 - loss: 0.7180 - val_accuracy: 0.8283 - val_loss: 0.5773\n",
      "Epoch 953/1000\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7567 - loss: 0.7625\n",
      "Epoch 953: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7569 - loss: 0.7618 - val_accuracy: 0.8180 - val_loss: 0.5901\n",
      "Epoch 954/1000\n",
      "\u001b[1m197/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.7807 - loss: 0.6878\n",
      "Epoch 954: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.7798 - loss: 0.6899 - val_accuracy: 0.8203 - val_loss: 0.5935\n",
      "Epoch 955/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7576 - loss: 0.7482\n",
      "Epoch 955: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7577 - loss: 0.7474 - val_accuracy: 0.8220 - val_loss: 0.6026\n",
      "Epoch 956/1000\n",
      "\u001b[1m184/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.7695 - loss: 0.7412\n",
      "Epoch 956: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.7685 - loss: 0.7420 - val_accuracy: 0.8254 - val_loss: 0.5928\n",
      "Epoch 957/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7495 - loss: 0.7682\n",
      "Epoch 957: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7506 - loss: 0.7643 - val_accuracy: 0.8203 - val_loss: 0.5880\n",
      "Epoch 958/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.7730 - loss: 0.6884\n",
      "Epoch 958: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.7722 - loss: 0.6938 - val_accuracy: 0.8323 - val_loss: 0.5780\n",
      "Epoch 959/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7675 - loss: 0.7319\n",
      "Epoch 959: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7673 - loss: 0.7322 - val_accuracy: 0.8014 - val_loss: 0.6391\n",
      "Epoch 960/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.7757 - loss: 0.7244\n",
      "Epoch 960: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.7761 - loss: 0.7226 - val_accuracy: 0.8214 - val_loss: 0.5915\n",
      "Epoch 961/1000\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7633 - loss: 0.7492\n",
      "Epoch 961: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7630 - loss: 0.7492 - val_accuracy: 0.8094 - val_loss: 0.6288\n",
      "Epoch 962/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7665 - loss: 0.7468\n",
      "Epoch 962: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7663 - loss: 0.7455 - val_accuracy: 0.8174 - val_loss: 0.6014\n",
      "Epoch 963/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.7726 - loss: 0.7161\n",
      "Epoch 963: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7723 - loss: 0.7180 - val_accuracy: 0.8277 - val_loss: 0.5810\n",
      "Epoch 964/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7691 - loss: 0.7362\n",
      "Epoch 964: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7687 - loss: 0.7359 - val_accuracy: 0.8226 - val_loss: 0.6184\n",
      "Epoch 965/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7690 - loss: 0.7175\n",
      "Epoch 965: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7687 - loss: 0.7196 - val_accuracy: 0.8317 - val_loss: 0.5847\n",
      "Epoch 966/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7711 - loss: 0.7237\n",
      "Epoch 966: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7706 - loss: 0.7241 - val_accuracy: 0.8248 - val_loss: 0.5777\n",
      "Epoch 967/1000\n",
      "\u001b[1m167/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7525 - loss: 0.7507  \n",
      "Epoch 967: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7544 - loss: 0.7485 - val_accuracy: 0.8357 - val_loss: 0.5864\n",
      "Epoch 968/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7729 - loss: 0.7178\n",
      "Epoch 968: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7730 - loss: 0.7168 - val_accuracy: 0.8243 - val_loss: 0.5844\n",
      "Epoch 969/1000\n",
      "\u001b[1m185/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.7620 - loss: 0.7319\n",
      "Epoch 969: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.7626 - loss: 0.7306 - val_accuracy: 0.8237 - val_loss: 0.6101\n",
      "Epoch 970/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7618 - loss: 0.7392\n",
      "Epoch 970: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7622 - loss: 0.7387 - val_accuracy: 0.8346 - val_loss: 0.5727\n",
      "Epoch 971/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.7731 - loss: 0.7024\n",
      "Epoch 971: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.7719 - loss: 0.7053 - val_accuracy: 0.8214 - val_loss: 0.5866\n",
      "Epoch 972/1000\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7475 - loss: 0.7808\n",
      "Epoch 972: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7489 - loss: 0.7773 - val_accuracy: 0.8243 - val_loss: 0.5765\n",
      "Epoch 973/1000\n",
      "\u001b[1m184/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7597 - loss: 0.7476\n",
      "Epoch 973: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.7590 - loss: 0.7503 - val_accuracy: 0.8254 - val_loss: 0.5990\n",
      "Epoch 974/1000\n",
      "\u001b[1m215/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.7698 - loss: 0.7146\n",
      "Epoch 974: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7696 - loss: 0.7152 - val_accuracy: 0.8168 - val_loss: 0.6014\n",
      "Epoch 975/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.7740 - loss: 0.7136\n",
      "Epoch 975: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7726 - loss: 0.7174 - val_accuracy: 0.8283 - val_loss: 0.5903\n",
      "Epoch 976/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.7572 - loss: 0.7544\n",
      "Epoch 976: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.7578 - loss: 0.7534 - val_accuracy: 0.8306 - val_loss: 0.5785\n",
      "Epoch 977/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7705 - loss: 0.7223\n",
      "Epoch 977: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7704 - loss: 0.7225 - val_accuracy: 0.8248 - val_loss: 0.5915\n",
      "Epoch 978/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.7761 - loss: 0.6989\n",
      "Epoch 978: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.7753 - loss: 0.7020 - val_accuracy: 0.8317 - val_loss: 0.5637\n",
      "Epoch 979/1000\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7626 - loss: 0.7604\n",
      "Epoch 979: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7632 - loss: 0.7571 - val_accuracy: 0.8266 - val_loss: 0.5919\n",
      "Epoch 980/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7660 - loss: 0.7393\n",
      "Epoch 980: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.7662 - loss: 0.7377 - val_accuracy: 0.8283 - val_loss: 0.6016\n",
      "Epoch 981/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7594 - loss: 0.7543\n",
      "Epoch 981: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7596 - loss: 0.7536 - val_accuracy: 0.8163 - val_loss: 0.6081\n",
      "Epoch 982/1000\n",
      "\u001b[1m185/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.7634 - loss: 0.7483\n",
      "Epoch 982: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.7638 - loss: 0.7472 - val_accuracy: 0.8260 - val_loss: 0.5962\n",
      "Epoch 983/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7644 - loss: 0.7552\n",
      "Epoch 983: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7643 - loss: 0.7548 - val_accuracy: 0.8254 - val_loss: 0.6083\n",
      "Epoch 984/1000\n",
      "\u001b[1m195/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.7653 - loss: 0.7638\n",
      "Epoch 984: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.7641 - loss: 0.7659 - val_accuracy: 0.8168 - val_loss: 0.6030\n",
      "Epoch 985/1000\n",
      "\u001b[1m191/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7577 - loss: 0.7544\n",
      "Epoch 985: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7581 - loss: 0.7525 - val_accuracy: 0.8100 - val_loss: 0.6055\n",
      "Epoch 986/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.7601 - loss: 0.7250\n",
      "Epoch 986: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.7611 - loss: 0.7249 - val_accuracy: 0.8283 - val_loss: 0.5882\n",
      "Epoch 987/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7803 - loss: 0.7051\n",
      "Epoch 987: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7800 - loss: 0.7053 - val_accuracy: 0.8220 - val_loss: 0.6175\n",
      "Epoch 988/1000\n",
      "\u001b[1m190/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7839 - loss: 0.6824\n",
      "Epoch 988: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.7827 - loss: 0.6873 - val_accuracy: 0.8191 - val_loss: 0.6077\n",
      "Epoch 989/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7596 - loss: 0.7510\n",
      "Epoch 989: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7597 - loss: 0.7507 - val_accuracy: 0.8254 - val_loss: 0.6038\n",
      "Epoch 990/1000\n",
      "\u001b[1m185/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.7493 - loss: 0.7784\n",
      "Epoch 990: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.7504 - loss: 0.7743 - val_accuracy: 0.8174 - val_loss: 0.6189\n",
      "Epoch 991/1000\n",
      "\u001b[1m199/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7634 - loss: 0.7473\n",
      "Epoch 991: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7639 - loss: 0.7458 - val_accuracy: 0.8203 - val_loss: 0.6383\n",
      "Epoch 992/1000\n",
      "\u001b[1m184/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.7657 - loss: 0.7255\n",
      "Epoch 992: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.7653 - loss: 0.7288 - val_accuracy: 0.8168 - val_loss: 0.6306\n",
      "Epoch 993/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7777 - loss: 0.7188\n",
      "Epoch 993: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7775 - loss: 0.7189 - val_accuracy: 0.8248 - val_loss: 0.5971\n",
      "Epoch 994/1000\n",
      "\u001b[1m193/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.7509 - loss: 0.7734\n",
      "Epoch 994: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7516 - loss: 0.7705 - val_accuracy: 0.8248 - val_loss: 0.6027\n",
      "Epoch 995/1000\n",
      "\u001b[1m153/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7522 - loss: 0.7695\n",
      "Epoch 995: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7539 - loss: 0.7679 - val_accuracy: 0.8174 - val_loss: 0.6335\n",
      "Epoch 996/1000\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.7529 - loss: 0.7554\n",
      "Epoch 996: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.7536 - loss: 0.7539 - val_accuracy: 0.8197 - val_loss: 0.6000\n",
      "Epoch 997/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7669 - loss: 0.7107\n",
      "Epoch 997: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7660 - loss: 0.7146 - val_accuracy: 0.8203 - val_loss: 0.5973\n",
      "Epoch 998/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.7673 - loss: 0.7432\n",
      "Epoch 998: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.7677 - loss: 0.7413 - val_accuracy: 0.8260 - val_loss: 0.5741\n",
      "Epoch 999/1000\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7741 - loss: 0.7128\n",
      "Epoch 999: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7735 - loss: 0.7141 - val_accuracy: 0.8306 - val_loss: 0.6025\n",
      "Epoch 1000/1000\n",
      "\u001b[1m188/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.7649 - loss: 0.7412\n",
      "Epoch 1000: val_loss did not improve from 0.56313\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.7645 - loss: 0.7414 - val_accuracy: 0.8208 - val_loss: 0.6048\n",
      "Training completed in:  0:03:40.264001\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "checkpoint = ModelCheckpoint(filepath = 'saved_models/audio_classification.hdf5.keras', verbose = 1, save_best_only = True)\n",
    "start = datetime.now()\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), callbacks=[checkpoint])\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8208357095718384\n"
     ]
    }
   ],
   "source": [
    "#Validation accuracy from above is about 82%. Training accuracy is around 76%\n",
    "test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(test_accuracy[1]) #validation accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'UrbanSound8K/dog_bark.wav' #testing on this sound file\n",
    "prediction_classes = features_extract(filename).reshape(1, -1)\n",
    "np.argmax(model.predict(prediction_classes), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dog_bark', 'children_playing', 'car_horn', 'air_conditioner',\n",
       "       'street_music', 'gun_shot', 'siren', 'engine_idling', 'jackhammer',\n",
       "       'drilling'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing On Test Audio Data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will preprocess the new audio data, predict the classes, and inverse transform the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.76445297e+02  1.28394089e+02 -3.72119827e+01  3.49234772e+01\n",
      " -2.46015453e+01 -6.89300728e+00  4.30942345e+00 -1.05011605e-01\n",
      " -2.30885334e+01  2.06345787e+01 -1.07478743e+01  2.08734846e+00\n",
      " -4.15044308e+00  8.20374846e-01 -1.51422806e+01  2.18557978e+00\n",
      " -5.28599501e+00  9.08012676e+00 -1.14536595e+00  4.28091621e+00\n",
      " -1.43432503e+01 -7.88370013e-01 -5.44772196e+00  5.51001167e+00\n",
      " -4.54434443e+00 -3.50117064e+00 -9.05346966e+00  6.07954860e-01\n",
      "  6.37112498e-01 -2.56788802e+00 -6.53705788e+00 -2.61835098e+00\n",
      " -2.21441221e+00  3.54255319e+00  2.51226711e+00 -4.15956783e+00\n",
      "  1.08446956e+00 -1.20071244e+00 -1.04576101e+01  2.49877954e+00]\n",
      "[[-1.76445297e+02  1.28394089e+02 -3.72119827e+01  3.49234772e+01\n",
      "  -2.46015453e+01 -6.89300728e+00  4.30942345e+00 -1.05011605e-01\n",
      "  -2.30885334e+01  2.06345787e+01 -1.07478743e+01  2.08734846e+00\n",
      "  -4.15044308e+00  8.20374846e-01 -1.51422806e+01  2.18557978e+00\n",
      "  -5.28599501e+00  9.08012676e+00 -1.14536595e+00  4.28091621e+00\n",
      "  -1.43432503e+01 -7.88370013e-01 -5.44772196e+00  5.51001167e+00\n",
      "  -4.54434443e+00 -3.50117064e+00 -9.05346966e+00  6.07954860e-01\n",
      "   6.37112498e-01 -2.56788802e+00 -6.53705788e+00 -2.61835098e+00\n",
      "  -2.21441221e+00  3.54255319e+00  2.51226711e+00 -4.15956783e+00\n",
      "   1.08446956e+00 -1.20071244e+00 -1.04576101e+01  2.49877954e+00]]\n",
      "(1, 40)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['car_horn'], dtype='<U16')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the file 191431-9-0-73.wav sounds like car horn, let's predict\n",
    "filename = 'UrbanSound8K/7389-1-4-14.wav'\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "print(mfccs_scaled_features)\n",
    "print(mfccs_scaled_features.shape)\n",
    "predicted_label=np.argmax(model.predict(prediction_classes), axis=-1) \n",
    "print(predicted_label)\n",
    "prediction_class = labelencoder.inverse_transform(predicted_label) \n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction successful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
